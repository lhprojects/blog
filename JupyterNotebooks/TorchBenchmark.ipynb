{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用torch官方的benchmark例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__name__ = \"fake name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % https://raw.githubusercontent.com/pytorch/examples/master/mnist/main.py\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                     epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                     100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if args.dry_run:\n",
    "                break\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    \n",
    "    #print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=14, metavar='N',\n",
    "                        help='number of epochs to train (default: 14)')\n",
    "    parser.add_argument('--lr', type=float, default=1.0, metavar='LR',\n",
    "                        help='learning rate (default: 1.0)')\n",
    "    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                        help='Learning rate step gamma (default: 0.7)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                        help='quickly check a single pass')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                        help='For Saving the current Model')\n",
    "    args = parser.parse_args()\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    train_kwargs = {'batch_size': args.batch_size}\n",
    "    test_kwargs = {'batch_size': args.test_batch_size}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "    dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "    dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "import psutil\n",
    "from torchvision import datasets\n",
    "\n",
    "\n",
    "def list_env():\n",
    "    print(platform.node())\n",
    "    print(platform.platform())\n",
    "    print(platform.processor())\n",
    "    print(\"cpu-count\", psutil.cpu_count())\n",
    "    print(sys.version)\n",
    "    print(torch.__version__)\n",
    "\n",
    "    \n",
    "    print(\"gpu available:\", torch.cuda.is_available())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(torch.cuda.get_device_name(i))\n",
    "        \n",
    "def download_data():\n",
    "    dataset1 = datasets.MNIST('../data', train= True, download=True)\n",
    "    dataset2 = datasets.MNIST('../data', train=False, download=True)\n",
    "    \n",
    "def benchmark():\n",
    "    list_env()\n",
    "    if torch.cuda.is_available():        \n",
    "        print(\"\\ndevice=gpu\")\n",
    "        psutil.cpu_percent(percpu=True)\n",
    "        argv = sys.argv\n",
    "        sys.argv = [\"\", \"--epochs\", \"1\"]\n",
    "        %timeit -r1 -n1 main()\n",
    "        sys.argv = argv\n",
    "        print(\"cpu-percent:\", psutil.cpu_percent(percpu=True))\n",
    "        \n",
    "    print(\"\\ndevice=cpu\")\n",
    "    psutil.cpu_percent(percpu=True)\n",
    "    argv = sys.argv\n",
    "    sys.argv = [\"\", \"--epochs\",\"1\", \"--no-cuda\"]\n",
    "    %timeit -r1 -n1 main()\n",
    "    sys.argv = argv\n",
    "    print(\"cpu-percent:\", psutil.cpu_percent(percpu=True))\n",
    "    \n",
    "download_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESKTOP-U61NOQ2\n",
      "Windows-10-10.0.18362-SP0\n",
      "Intel64 Family 6 Model 142 Stepping 10, GenuineIntel\n",
      "cpu-count 8\n",
      "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
      "1.7.1\n",
      "gpu available: True\n",
      "GeForce MX250\n",
      "\n",
      "device=gpu\n",
      "Test set: Average loss: 0.0447, Accuracy: 9859/10000 (99%)\n",
      "19.9 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "cpu-percent: [61.0, 3.8, 14.6, 10.0, 19.3, 5.3, 10.4, 80.9]\n",
      "\n",
      "device=cpu\n",
      "Test set: Average loss: 0.0460, Accuracy: 9853/10000 (99%)\n",
      "2min 20s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "cpu-percent: [55.3, 51.4, 61.3, 65.7, 59.0, 62.6, 72.1, 77.7]\n"
     ]
    }
   ],
   "source": [
    "benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liangh-PC\n",
      "Windows-7-6.1.7601-SP1\n",
      "Intel64 Family 6 Model 94 Stepping 3, GenuineIntel\n",
      "cpu-count 8\n",
      "3.6.7 |Anaconda, Inc.| (default, Dec 10 2018, 20:35:02) [MSC v.1915 64 bit (AMD64)]\n",
      "1.7.1\n",
      "gpu available: False\n",
      "\n",
      "device=cpu\n",
      "Test set: Average loss: 0.0471, Accuracy: 9844/10000 (98%)\n",
      "1min 34s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "cpu-percent: [43.7, 87.4, 70.8, 46.9, 66.9, 45.0, 53.9, 38.3]\n"
     ]
    }
   ],
   "source": [
    "benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## my notebook 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESKTOP-JPH34GE\n",
      "Windows-10-10.0.17134-SP0\n",
      "Intel64 Family 6 Model 60 Stepping 3, GenuineIntel\n",
      "cpu-count 8\n",
      "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
      "1.7.1\n",
      "gpu available: True\n",
      "GeForce GTX 850M\n",
      "\n",
      "device=gpu\n",
      "Test set: Average loss: 0.0441, Accuracy: 9860/10000 (99%)\n",
      "31.8 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "cpu-percent: [33.8, 14.1, 23.1, 8.2, 12.1, 9.7, 5.4, 61.7]\n",
      "\n",
      "device=cpu\n",
      "Test set: Average loss: 0.0460, Accuracy: 9853/10000 (99%)\n",
      "2min 44s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n",
      "cpu-percent: [65.4, 45.8, 61.2, 59.0, 53.5, 59.0, 55.6, 69.9]\n"
     ]
    }
   ],
   "source": [
    "benchmark()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "24",
    "lenType": "16",
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
