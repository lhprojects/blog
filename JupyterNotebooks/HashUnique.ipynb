{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#hash_unique.unique-is-faster-than-numpy.unique-and-pandas.unique\" data-toc-modified-id=\"hash_unique.unique-is-faster-than-numpy.unique-and-pandas.unique-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span><code>hash_unique.unique</code> is faster than <code>numpy.unique</code> and <code>pandas.unique</code></a></span></li><li><span><a href=\"#implementation\" data-toc-modified-id=\"implementation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>implementation</a></span></li><li><span><a href=\"#Simple-test\" data-toc-modified-id=\"Simple-test-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Simple test</a></span></li><li><span><a href=\"#Check-hash-quality\" data-toc-modified-id=\"Check-hash-quality-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Check hash quality</a></span></li><li><span><a href=\"#performance-for-tiny-array\" data-toc-modified-id=\"performance-for-tiny-array-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>performance for tiny array</a></span></li><li><span><a href=\"#performance-for-medium-array\" data-toc-modified-id=\"performance-for-medium-array-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>performance for medium array</a></span></li><li><span><a href=\"#performance-for-large-array\" data-toc-modified-id=\"performance-for-large-array-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>performance for large array</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `hash_unique.unique` is faster than `numpy.unique` and `pandas.unique`\n",
    "\n",
    "for random array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hash_unique.py\n"
     ]
    }
   ],
   "source": [
    "%%file hash_unique.py\n",
    "\n",
    "# don't remove the follows for your use\n",
    "# Author: https://lhprojects.github.io/blog/\n",
    "# don't remove above lines\n",
    "\n",
    "import numba\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def unique(ar, weights = None, return_counts = False, return_hit_accuracy = False):\n",
    "    '''\n",
    "    ar: integer array\n",
    "    return:\n",
    "        uniques [, uniques_counts] [, hit_accuracy]\n",
    "        hit_accuracy should be close to 1. unless\n",
    "        the hash function has some quality problem\n",
    "    '''\n",
    "    if weights is not None:\n",
    "        f,s,t = unique_impl64_w(ar, weights)\n",
    "    else:\n",
    "        f,s,t = unique_impl64(ar)\n",
    "        \n",
    "    if return_counts and return_hit_accuracy:\n",
    "        return f, s, t\n",
    "    elif return_counts:\n",
    "        return f, s\n",
    "    elif return_hit_accuracy:\n",
    "        return f, t\n",
    "    else:\n",
    "        return f\n",
    "    \n",
    "def unique32(ar, weights = None, return_counts = False, return_hit_accuracy = False):\n",
    "    '''\n",
    "    ar: integer array\n",
    "    NOTE: upper 32 bits ignored for hash function\n",
    "    return:\n",
    "        uniques [, uniques_counts] [, hit_accuracy]\n",
    "        hit_accuracy should be close to 1. unless\n",
    "        the hash function has some quality problem\n",
    "    '''\n",
    "    \n",
    "    if weights is not None:\n",
    "        f,s,t = unique_impl32_w(ar, weights)\n",
    "    else:\n",
    "        f,s,t = unique_impl32(ar)\n",
    "    \n",
    "    if return_counts and return_hit_accuracy:\n",
    "        return f, s, t\n",
    "    elif return_counts:\n",
    "        return f, s\n",
    "    elif return_hit_accuracy:\n",
    "        return f, t\n",
    "    else:\n",
    "        return f\n",
    "\n",
    "@numba.njit\n",
    "def length(l):\n",
    "    l = int(np.ceil(np.log2(l)))\n",
    "    # 4*len(ar) > l > 2*len(ar)\n",
    "    l = 2 << l\n",
    "    return l\n",
    "\n",
    "@numba.njit\n",
    "def FNV_1_64(v):\n",
    "    # https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function\n",
    "    \n",
    "    byte_mask = np.uint64(255)\n",
    "    bs = np.uint64(v)\n",
    "    x1 = (bs) & byte_mask\n",
    "    x2 = (bs>>8) &byte_mask\n",
    "    x3 = (bs>>16) &byte_mask\n",
    "    x4 = (bs>>24) &byte_mask\n",
    "    x5= (bs>>32) &byte_mask\n",
    "    x6= (bs>>40) &byte_mask\n",
    "    x7= (bs>>48) &byte_mask\n",
    "    x8= (bs>>56) &byte_mask\n",
    "\n",
    "    FNV_primer = np.uint64(1099511628211)\n",
    "    FNV_bias = np.uint64(14695981039346656037)\n",
    "    h = FNV_bias\n",
    "    h = h*FNV_primer\n",
    "    h = h^x1\n",
    "    h = h*FNV_primer\n",
    "    h = h^x2\n",
    "    h = h*FNV_primer\n",
    "    h = h^x3\n",
    "    h = h*FNV_primer\n",
    "    h = h^x4\n",
    "    h = h*FNV_primer\n",
    "    h = h^x5\n",
    "    h = h*FNV_primer\n",
    "    h = h^x6\n",
    "    h = h*FNV_primer\n",
    "    h = h^x7\n",
    "    h = h*FNV_primer\n",
    "    h = h^x8\n",
    "    return h\n",
    "\n",
    "@numba.njit\n",
    "def FNV_1_32(v):\n",
    "    \n",
    "    byte_mask = np.uint64(255)\n",
    "    bs = np.uint64(v)\n",
    "    x1 = (bs) & byte_mask\n",
    "    x2 = (bs>>8) &byte_mask\n",
    "    x3 = (bs>>16) &byte_mask\n",
    "    x4 = (bs>>24) &byte_mask\n",
    "\n",
    "    FNV_primer = np.uint64(1099511628211)\n",
    "    FNV_bias = np.uint64(14695981039346656037)\n",
    "    h = FNV_bias\n",
    "    h = h*FNV_primer\n",
    "    h = h^x1\n",
    "    h = h*FNV_primer\n",
    "    h = h^x2\n",
    "    h = h*FNV_primer\n",
    "    h = h^x3\n",
    "    h = h*FNV_primer\n",
    "    h = h^x4\n",
    "    return h\n",
    "\n",
    "@numba.njit\n",
    "def make_hash_table(ar):\n",
    "    l = length(len(ar))    \n",
    "    mask = l - 1      \n",
    "    \n",
    "    uniques = np.empty(l, dtype=ar.dtype)\n",
    "    uniques_cnt = np.zeros(l, dtype=np.int_)\n",
    "    return uniques, uniques_cnt, l, mask\n",
    "\n",
    "@numba.njit\n",
    "def make_hash_table_w(ar):\n",
    "    l = length(len(ar))    \n",
    "    mask = l - 1      \n",
    "    \n",
    "    uniques = np.empty(l, dtype=ar.dtype)\n",
    "    uniques_cnt = np.zeros(l, dtype=np.int_)\n",
    "    uniques_weight = np.zeros(l, dtype=np.float_)\n",
    "    return uniques, uniques_cnt, uniques_weight, l, mask\n",
    "\n",
    "@numba.njit\n",
    "def set_item(uniques, uniques_cnt, mask, h, v, total, miss_hits, weight):\n",
    "        \n",
    "    index = (h & mask)\n",
    "\n",
    "    # open address hash\n",
    "    # great cache performance\n",
    "    while True:\n",
    "        if uniques_cnt[index] == 0:\n",
    "            # insert new\n",
    "            uniques_cnt[index] += weight\n",
    "            uniques[index] = v\n",
    "            total += 1\n",
    "            break\n",
    "        elif uniques[index] == v:\n",
    "            uniques_cnt[index] += weight\n",
    "            break\n",
    "        else:\n",
    "            miss_hits += 1\n",
    "            index += 1\n",
    "            index = index & mask\n",
    "    return total, miss_hits\n",
    "    \n",
    "@numba.njit\n",
    "def set_item_w(uniques, uniques_cnt, uniques_weights, mask, h, v, w, total, miss_hits):\n",
    "        \n",
    "    index = (h & mask)\n",
    "\n",
    "    # open address hash\n",
    "    # great cache performance\n",
    "    while True:\n",
    "        if uniques_cnt[index] == 0:\n",
    "            # insert new\n",
    "            uniques_cnt[index] += 1\n",
    "            uniques_weights[index] += w\n",
    "            uniques[index] = v\n",
    "            total += 1\n",
    "            break\n",
    "        elif uniques[index] == v:\n",
    "            uniques_cnt[index] += 1\n",
    "            uniques_weights[index] += w\n",
    "            break\n",
    "        else:\n",
    "            miss_hits += 1\n",
    "            index += 1\n",
    "            index = index & mask\n",
    "    return total, miss_hits\n",
    "    \n",
    "@numba.njit\n",
    "def concrete(ar, uniques, uniques_cnt, l, total):\n",
    "    # flush the results in a concrete array            \n",
    "    uniques_ = np.empty(total, dtype=ar.dtype)\n",
    "    uniques_cnt_ = np.empty(total, dtype=np.int_)\n",
    "    t = 0\n",
    "    for i in range(l):\n",
    "        if uniques_cnt[i] > 0:\n",
    "            uniques_[t] = uniques[i]\n",
    "            uniques_cnt_[t] = uniques_cnt[i]\n",
    "            t += 1\n",
    "    return uniques_, uniques_cnt_\n",
    "\n",
    "@numba.njit\n",
    "def concrete_w(ar, uniques, uniques_cnt, uniques_weight, l, total):\n",
    "    # flush the results in a concrete array            \n",
    "    uniques_ = np.empty(total, dtype=ar.dtype)\n",
    "    uniques_cnt_ = np.empty(total, dtype=np.int_)\n",
    "    uniques_weight_ = np.empty(total, dtype=np.float_)\n",
    "    t = 0\n",
    "    for i in range(l):\n",
    "        if uniques_cnt[i] > 0:\n",
    "            uniques_[t] = uniques[i]\n",
    "            uniques_cnt_[t] = uniques_cnt[i]\n",
    "            uniques_weight_[t] = uniques_weight[i]\n",
    "            t += 1\n",
    "    return uniques_, uniques_cnt_, uniques_weight_\n",
    "\n",
    "def unique_factor(hash_function):\n",
    "    \n",
    "    @numba.njit\n",
    "    def unique_impl(ar):\n",
    "\n",
    "        uniques, uniques_cnt, l, mask = make_hash_table(ar)\n",
    "        total = 0    \n",
    "        miss_hits = 0    \n",
    "\n",
    "        for v in ar:\n",
    "            h = hash_function(v)\n",
    "            total, miss_hits = set_item(uniques, uniques_cnt, mask, h, v, total, miss_hits, 1)\n",
    "\n",
    "        uniques_, uniques_cnt_ = concrete(ar, uniques, uniques_cnt, l, total)\n",
    "\n",
    "        if len(ar) == 0:\n",
    "            hit_accuracy = np.nan\n",
    "        else:\n",
    "            hit_accuracy = len(ar)/((len(ar) + miss_hits)*1.0)\n",
    "        return uniques_, uniques_cnt_, hit_accuracy\n",
    "    \n",
    "    return unique_impl\n",
    "\n",
    "\n",
    "def unique_factor_w(hash_function):\n",
    "    \n",
    "    @numba.njit\n",
    "    def unique_impl_w(ar, weights):\n",
    "\n",
    "        uniques, uniques_cnt, uniques_weight, l, mask = make_hash_table_w(ar)\n",
    "        total = 0    \n",
    "        miss_hits = 0    \n",
    "\n",
    "        for i, v in enumerate(ar):\n",
    "            h = hash_function(v)\n",
    "            w = weights[i]\n",
    "            total, miss_hits = set_item_w(uniques, uniques_cnt, uniques_weight, mask, h, v, w, total, miss_hits)\n",
    "            \n",
    "        uniques_, uniques_cnt_, uniques_weight_ = concrete_w(ar, uniques, uniques_cnt, uniques_weight, l, total)\n",
    "\n",
    "        if len(ar) == 0:\n",
    "            hit_accuracy = np.nan\n",
    "        else:\n",
    "            hit_accuracy = len(ar)/((len(ar) + miss_hits)*1.0)\n",
    "        return uniques_, uniques_weight_, hit_accuracy\n",
    "    \n",
    "    return unique_impl_w\n",
    "\n",
    "unique_impl64 = unique_factor(FNV_1_64)\n",
    "unique_impl32 = unique_factor(FNV_1_32)\n",
    "unique_impl64_w = unique_factor_w(FNV_1_64)\n",
    "unique_impl32_w = unique_factor_w(FNV_1_32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2) (3, 1) (4, 1) (5, 1) (6, 2) (7, 3) \n",
      "(0, 2) (3, 1) (4, 1) (5, 1) (6, 2) (7, 3) \n"
     ]
    }
   ],
   "source": [
    "import hash_unique\n",
    "import pandas\n",
    "import numpy as np\n",
    "import imp\n",
    "imp.reload(hash_unique)\n",
    "\n",
    "x = np.random.randint(10, size=10)\n",
    "\n",
    "u, c = np.unique(x, return_counts=True)\n",
    "\n",
    "hash_u, hash_c = hash_unique.unique(x, return_counts=True)\n",
    "index = np.argsort(hash_u)\n",
    "hash_u = hash_u[index]\n",
    "hash_c = hash_c[index]\n",
    "\n",
    "\n",
    "for u_, c_ in zip(u, c):\n",
    "    print((u_, c_), end=\" \")\n",
    "print()\n",
    "\n",
    "for u_, c_ in zip(hash_u, hash_c):\n",
    "    print((u_, c_), end=\" \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check hash quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.950\n",
      "4329\n",
      "4065\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(5000, size=10000)\n",
    "f, hit_accuracy = hash_unique.unique(x, return_hit_accuracy=True)\n",
    "\n",
    "length = hash_unique.length(len(x))\n",
    "y = np.array([hash_unique.FNV_1_64(v) for v in x], dtype=np.uint64) & np.uint64(length - 1)\n",
    "\n",
    "print(\"%.3f\"%hit_accuracy)\n",
    "print(len(set(x)))\n",
    "print(len(set(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performance for tiny array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.1 µs ± 126 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "1.39 µs ± 5.25 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "The slowest run took 4.53 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "2.46 µs ± 1.78 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "22.6 µs ± 2.04 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(5, size=10)\n",
    "%timeit np.unique(x, return_counts=True)\n",
    "%timeit hash_unique.unique(x, return_counts=True)\n",
    "%timeit hash_unique.unique32(x, return_counts=True)\n",
    "%timeit pandas.unique(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.8 µs ± 26.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "1.42 µs ± 4.92 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "1.42 µs ± 3.34 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "24.1 µs ± 90 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(5, size=10)\n",
    "%timeit np.unique(x, return_counts=True)\n",
    "%timeit hash_unique.unique(x, return_counts=True)\n",
    "%timeit hash_unique.unique32(x, return_counts=True)\n",
    "%timeit pandas.unique(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performance for medium array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 µs ± 2.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "111 µs ± 384 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "82.4 µs ± 643 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "149 µs ± 13.2 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "102 µs ± 462 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "123 µs ± 1.36 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(5000, size=10000)\n",
    "%timeit np.unique(x, return_counts=True)\n",
    "%timeit hash_unique.unique(x, return_counts=True)\n",
    "%timeit hash_unique.unique32(x, return_counts=True)\n",
    "weights = np.ones(len(x), dtype=np.float)\n",
    "%timeit hash_unique.unique(x, weights = weights, return_counts=True)\n",
    "%timeit hash_unique.unique32(x, weights = weights, return_counts=True)\n",
    "%timeit pandas.unique(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 µs ± 670 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "99.8 µs ± 294 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "64.9 µs ± 399 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "122 µs ± 382 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(10000,0,-1)\n",
    "%timeit np.unique(x, return_counts=True)\n",
    "%timeit hash_unique.unique(x)\n",
    "%timeit hash_unique.unique32(x, return_counts=True)\n",
    "%timeit pandas.unique(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.6 µs ± 732 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "98.5 µs ± 765 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "65.4 µs ± 408 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "123 µs ± 703 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = np.arange(0,10000)\n",
    "%timeit np.unique(x, return_counts=True)\n",
    "%timeit hash_unique.unique(x)\n",
    "%timeit hash_unique.unique32(x)\n",
    "%timeit pandas.unique(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performance for large array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705 ms ± 3.66 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "536 ms ± 11.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "407 ms ± 5.21 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "723 ms ± 29.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "576 ms ± 7.37 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "590 ms ± 26.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(10000000//2, size=10000000)\n",
    "%timeit np.unique(x, return_counts=True)\n",
    "%timeit hash_unique.unique(x, return_counts=True)\n",
    "%timeit hash_unique.unique32(x, return_counts=True)\n",
    "weights = np.ones(len(x), dtype=np.float)\n",
    "%timeit hash_unique.unique(x, weights = weights, return_counts=True)\n",
    "%timeit hash_unique.unique32(x, weights = weights, return_counts=True)\n",
    "%timeit pandas.unique(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
