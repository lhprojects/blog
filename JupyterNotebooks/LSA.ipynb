{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#潜在语义模型\" data-toc-modified-id=\"潜在语义模型-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>潜在语义模型</a></span></li><li><span><a href=\"#潜在语义分析（LSA）\" data-toc-modified-id=\"潜在语义分析（LSA）-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>潜在语义分析（LSA）</a></span><ul class=\"toc-item\"><li><span><a href=\"#玩具级数据集-（Toy-dataset）\" data-toc-modified-id=\"玩具级数据集-（Toy-dataset）-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>玩具级数据集 （Toy dataset）</a></span></li><li><span><a href=\"#字母表-(Alphabet)\" data-toc-modified-id=\"字母表-(Alphabet)-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>字母表 (Alphabet)</a></span></li><li><span><a href=\"#分词-(Parse)\" data-toc-modified-id=\"分词-(Parse)-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>分词 (Parse)</a></span><ul class=\"toc-item\"><li><span><a href=\"#test-split\" data-toc-modified-id=\"test-split-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>test split</a></span></li></ul></li><li><span><a href=\"#建立结构化数据集-(Structured-documents)\" data-toc-modified-id=\"建立结构化数据集-(Structured-documents)-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>建立结构化数据集 (Structured documents)</a></span></li><li><span><a href=\"#我们使用频率逆文档来表示term-document矩阵。(TFIDF)\" data-toc-modified-id=\"我们使用频率逆文档来表示term-document矩阵。(TFIDF)-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>我们使用频率逆文档来表示term-document矩阵。(TFIDF)</a></span></li><li><span><a href=\"#奇异值分解（SVD）\" data-toc-modified-id=\"奇异值分解（SVD）-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>奇异值分解（SVD）</a></span></li><li><span><a href=\"#非负矩阵分解\" data-toc-modified-id=\"非负矩阵分解-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>非负矩阵分解</a></span></li></ul></li><li><span><a href=\"#概率潜在语义分析(pLSA)\" data-toc-modified-id=\"概率潜在语义分析(pLSA)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>概率潜在语义分析(pLSA)</a></span></li><li><span><a href=\"#潜在狄利克雷分配(LDA)\" data-toc-modified-id=\"潜在狄利克雷分配(LDA)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>潜在狄利克雷分配(LDA)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gibbs抽样\" data-toc-modified-id=\"Gibbs抽样-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Gibbs抽样</a></span><ul class=\"toc-item\"><li><span><a href=\"#初始化\" data-toc-modified-id=\"初始化-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>初始化</a></span></li><li><span><a href=\"#训练\" data-toc-modified-id=\"训练-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>训练</a></span></li></ul></li></ul></li><li><span><a href=\"#20新闻组数据集\" data-toc-modified-id=\"20新闻组数据集-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>20新闻组数据集</a></span><ul class=\"toc-item\"><li><span><a href=\"#下载停止词汇\" data-toc-modified-id=\"下载停止词汇-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>下载停止词汇</a></span></li><li><span><a href=\"#20新闻组语料库\" data-toc-modified-id=\"20新闻组语料库-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>20新闻组语料库</a></span></li><li><span><a href=\"#预处理\" data-toc-modified-id=\"预处理-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>预处理</a></span></li><li><span><a href=\"#结构化数据-(Structured-data)\" data-toc-modified-id=\"结构化数据-(Structured-data)-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>结构化数据 (Structured data)</a></span></li><li><span><a href=\"#SVD_LSA\" data-toc-modified-id=\"SVD_LSA-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>SVD_LSA</a></span></li><li><span><a href=\"#NMF_LSA\" data-toc-modified-id=\"NMF_LSA-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>NMF_LSA</a></span></li><li><span><a href=\"#pLSA\" data-toc-modified-id=\"pLSA-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>pLSA</a></span></li><li><span><a href=\"#LDA\" data-toc-modified-id=\"LDA-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span>LDA</a></span></li></ul></li><li><span><a href=\"#Bakcups\" data-toc-modified-id=\"Bakcups-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Bakcups</a></span><ul class=\"toc-item\"><li><span><a href=\"#随机梯度下降-(Stochastic-gradient-descent)\" data-toc-modified-id=\"随机梯度下降-(Stochastic-gradient-descent)-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>随机梯度下降 (Stochastic gradient descent)</a></span><ul class=\"toc-item\"><li><span><a href=\"#the-pLSA\" data-toc-modified-id=\"the-pLSA-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>the pLSA</a></span></li><li><span><a href=\"#the-LDA\" data-toc-modified-id=\"the-LDA-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>the LDA</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 潜在语义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主要参考赵航的书"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import string\n",
    "from IPython import display\n",
    "import pandas\n",
    "\n",
    "word_elements = set(string.ascii_letters + string.digits + \"_\")\n",
    "    \n",
    "def document_to_terms(doc, stop_words={}):\n",
    "    '''\n",
    "    split a document to a set of words\n",
    "    '''\n",
    "    if type(stop_words) is list:\n",
    "        stop_words = set(stop_words)\n",
    "        \n",
    "    doc_terms=[]    \n",
    "    begin=0\n",
    "    end=0\n",
    "    for char in doc:\n",
    "        if char in word_elements:\n",
    "            end += 1\n",
    "        else:\n",
    "            if end > begin:\n",
    "                word = doc[begin:end]\n",
    "                if word.lower() not in stop_words:\n",
    "                    doc_terms.append(word)\n",
    "            end += 1\n",
    "            begin = end\n",
    "\n",
    "    if end > begin:\n",
    "        word = doc[begin:end]        \n",
    "        if word.lower() not in stop_words:\n",
    "            doc_terms.append(word)\n",
    "            \n",
    "    return doc_terms\n",
    "\n",
    "\n",
    "class StructuredDocuments:\n",
    "    \n",
    "    def set_documents(self, documents, stop_words=[], threshold = 0):\n",
    "        \n",
    "        \n",
    "        \n",
    "        terms_count = { }\n",
    "        stop_words_set = set(stop_words)\n",
    "        for doc in documents:\n",
    "            doc_terms = document_to_terms(doc, stop_words=stop_words_set)\n",
    "            \n",
    "            for term in doc_terms:\n",
    "                lower_term = term.lower()\n",
    "                if lower_term not in terms_count:\n",
    "                    terms_count[lower_term] = 0\n",
    "                terms_count[lower_term] += 1\n",
    "        \n",
    "        for term in terms_count:\n",
    "            n = terms_count[term]\n",
    "            if n < threshold:\n",
    "                stop_words_set.add(term)\n",
    "                \n",
    "                \n",
    "        terms = []\n",
    "        terms_set = set()\n",
    "        term_to_index = { }\n",
    "        docs_terms = []\n",
    "        docs_term_indices = []\n",
    "                \n",
    "        \n",
    "        for doc in documents:\n",
    "            doc_terms = document_to_terms(doc, stop_words=stop_words_set)\n",
    "            # numpy array\n",
    "            doc_term_indices = np.zeros(len(doc_terms), dtype=np.int)\n",
    "            \n",
    "            for n, term in enumerate(doc_terms):\n",
    "                lower_term = term.lower()\n",
    "                if lower_term not in terms_set:\n",
    "                    term_to_index[lower_term] = len(terms)\n",
    "                    terms_set.add(lower_term)\n",
    "                    terms.append(lower_term)\n",
    "                doc_term_indices[n] = term_to_index[lower_term]\n",
    "                    \n",
    "            docs_terms.append(doc_terms)            \n",
    "            docs_term_indices.append(doc_term_indices)\n",
    "                    \n",
    "        self.documents_ = documents\n",
    "        self.terms_ = terms\n",
    "        self.terms_set_ = terms_set\n",
    "        self.term_to_index_ = term_to_index\n",
    "        self.docs_terms_ = docs_terms\n",
    "        \n",
    "        self.n_terms = len(terms)\n",
    "        self.n_documents = len(documents)\n",
    "        self.docs_term_indices = docs_term_indices\n",
    "        \n",
    "        self.stop_words_set = stop_words_set\n",
    "    \n",
    "    def print_info(self, n = None, n_shown_terms = 20):\n",
    "        sdocs = self\n",
    "        print(\"%d terms found in %d documents.\"%(len(sdocs.terms_), len(sdocs.documents_)))\n",
    "        \n",
    "        print(\"terms:\", [term for term in itertools.islice(sdocs.terms_, n_shown_terms)])\n",
    "        print(\"terms_set:\", [term for term in itertools.islice(sdocs.terms_set_, n_shown_terms)])\n",
    "        \n",
    "        print(\"term_to_index:\", [(term,sdocs.term_to_index_[term]) for term in itertools.islice(sdocs.term_to_index_, n)])\n",
    "        print(\"docs_terms:\", [ [word for word in itertools.islice(term, n)]\\\n",
    "                                  for term in itertools.islice(sdocs.docs_terms_, n)])\n",
    "        print(\"docs_term_indices:\", [[idx for idx in itertools.islice(term, n)]\\\n",
    "                                for term in itertools.islice(sdocs.docs_term_indices, n)])\n",
    "\n",
    "class LSABase:\n",
    "    \n",
    "    def set_documents(self, documents, stop_words=[\"\"], threshold = 0):\n",
    "        sdocs = StructuredDocuments()\n",
    "        sdocs.set_documents(documents, stop_words=stop_words, threshold = threshold)\n",
    "        self.set_structured_documents(sdocs)\n",
    "        \n",
    "    def set_structured_documents(self, sdocs):\n",
    "            \n",
    "        self.structured_documents = sdocs\n",
    "        self.n_terms = sdocs.n_terms\n",
    "        self.n_documents = sdocs.n_documents\n",
    "        self.docs_term_indices = sdocs.docs_term_indices\n",
    "        \n",
    "        \n",
    "    # set(_structured)_documents first\n",
    "    def cal_term_doc_mat(self, metric=\"TFIDF\"):\n",
    "        # terms-documents matrix\n",
    "        \n",
    "        n_terms = self.n_terms\n",
    "        n_documents = self.n_documents\n",
    "        docs_term_indices = self.docs_term_indices\n",
    "        \n",
    "        tf_j = np.zeros(n_documents)  # number of terms in document j \n",
    "        df_i = np.zeros(n_terms)      # number of documents which contain term i\n",
    "        df = n_documents\n",
    "        \n",
    "        tf_ij = np.zeros((n_terms, n_documents))\n",
    "\n",
    "        for j, doc_term_indices in enumerate(docs_term_indices):\n",
    "            \n",
    "            tf_j[j] = len(doc_term_indices)\n",
    "\n",
    "            add_to_df_i = np.zeros(n_terms)\n",
    "            \n",
    "            for i in doc_term_indices:                \n",
    "                \n",
    "                tf_ij[i,j] += 1\n",
    "                \n",
    "                add_to_df_i[i] = 1\n",
    "\n",
    "            df_i += add_to_df_i\n",
    "\n",
    "        \n",
    "            \n",
    "        if metric==\"TFIDF\":\n",
    "            \n",
    "            IDF = np.log(df / np.maximum(df_i, 1))\n",
    "            # X in hang's book\n",
    "        \n",
    "            self.IDF = IDF\n",
    "            \n",
    "            # in case empty document\n",
    "            tf_ij /= np.maximum(tf_j, 1)\n",
    "            self.term_doc_mat = tf_ij / IDF[:,np.newaxis]\n",
    "            \n",
    "        elif metric==\"TF\":\n",
    "            \n",
    "            # in case empty document\n",
    "            tf_ij /= np.maximum(tf_j, 1)\n",
    "            self.term_doc_mat = tf_ij\n",
    "        elif metric==\"TAF\":\n",
    "            \n",
    "            # in case empty document\n",
    "            self.term_doc_mat = tf_ij\n",
    "            \n",
    "                    \n",
    "        self.tf_j = tf_j\n",
    "        self.df_i = df_i\n",
    "        self.df = df\n",
    "\n",
    "    \n",
    "    \n",
    "    def print_mat(self, **kargs):\n",
    "        print_mat(self, **kargs)\n",
    "\n",
    "    def print_doc_doc_similarity(self):\n",
    "        print_doc_doc_similarity(self)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def print_mat(lsa, max_topics=None, max_terms=None, max_docs=None, topic_names=None):\n",
    "    #print_doc_topic_mat(lsa, max_topics=max_topics, topic_names=topic_names)\n",
    "    \n",
    "    \n",
    "    print_doc_vectors(lsa, max_topics=max_topics, max_docs=max_docs, topic_names=topic_names)\n",
    "    print_topic_vectors(lsa, max_topics=max_topics, max_terms=max_terms, topic_names=topic_names)\n",
    "              \n",
    "        \n",
    "def print_topic_vectors(lsa, max_topics = None, max_terms = None, topic_names=None):\n",
    "    if max_topics is None:\n",
    "        max_topics = 100\n",
    "    if max_terms is None:\n",
    "        max_terms = 10\n",
    "    \n",
    "    term_topic_mat = lsa.term_topic_mat\n",
    "\n",
    "    n_terms = lsa.n_terms\n",
    "\n",
    "    terms = lsa.structured_documents.terms_\n",
    "    ntopics = term_topic_mat.shape[1]\n",
    "\n",
    "    ntopics = min(max_topics, ntopics)\n",
    "    n_terms = min(max_terms, n_terms)\n",
    "    \n",
    "    \n",
    "    columns = [\"topic\"] + [\"composition %d\"%t for t in range(n_terms)]\n",
    "    data = []\n",
    "    for t in range(ntopics):\n",
    "        row = []\n",
    "        if topic_names is None:\n",
    "            row.append(t)\n",
    "        else:\n",
    "            row.append(topic_names[t])\n",
    "                    \n",
    "        index = np.argsort(-np.abs(term_topic_mat[:,t]))\n",
    "\n",
    "        for j in range(n_terms):\n",
    "            i = index[j]\n",
    "            row.append((terms[i], \"%.1E\"%term_topic_mat[i, t]))            \n",
    "        data.append(row)\n",
    "        \n",
    "    df = pandas.DataFrame(data=data, columns=columns)\n",
    "    display.display(df)\n",
    "        \n",
    "def print_doc_vectors(lsa, max_topics = None, max_docs = None, topic_names=None):\n",
    "    if max_docs is None:\n",
    "        max_docs = 100\n",
    "    if max_topics is None:\n",
    "        max_topics = 10\n",
    "    \n",
    "    topic_doc_mat = lsa.topic_doc_mat\n",
    "\n",
    "    n_documents = lsa.n_documents\n",
    "    ntopics = topic_doc_mat.shape[0]\n",
    "\n",
    "    ntopics = min(max_topics, ntopics)\n",
    "    n_documents = min(max_docs, n_documents)\n",
    "    \n",
    "    data=[]\n",
    "    columns = [\"document\"] + [\"composition %d\"%t for t in range(ntopics)]\n",
    "    for d in range(n_documents):\n",
    "                     \n",
    "        row = []\n",
    "        row.append(d)\n",
    "        \n",
    "        index = np.argsort(-np.abs(topic_doc_mat[:,d]))\n",
    "\n",
    "        for j in range(ntopics):        \n",
    "            t = index[j]         \n",
    "            \n",
    "            if topic_names is None:\n",
    "                tname = t\n",
    "            else:\n",
    "                tname = topic_names[t]\n",
    "                \n",
    "            row.append((tname,\"%.1E\"%topic_doc_mat[t, d]))\n",
    "        data.append(row)\n",
    "            \n",
    "    df = pandas.DataFrame(data=data, columns=columns)\n",
    "    display.display(df)\n",
    "\n",
    "            \n",
    "    \n",
    "def print_doc_topic_mat(lsa, max_topics = None, topic_names=None, max_docs=None):\n",
    "    if max_topics is None:\n",
    "        max_topics = 20\n",
    "    if max_docs is None:\n",
    "        max_docs = 15\n",
    "        \n",
    "    term_topic_mat = lsa.term_topic_mat\n",
    "    topic_doc_mat = lsa.topic_doc_mat\n",
    "\n",
    "    n_documents = lsa.n_documents\n",
    "    n_terms = lsa.n_terms\n",
    "\n",
    "    terms = lsa.structured_documents.terms_\n",
    "    ntopics = topic_doc_mat.shape[0]    \n",
    "    \n",
    "    ntopics = min(ntopics, max_topics)\n",
    "    n_documents = min(n_documents, max_docs)\n",
    "\n",
    "    print(\"%8s\"%\"document\", end=\"\")\n",
    "    for t in range(ntopics):\n",
    "        if topic_names is None:\n",
    "            tname = \"topic%d\"%t\n",
    "        else:\n",
    "            tname = topic_names[t]\n",
    "             \n",
    "        ts = \" %10s\"%tname\n",
    "        \n",
    "        print(ts, end=\"\")\n",
    "    print()\n",
    "\n",
    "    for i in range(n_documents):\n",
    "        print(\"%8d\"%i, end=\"\")\n",
    "        for t in range(ntopics):\n",
    "            print(\" %+.1e\"%topic_doc_mat[t, i], end=\"\")\n",
    "        print()\n",
    "\n",
    "    print()\n",
    "    \n",
    "\n",
    "        \n",
    "class SVD_LSA(LSABase):\n",
    "                        \n",
    "    def topic_decompose(self, ntopics, term_weight = \"TFIDF\"):       \n",
    "        self.cal_term_doc_mat( term_weight)\n",
    "            \n",
    "        U, S, VT = np.linalg.svd(self.term_doc_mat, full_matrices=False)\n",
    "        \n",
    "        U = U[:,:ntopics]\n",
    "        VT = VT[:ntopics,:]\n",
    "        S = S[:ntopics]\n",
    "        \n",
    "        self.U = U\n",
    "        self.S = S\n",
    "        self.VT = VT\n",
    "        self.term_topic_mat = U\n",
    "        self.topic_doc_mat = VT\n",
    "        self.ntopics = ntopics\n",
    "\n",
    "# non-negative matrix factorization\n",
    "def NMF(A, k, max_iters, seed = None, on_update=None):\n",
    "    # A = [m x n]\n",
    "    # W = [m x k]\n",
    "    # H = [k x n]\n",
    "    if seed is None:\n",
    "        seed = 0\n",
    "\n",
    "    m = A.shape[0]\n",
    "    n = A.shape[1]\n",
    "\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    W = rng.rand(m, k)\n",
    "    H = rng.rand(k, n)\n",
    "    \n",
    "    for i in range(max_iters):\n",
    "        Hold = H\n",
    "        Wold = W\n",
    "        # update imediately\n",
    "        #(k,n) =  (k,n) * { [(k,m) (m,n)] / [(k,m)(m,k)(k,n) + epsilon]}  }\n",
    "        H = H * ((W.T.dot(A)) / (W.T.dot(W).dot(H) + 1E-20))\n",
    "        # update imediately\n",
    "        #(k,n) =  (m,k) * { [(m,n) (n,k)] / [(m,k)(k,n)(n,k)]}\n",
    "        W = W * ((A.dot(H.transpose())) / (W.dot(H.dot(H.transpose())) + 1E-20))\n",
    "        \n",
    "        \n",
    "        # ad-hoc normalization\n",
    "        scaleW = W.sum(axis=0)\n",
    "        W = W / scaleW\n",
    "        H = scaleW[:,np.newaxis] * H\n",
    "        \n",
    "        if on_update is not None:\n",
    "            if on_update(i, H, W, Hold, Wold):\n",
    "                break\n",
    "\n",
    "    return W, H\n",
    "\n",
    "class NMF_LSA(LSABase):\n",
    "\n",
    "    \n",
    "        \n",
    "    def topic_decompose(self, ntopics, term_weight = \"TFIDF\", max_iters=200,  seed = None, on_update=None):    \n",
    "        self.cal_term_doc_mat(term_weight)\n",
    "            \n",
    "        n_terms = self.n_terms\n",
    "        n_documents = self.n_documents\n",
    "        term_doc_mat = self.term_doc_mat\n",
    " \n",
    "        W, H = NMF(term_doc_mat, ntopics, max_iters = max_iters, seed=seed, on_update=on_update)\n",
    "\n",
    "        #print(W)\n",
    "        #print(H)\n",
    "        \n",
    "        # ad-hoc normalization\n",
    "        if term_weight == \"TFIDF\":\n",
    "            #print(self.IDF)\n",
    "            #print(1./np.maximum(self.IDF, 1E-20))\n",
    "            scaleW = W.T.dot( 1./np.maximum(self.IDF, 1E-20) )\n",
    "        elif term_weight == \"TF\":\n",
    "            scaleW = W.sum(axis=0)\n",
    "                        \n",
    "        W = W/scaleW\n",
    "        H = H*scaleW[:,np.newaxis]\n",
    "                \n",
    "        #print(W)\n",
    "        #print(H)\n",
    "        \n",
    "        self.term_topic_mat = W\n",
    "        self.topic_doc_mat = H\n",
    "        self.W = W\n",
    "        self.H = H\n",
    "        self.ntopics = ntopics\n",
    "        \n",
    "class pLSA(LSABase):\n",
    "    \n",
    "    def topic_decompose(self, ntopics, max_iters=200, on_update=None, seed=0, alpha=1E-10):\n",
    "        \n",
    "        n_terms = self.n_terms\n",
    "        n_documents = self.n_documents\n",
    "        docs_term_indices = self.docs_term_indices\n",
    "        \n",
    "        rng = np.random.RandomState(seed=seed)\n",
    "        Pwz = rng.rand(n_terms, ntopics)\n",
    "        Pzd = rng.rand(ntopics, n_documents)\n",
    "        \n",
    "        Pwz = Pwz/Pwz.sum(axis=0)\n",
    "        \n",
    "        nwd = np.zeros((n_terms, n_documents)) # number of word `w` in document `d`\n",
    "\n",
    "        for j, doc_term_indices in enumerate(docs_term_indices):                \n",
    "            for i in doc_term_indices:                                \n",
    "                nwd[i,j] += 1\n",
    "  \n",
    "        # need for empty doc\n",
    "        nwd += alpha\n",
    "    \n",
    "        # total words in a doc\n",
    "        nd = nwd.sum(axis=0)\n",
    "        \n",
    "        Rwd = np.zeros((n_terms, n_documents))\n",
    "    \n",
    "        for i in range(max_iters):\n",
    "\n",
    "\n",
    "            np.dot(Pwz, Pzd, out=Rwd)\n",
    "            # we need to inverse the elements of this matrix\n",
    "            # add 1E-20 to avoid 0\n",
    "            np.add(Rwd, 1E-20, out=Rwd)\n",
    "            np.divide(nwd, Rwd, out=Rwd)\n",
    "            \n",
    "            Pwz_new = Rwd.dot(Pzd.T) * Pwz\n",
    "            Pwz_new = Pwz_new / Pwz_new.sum(axis=0)\n",
    "\n",
    "            Pzd_new = Pwz.T.dot(Rwd) * Pzd / nd\n",
    "                        \n",
    "            if on_update is not None:\n",
    "                if on_update(i, Pwz_new, Pzd_new, Pwz, Pzd):\n",
    "                    Pwz = Pwz_new\n",
    "                    Pzd = Pzd_new\n",
    "                    break\n",
    "\n",
    "            Pwz = Pwz_new\n",
    "            Pzd = Pzd_new\n",
    "            \n",
    "        self.term_topic_mat = Pwz\n",
    "        self.topic_doc_mat = Pzd\n",
    "        self.ntopics = ntopics\n",
    "        \n",
    "        \n",
    "class LDA(LSABase):\n",
    "        \n",
    "    # intialization randomly\n",
    "    # assign each word a topic\n",
    "    def initialize_randomly(self, ntopics):\n",
    "        n_documents = self.n_documents\n",
    "        n_terms = self.n_terms\n",
    "        \n",
    "        n_mk = np.zeros((n_documents, ntopics))\n",
    "        n_kv = np.zeros((ntopics, n_terms))\n",
    "        n_m = np.zeros(n_documents)\n",
    "        n_k = np.zeros(ntopics)\n",
    "\n",
    "        k_mp = n_documents*[None]\n",
    "        v_mp =  self.docs_term_indices\n",
    "        \n",
    "        #assert type(self.docs_term_indices[0]) is np.ndarray\n",
    "        \n",
    "        for m in range(n_documents):\n",
    "            length = len(v_mp[m])\n",
    "            \n",
    "            # generate len(doc_terms) random topics\n",
    "            k = np.random.randint(ntopics, size=length, dtype=np.int)\n",
    "            \n",
    "            # assign topic\n",
    "            k_mp[m] = k[:]\n",
    "            \n",
    "            # assign document length\n",
    "            n_m[m] = length\n",
    "            \n",
    "            for p in range(length):\n",
    "                v = v_mp[m][p]\n",
    "                n_mk[m, k] += 1 \n",
    "                n_kv[k,v] += 1 \n",
    "                n_k[k] += 1\n",
    "\n",
    "        self.n_mk = n_mk\n",
    "        self.n_kv = n_kv\n",
    "        self.n_m = n_m\n",
    "        self.n_k = n_k\n",
    "        self.k_mp = k_mp\n",
    "        self.v_mp = v_mp\n",
    "\n",
    "    def topic_decompose(self, ntopics, alpha=1, beta=1, warnming_iters=1000, estimate_iters=100, sampling_method=\"Gibbs\"):        \n",
    "        n_documents = self.n_documents\n",
    "        n_terms = self.n_terms\n",
    "        \n",
    "        self.initialize_randomly(ntopics)\n",
    "        \n",
    "        n_mk = self.n_mk\n",
    "        n_m = self.n_m\n",
    "        n_kv = self.n_kv\n",
    "        n_k = self.n_k\n",
    "        \n",
    "        theta_mk_sum = np.zeros((n_documents, ntopics))\n",
    "        phi_kv_sum = np.zeros((ntopics, n_terms))\n",
    "        \n",
    "        for _ in range(warnming_iters):\n",
    "            if sampling_method == \"Gibbs\":\n",
    "                self.Gibbs_step(self.zw_Gibbs_topic_prob, alpha, beta)\n",
    "            else:\n",
    "                self.MH_step(self.zw_MH_topic_prob, alpha, beta)\n",
    "\n",
    "        for _ in range(estimate_iters):\n",
    "            if sampling_method == \"Gibbs\":\n",
    "                self.Gibbs_step(self.zw_Gibbs_topic_prob, alpha, beta)\n",
    "            else:\n",
    "                self.MH_step(self.zw_MH_topic_prob, alpha, beta)\n",
    "\n",
    "            #print(n_mk)\n",
    "            #print(n_kv)\n",
    "            theta_mk_sum += (n_mk + alpha)/(n_mk + alpha).sum(axis=1, keepdims=True)\n",
    "            phi_kv_sum += (n_kv + beta)/(n_kv + beta).sum(axis=1, keepdims=True)\n",
    "        \n",
    "        theta_mk = theta_mk_sum/estimate_iters\n",
    "        phi_kv = phi_kv_sum/estimate_iters\n",
    "        \n",
    "        self.theta_mk = theta_mk\n",
    "        self.phi_kv = phi_kv\n",
    "        self.term_topic_mat = phi_kv.transpose()\n",
    "        self.topic_doc_mat = theta_mk.transpose()\n",
    "        \n",
    "        \n",
    "    # generate P(z|w) sample\n",
    "    def zw_Gibbs_topic_prob(self, m, v, alpha, beta):\n",
    "        n_mk = self.n_mk\n",
    "        n_m = self.n_m\n",
    "        n_kv = self.n_kv\n",
    "        n_k = self.n_k\n",
    "            \n",
    "        n_kv_ = (n_kv[:,v] + beta) / (n_kv[:,:] + beta).sum(axis=1)\n",
    "        n_mk_ = (n_mk[m,:] + alpha) / (n_mk[m,:] + alpha).sum()\n",
    "        return n_kv_*n_mk_\n",
    "\n",
    "    # generate P(z|w) sample\n",
    "    def zw_MH_topic_prob(m, v, k, alpha, beta):\n",
    "        n_mk = self.n_mk\n",
    "        n_m = self.n_m\n",
    "        n_kv = self.n_kv\n",
    "        n_k = self.n_k\n",
    "        \n",
    "        n_kv_ = (n_kv[k,v] + beta) / (n_kv[k,:] + beta).sum()\n",
    "        n_mk_ = (n_mk[m,k] + alpha) / (n_mk[m,:] + alpha).sum()\n",
    "        return n_kv_*n_mk_\n",
    "\n",
    "    \n",
    "    def MH_step(self, topic_prob, alpha, beta):\n",
    "\n",
    "        n_documents = self.n_documents\n",
    "\n",
    "        v_mp = self.v_mp\n",
    "        k_mp = self.k_mp\n",
    "        \n",
    "        n_mk = self.n_mk\n",
    "        n_m = self.n_m\n",
    "        n_kv = self.n_kv\n",
    "        n_k = self.n_k\n",
    "        \n",
    "        # random document\n",
    "        m = np.random.randint(n_document, dtype=np.int)\n",
    "        # random term\n",
    "        p = np.random.randint(len(v_mp[m]), dtype=np.int)\n",
    "        \n",
    "        v = v_mp[m][p]\n",
    "        k = k_mp[m][p]    \n",
    "        \n",
    "        # random new topic\n",
    "        kp = np.random.randint(ntopics, dtype=np.int)\n",
    "\n",
    "        k_prob = topic_prob(m, v, k, alpha, beta)\n",
    "        kp_prob = topic_prob(m, v, kp, alpha, beta)\n",
    "\n",
    "        acc = kp_prob / (k_prob + 1E-10)\n",
    "        u = np.random.rand()\n",
    "        if u < acc:\n",
    "            # accept      \n",
    "            n_mk[m, k] -= 1\n",
    "            #n_m[m] -= 1\n",
    "            n_kv[k, v] -= 1\n",
    "            n_k[k] -= 1\n",
    "\n",
    "            k_mp[m][p] = kp\n",
    "            \n",
    "            n_mk[m, kp] += 1\n",
    "            #n_m[m] += 1\n",
    "            n_kv[kp, v] += 1\n",
    "            n_k[kp] += 1\n",
    "\n",
    "    \n",
    "    \n",
    "    def Gibbs_step(self, sample_topic, alpha, beta):\n",
    "        n_documents = self.n_documents\n",
    "        \n",
    "        v_mp = self.v_mp\n",
    "        k_mp = self.k_mp\n",
    "        \n",
    "        n_mk = self.n_mk\n",
    "        n_m = self.n_m\n",
    "        n_kv = self.n_kv\n",
    "        n_k = self.n_k\n",
    "\n",
    "        for m in range(n_documents):\n",
    "            for p in range(len(v_mp[m])):\n",
    "                \n",
    "                # current term\n",
    "                v = v_mp[m][p]\n",
    "\n",
    "                # current topic\n",
    "                k = k_mp[m][p]   \n",
    "                \n",
    "                n_mk[m, k] -= 1\n",
    "                #n_m[m] -= 1\n",
    "                n_kv[k, v] -= 1\n",
    "                n_k[k] -= 1\n",
    "\n",
    "                topics_prob = sample_topic(m, v, alpha, beta)\n",
    "                acc = topics_prob.cumsum()/topics_prob.sum()\n",
    "                u = np.random.rand()\n",
    "                kp = np.searchsorted(acc, u, side=\"left\")\n",
    "\n",
    "                k_mp[m][p] = kp\n",
    "                \n",
    "                n_mk[m, kp] += 1\n",
    "                #n_m[m] += 1\n",
    "                n_kv[kp, v] += 1\n",
    "                n_k[kp] += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 潜在语义分析（LSA）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 玩具级数据集 （Toy dataset）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的文档包含两个主题：一个是粒子物理，常用词汇为\"meson\", \"photon\"。\n",
    "另外一个主题是生活，常用词汇为\"girl\", \"boy\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents set\n",
    "documents = [\n",
    "    \"Girl loves boy\",\n",
    "    \"Boy loves girl\",\n",
    "    \"Girl loves girl\",\n",
    "    \"Boy loves boy\",\n",
    "    \n",
    "    \"Meson hits photon\",\n",
    "    \"Photon hits meson\",\n",
    "    \"Photon hits photon\",\n",
    "    \"Meson hits meson\",\n",
    "\n",
    "    \"Boy loves meson\",\n",
    "    \"Girl loves photon\",\n",
    "    \"Meson hits girl\",\n",
    "    \"Photon hits boy a\",\n",
    "    \"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字母表 (Alphabet)\n",
    "\n",
    "任何单词有若干个连续的字母表中的字母组成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(list(word_elements)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词 (Parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aBc1', 'bc', '1C1', '60s', '80']\n"
     ]
    }
   ],
   "source": [
    "document_test = \" a   aBc1 bc 1C1 60s,80\"\n",
    "print(document_to_terms(document_test, stop_words=[\"a\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立结构化数据集 (Structured documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 terms found in 13 documents.\n",
      "terms: ['girl', 'loves', 'boy', 'meson', 'hits', 'photon']\n",
      "terms_set: ['girl', 'meson', 'photon', 'boy', 'hits', 'loves']\n",
      "term_to_index: [('girl', 0), ('loves', 1), ('boy', 2), ('meson', 3), ('hits', 4), ('photon', 5)]\n",
      "docs_terms: [['Girl', 'loves', 'boy'], ['Boy', 'loves', 'girl'], ['Girl', 'loves', 'girl'], ['Boy', 'loves', 'boy'], ['Meson', 'hits', 'photon'], ['Photon', 'hits', 'meson'], ['Photon', 'hits', 'photon'], ['Meson', 'hits', 'meson'], ['Boy', 'loves', 'meson'], ['Girl', 'loves', 'photon'], ['Meson', 'hits', 'girl'], ['Photon', 'hits', 'boy'], []]\n",
      "docs_term_indices: [[0, 1, 2], [2, 1, 0], [0, 1, 0], [2, 1, 2], [3, 4, 5], [5, 4, 3], [5, 4, 5], [3, 4, 3], [2, 1, 3], [0, 1, 5], [3, 4, 0], [5, 4, 2], []]\n"
     ]
    }
   ],
   "source": [
    "sdocs = StructuredDocuments()\n",
    "sdocs.set_documents(documents, threshold=2)\n",
    "sdocs.print_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们使用频率逆文档来表示term-document矩阵。(TFIDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term-document (7X13) matrix setup\n",
      "term_doc_mat [[1. 1. 2. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [1. 1. 0. 2. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 2. 1. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 2. 0. 0. 1. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "tf_j [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 0.]\n",
      "tf_i [5. 6. 5. 5. 6. 5. 1.]\n"
     ]
    }
   ],
   "source": [
    "lsa = LSABase()\n",
    "lsa.set_documents(documents)\n",
    "lsa.cal_term_doc_mat(metric=\"TAF\")\n",
    "with np.printoptions(precision=2):\n",
    "    print(\"term-document (%dX%d) matrix setup\"%(lsa.term_doc_mat.shape[0],lsa.term_doc_mat.shape[1]))\n",
    "    print(\"term_doc_mat\", lsa.term_doc_mat)\n",
    "    print(\"tf_j\", lsa.tf_j)\n",
    "    print(\"tf_i\", lsa.df_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 奇异值分解（SVD）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将term-documents矩阵分解为 u s vT\n",
    "保留其中主值最大的部分。\n",
    "奇异值分解的正交性要求，矩阵的部分数值小于0，如何解释呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(physics, 3.3E-01)</td>\n",
       "      <td>(live, 3.1E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(physics, 3.3E-01)</td>\n",
       "      <td>(live, 3.1E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(physics, 3.2E-01)</td>\n",
       "      <td>(live, 3.2E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(physics, 3.4E-01)</td>\n",
       "      <td>(live, 3.0E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(physics, -3.6E-01)</td>\n",
       "      <td>(live, 2.8E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(physics, -3.6E-01)</td>\n",
       "      <td>(live, 2.8E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>(physics, -3.5E-01)</td>\n",
       "      <td>(live, 2.7E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>(physics, -3.7E-01)</td>\n",
       "      <td>(live, 2.9E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>(live, 3.0E-01)</td>\n",
       "      <td>(physics, 1.1E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>(live, 3.0E-01)</td>\n",
       "      <td>(physics, 1.1E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>(live, 3.0E-01)</td>\n",
       "      <td>(physics, -1.5E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>(live, 2.1E-01)</td>\n",
       "      <td>(physics, -1.0E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>(live, 0.0E+00)</td>\n",
       "      <td>(physics, 0.0E+00)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    document        composition 0        composition 1\n",
       "0          0   (physics, 3.3E-01)      (live, 3.1E-01)\n",
       "1          1   (physics, 3.3E-01)      (live, 3.1E-01)\n",
       "2          2   (physics, 3.2E-01)      (live, 3.2E-01)\n",
       "3          3   (physics, 3.4E-01)      (live, 3.0E-01)\n",
       "4          4  (physics, -3.6E-01)      (live, 2.8E-01)\n",
       "5          5  (physics, -3.6E-01)      (live, 2.8E-01)\n",
       "6          6  (physics, -3.5E-01)      (live, 2.7E-01)\n",
       "7          7  (physics, -3.7E-01)      (live, 2.9E-01)\n",
       "8          8      (live, 3.0E-01)   (physics, 1.1E-01)\n",
       "9          9      (live, 3.0E-01)   (physics, 1.1E-01)\n",
       "10        10      (live, 3.0E-01)  (physics, -1.5E-01)\n",
       "11        11      (live, 2.1E-01)  (physics, -1.0E-01)\n",
       "12        12      (live, 0.0E+00)   (physics, 0.0E+00)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "      <th>composition 2</th>\n",
       "      <th>composition 3</th>\n",
       "      <th>composition 4</th>\n",
       "      <th>composition 5</th>\n",
       "      <th>composition 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>live</td>\n",
       "      <td>(girl, 4.4E-01)</td>\n",
       "      <td>(loves, 4.4E-01)</td>\n",
       "      <td>(meson, 4.2E-01)</td>\n",
       "      <td>(boy, 4.0E-01)</td>\n",
       "      <td>(hits, 3.8E-01)</td>\n",
       "      <td>(photon, 3.7E-01)</td>\n",
       "      <td>(a, 3.8E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>physics</td>\n",
       "      <td>(hits, -4.7E-01)</td>\n",
       "      <td>(loves, 4.3E-01)</td>\n",
       "      <td>(meson, -4.2E-01)</td>\n",
       "      <td>(photon, -3.9E-01)</td>\n",
       "      <td>(boy, 3.8E-01)</td>\n",
       "      <td>(girl, 3.5E-01)</td>\n",
       "      <td>(a, -2.2E-02)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic     composition 0     composition 1      composition 2  \\\n",
       "0     live   (girl, 4.4E-01)  (loves, 4.4E-01)   (meson, 4.2E-01)   \n",
       "1  physics  (hits, -4.7E-01)  (loves, 4.3E-01)  (meson, -4.2E-01)   \n",
       "\n",
       "        composition 3    composition 4      composition 5  composition 6  \n",
       "0      (boy, 4.0E-01)  (hits, 3.8E-01)  (photon, 3.7E-01)   (a, 3.8E-02)  \n",
       "1  (photon, -3.9E-01)   (boy, 3.8E-01)    (girl, 3.5E-01)  (a, -2.2E-02)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lsa = SVD_LSA()\n",
    "lsa.set_documents(documents)\n",
    "lsa.topic_decompose(ntopics=2, term_weight=\"TF\")\n",
    "lsa.print_mat(topic_names=[\"live\",\"physics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非负矩阵分解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将term-documents矩阵$X$分解为 $WH$，其中$W$和$H$为（任意元素）非负矩阵。\n",
    "目标为优化\n",
    "$$\\sum_{ij}(WH-X)_{ij}^2\n",
    "优化方法采用“乘法更新规则”。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want 2 topics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(physics, 1.0E+00)</td>\n",
       "      <td>(live, 3.4E-77)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(physics, 1.0E+00)</td>\n",
       "      <td>(live, 5.5E-77)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(physics, 1.0E+00)</td>\n",
       "      <td>(live, 1.9E-24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(physics, 1.0E+00)</td>\n",
       "      <td>(live, 0.0E+00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(live, 1.0E+00)</td>\n",
       "      <td>(physics, 4.8E-48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(live, 1.0E+00)</td>\n",
       "      <td>(physics, 4.4E-48)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>(live, 1.0E+00)</td>\n",
       "      <td>(physics, 4.1E-63)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>(live, 1.1E+00)</td>\n",
       "      <td>(physics, 1.9E-36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>(physics, 6.9E-01)</td>\n",
       "      <td>(live, 3.3E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>(physics, 7.0E-01)</td>\n",
       "      <td>(live, 3.1E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>(live, 7.2E-01)</td>\n",
       "      <td>(physics, 3.2E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>(live, 5.2E-01)</td>\n",
       "      <td>(physics, 2.4E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>(live, 0.0E+00)</td>\n",
       "      <td>(physics, 0.0E+00)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    document       composition 0       composition 1\n",
       "0          0  (physics, 1.0E+00)     (live, 3.4E-77)\n",
       "1          1  (physics, 1.0E+00)     (live, 5.5E-77)\n",
       "2          2  (physics, 1.0E+00)     (live, 1.9E-24)\n",
       "3          3  (physics, 1.0E+00)     (live, 0.0E+00)\n",
       "4          4     (live, 1.0E+00)  (physics, 4.8E-48)\n",
       "5          5     (live, 1.0E+00)  (physics, 4.4E-48)\n",
       "6          6     (live, 1.0E+00)  (physics, 4.1E-63)\n",
       "7          7     (live, 1.1E+00)  (physics, 1.9E-36)\n",
       "8          8  (physics, 6.9E-01)     (live, 3.3E-01)\n",
       "9          9  (physics, 7.0E-01)     (live, 3.1E-01)\n",
       "10        10     (live, 7.2E-01)  (physics, 3.2E-01)\n",
       "11        11     (live, 5.2E-01)  (physics, 2.4E-01)\n",
       "12        12     (live, 0.0E+00)  (physics, 0.0E+00)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "      <th>composition 2</th>\n",
       "      <th>composition 3</th>\n",
       "      <th>composition 4</th>\n",
       "      <th>composition 5</th>\n",
       "      <th>composition 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>live</td>\n",
       "      <td>(hits, 3.3E-01)</td>\n",
       "      <td>(meson, 3.3E-01)</td>\n",
       "      <td>(photon, 3.0E-01)</td>\n",
       "      <td>(a, 2.3E-02)</td>\n",
       "      <td>(girl, 1.7E-02)</td>\n",
       "      <td>(boy, 2.4E-06)</td>\n",
       "      <td>(loves, 2.5E-24)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>physics</td>\n",
       "      <td>(loves, 3.4E-01)</td>\n",
       "      <td>(girl, 3.2E-01)</td>\n",
       "      <td>(boy, 3.1E-01)</td>\n",
       "      <td>(meson, 1.4E-02)</td>\n",
       "      <td>(photon, 9.8E-03)</td>\n",
       "      <td>(a, 7.6E-03)</td>\n",
       "      <td>(hits, 7.5E-42)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic     composition 0     composition 1      composition 2  \\\n",
       "0     live   (hits, 3.3E-01)  (meson, 3.3E-01)  (photon, 3.0E-01)   \n",
       "1  physics  (loves, 3.4E-01)   (girl, 3.2E-01)     (boy, 3.1E-01)   \n",
       "\n",
       "      composition 3      composition 4   composition 5     composition 6  \n",
       "0      (a, 2.3E-02)    (girl, 1.7E-02)  (boy, 2.4E-06)  (loves, 2.5E-24)  \n",
       "1  (meson, 1.4E-02)  (photon, 9.8E-03)    (a, 7.6E-03)   (hits, 7.5E-42)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ntopics = 2\n",
    "print(\"We want %d topics\"%ntopics)\n",
    "\n",
    "lsa = NMF_LSA()\n",
    "lsa.set_documents(documents)\n",
    "lsa.topic_decompose(ntopics=2, term_weight=\"TF\")\n",
    "lsa.print_mat(topic_names=[\"live\",\"physics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want 2 topics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(physics, 1.3E+00)</td>\n",
       "      <td>(live, 1.4E-74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(physics, 1.3E+00)</td>\n",
       "      <td>(live, 2.2E-74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(physics, 1.3E+00)</td>\n",
       "      <td>(live, 3.3E-28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(physics, 1.3E+00)</td>\n",
       "      <td>(live, 4.2E-200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(live, 1.3E+00)</td>\n",
       "      <td>(physics, 1.1E-44)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(live, 1.3E+00)</td>\n",
       "      <td>(physics, 1.0E-44)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>(live, 1.3E+00)</td>\n",
       "      <td>(physics, 3.6E-50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>(live, 1.4E+00)</td>\n",
       "      <td>(physics, 2.5E-40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>(physics, 9.7E-01)</td>\n",
       "      <td>(live, 3.3E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>(physics, 9.7E-01)</td>\n",
       "      <td>(live, 3.2E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>(live, 9.8E-01)</td>\n",
       "      <td>(physics, 3.3E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>(live, 7.0E-01)</td>\n",
       "      <td>(physics, 2.4E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>(live, 0.0E+00)</td>\n",
       "      <td>(physics, 0.0E+00)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    document       composition 0       composition 1\n",
       "0          0  (physics, 1.3E+00)     (live, 1.4E-74)\n",
       "1          1  (physics, 1.3E+00)     (live, 2.2E-74)\n",
       "2          2  (physics, 1.3E+00)     (live, 3.3E-28)\n",
       "3          3  (physics, 1.3E+00)    (live, 4.2E-200)\n",
       "4          4     (live, 1.3E+00)  (physics, 1.1E-44)\n",
       "5          5     (live, 1.3E+00)  (physics, 1.0E-44)\n",
       "6          6     (live, 1.3E+00)  (physics, 3.6E-50)\n",
       "7          7     (live, 1.4E+00)  (physics, 2.5E-40)\n",
       "8          8  (physics, 9.7E-01)     (live, 3.3E-01)\n",
       "9          9  (physics, 9.7E-01)     (live, 3.2E-01)\n",
       "10        10     (live, 9.8E-01)  (physics, 3.3E-01)\n",
       "11        11     (live, 7.0E-01)  (physics, 2.4E-01)\n",
       "12        12     (live, 0.0E+00)  (physics, 0.0E+00)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "      <th>composition 2</th>\n",
       "      <th>composition 3</th>\n",
       "      <th>composition 4</th>\n",
       "      <th>composition 5</th>\n",
       "      <th>composition 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>live</td>\n",
       "      <td>(hits, 3.4E-01)</td>\n",
       "      <td>(meson, 2.7E-01)</td>\n",
       "      <td>(photon, 2.4E-01)</td>\n",
       "      <td>(girl, 2.0E-02)</td>\n",
       "      <td>(a, 7.7E-03)</td>\n",
       "      <td>(boy, 2.2E-03)</td>\n",
       "      <td>(loves, 1.2E-30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>physics</td>\n",
       "      <td>(loves, 3.4E-01)</td>\n",
       "      <td>(girl, 2.5E-01)</td>\n",
       "      <td>(boy, 2.5E-01)</td>\n",
       "      <td>(meson, 1.7E-02)</td>\n",
       "      <td>(photon, 1.4E-02)</td>\n",
       "      <td>(a, 1.7E-03)</td>\n",
       "      <td>(hits, 3.5E-49)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic     composition 0     composition 1      composition 2  \\\n",
       "0     live   (hits, 3.4E-01)  (meson, 2.7E-01)  (photon, 2.4E-01)   \n",
       "1  physics  (loves, 3.4E-01)   (girl, 2.5E-01)     (boy, 2.5E-01)   \n",
       "\n",
       "      composition 3      composition 4   composition 5     composition 6  \n",
       "0   (girl, 2.0E-02)       (a, 7.7E-03)  (boy, 2.2E-03)  (loves, 1.2E-30)  \n",
       "1  (meson, 1.7E-02)  (photon, 1.4E-02)    (a, 1.7E-03)   (hits, 3.5E-49)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ntopics = 2\n",
    "print(\"We want %d topics\"%ntopics)\n",
    "\n",
    "lsa = NMF_LSA()\n",
    "lsa.set_documents(documents)\n",
    "lsa.topic_decompose(ntopics=2, term_weight=\"TFIDF\")\n",
    "lsa.print_mat(topic_names=[\"live\",\"physics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 概率潜在语义分析(pLSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概率潜在语义分析即潜在语义分析概率化版本，是一种生成模型。\n",
    "\n",
    "设文档集合为$D=\\{d_j\\}, j < |D|$，单词集合为$W=\\{w_i\\}, i < |W|$，文档$d_j$也是单词的序列，序列长度为$|d_j|$（重复单词多次计数。）\n",
    "\n",
    "概率模型给出文档$d_j$中某一单词位置（比如第一个单词），单词$w_i$出现的概率$P(w_i, d_j)$为\n",
    "$$\n",
    "P(w_i, d_j) = \n",
    "\\sum_k P(w_i, z_k) P(z_k, d_j)\n",
    "$$\n",
    "其中$P(z_k, d_j)$为文档$d_j$中某一单词选取话题$z_k$的概率，$P(w_i, z_k)$为话题$z_k$中单词$w_i$出现的概率。\n",
    "\n",
    "设文档$d_j$第$i^\\prime$个单词是单词$w_{i(d_j, i^\\prime)}$（$i^\\prime < |d_j|$），\n",
    "则文档$d_j$生成的概率为\n",
    "$$\n",
    "\\prod_{i^\\prime < |d_j|} P(w_{i(d_j, i^\\prime)}, d_j)\n",
    "=\\prod_{i < |W|} { P(w_i, d_j)^{n(w_i, d_j)} }\n",
    "$$\n",
    "$n(w_i, d_j)$为单词$i$在文档$j$中出现的频次。\n",
    "所有文档的生成概率的对数为\n",
    "$$\n",
    "L = \\sum_j \\sum_{i} n(w_i, d_j) \\log P(w_i, d_j)\n",
    "$$\n",
    "优化方法采用EM算法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want 2 topics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(physics, 1.0E+00)</td>\n",
       "      <td>(live, 2.1E-34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(physics, 1.0E+00)</td>\n",
       "      <td>(live, 4.5E-34)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(physics, 1.0E+00)</td>\n",
       "      <td>(live, 5.2E-46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(physics, 1.0E+00)</td>\n",
       "      <td>(live, 5.2E-30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(live, 1.0E+00)</td>\n",
       "      <td>(physics, 1.7E-30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(live, 1.0E+00)</td>\n",
       "      <td>(physics, 9.7E-31)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>(live, 1.0E+00)</td>\n",
       "      <td>(physics, 2.3E-35)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>(live, 1.0E+00)</td>\n",
       "      <td>(physics, 9.3E-30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>(physics, 6.7E-01)</td>\n",
       "      <td>(live, 3.3E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>(physics, 6.7E-01)</td>\n",
       "      <td>(live, 3.3E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>(live, 6.7E-01)</td>\n",
       "      <td>(physics, 3.3E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>(live, 7.5E-01)</td>\n",
       "      <td>(physics, 2.5E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>(live, 5.7E-01)</td>\n",
       "      <td>(physics, 4.3E-01)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    document       composition 0       composition 1\n",
       "0          0  (physics, 1.0E+00)     (live, 2.1E-34)\n",
       "1          1  (physics, 1.0E+00)     (live, 4.5E-34)\n",
       "2          2  (physics, 1.0E+00)     (live, 5.2E-46)\n",
       "3          3  (physics, 1.0E+00)     (live, 5.2E-30)\n",
       "4          4     (live, 1.0E+00)  (physics, 1.7E-30)\n",
       "5          5     (live, 1.0E+00)  (physics, 9.7E-31)\n",
       "6          6     (live, 1.0E+00)  (physics, 2.3E-35)\n",
       "7          7     (live, 1.0E+00)  (physics, 9.3E-30)\n",
       "8          8  (physics, 6.7E-01)     (live, 3.3E-01)\n",
       "9          9  (physics, 6.7E-01)     (live, 3.3E-01)\n",
       "10        10     (live, 6.7E-01)  (physics, 3.3E-01)\n",
       "11        11     (live, 7.5E-01)  (physics, 2.5E-01)\n",
       "12        12     (live, 5.7E-01)  (physics, 4.3E-01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "      <th>composition 2</th>\n",
       "      <th>composition 3</th>\n",
       "      <th>composition 4</th>\n",
       "      <th>composition 5</th>\n",
       "      <th>composition 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>live</td>\n",
       "      <td>(hits, 3.2E-01)</td>\n",
       "      <td>(photon, 3.2E-01)</td>\n",
       "      <td>(meson, 3.2E-01)</td>\n",
       "      <td>(a, 5.3E-02)</td>\n",
       "      <td>(boy, 4.7E-11)</td>\n",
       "      <td>(girl, 3.5E-11)</td>\n",
       "      <td>(loves, 2.5E-11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>physics</td>\n",
       "      <td>(loves, 3.3E-01)</td>\n",
       "      <td>(girl, 3.3E-01)</td>\n",
       "      <td>(boy, 3.3E-01)</td>\n",
       "      <td>(meson, 4.0E-11)</td>\n",
       "      <td>(photon, 3.8E-11)</td>\n",
       "      <td>(a, 3.4E-11)</td>\n",
       "      <td>(hits, 2.6E-11)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic     composition 0      composition 1     composition 2  \\\n",
       "0     live   (hits, 3.2E-01)  (photon, 3.2E-01)  (meson, 3.2E-01)   \n",
       "1  physics  (loves, 3.3E-01)    (girl, 3.3E-01)    (boy, 3.3E-01)   \n",
       "\n",
       "      composition 3      composition 4    composition 5     composition 6  \n",
       "0      (a, 5.3E-02)     (boy, 4.7E-11)  (girl, 3.5E-11)  (loves, 2.5E-11)  \n",
       "1  (meson, 4.0E-11)  (photon, 3.8E-11)     (a, 3.4E-11)   (hits, 2.6E-11)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ntopics = 2\n",
    "print(\"We want %d topics\"%ntopics)\n",
    "\n",
    "lsa = pLSA()\n",
    "lsa.set_documents(documents)\n",
    "lsa.topic_decompose(ntopics=ntopics)\n",
    "lsa.print_mat(topic_names=[\"live\",\"physics\"], max_docs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 潜在狄利克雷分配(LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设文档集合为$D=\\{d_m\\}, m<|D|$，单词集合为$W=\\{w_i\\},i < |W|$，文档$d_j$也是单词的序列，序列长度为$|d_m|$（重复单词多次计数。）。\n",
    "话题向量为$\\mathbf{z}=\\{z_m\\},m < |D|$。\n",
    "单词向量为$\\mathbf{w} = \\{w_{mn}\\}, m < |D|, n< |d_m|$。\n",
    "话题向量为$\\mathbf{z} = \\{z_{mn}\\}, m < |D|, n< |d_m|$。\n",
    "话题向量先验计数为$\\mathbf{\\alpha} = \\{\\alpha_{mk}\\}, m < |D|, k < K$。\n",
    "话题词向量先验计数为$\\mathbf{\\beta} = \\{\\beta_{ki}\\}, k < K, i < |W|$。\n",
    "\n",
    "\n",
    "$$\n",
    "P(\\mathbf{w}, \\mathbf{z}, \\mathbf{\\theta},\\mathbf{\\phi}| \\alpha, \\beta) = \n",
    "\\left[\\prod_k \\text{Dir} (\\phi_k|\\beta)\\right]\n",
    "\\left[\\prod_m \\text{Dir}(\\theta_m|\\alpha)\\right]\n",
    "\\left[\n",
    "\\prod_{mn} \\text{Cat}(z_{mn}|\\theta_m) \n",
    "\\text{Cat}(w_{mn}|\\phi_{z_{mn}})\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "我们想要求 $P(\\mathbf{z},\\theta,\\phi|\\mathbf{w})$\n",
    "$$P(\\mathbf{z},\\theta,\\phi|\\mathbf{w})\n",
    "=\n",
    "P(\\theta,\\phi|\\mathbf{z},\\mathbf{w})\n",
    "P(\\mathbf{z},\\mathbf{w})\n",
    "/P(\\mathbf{w})\n",
    "=\n",
    "P(\\theta,\\phi|\\mathbf{z},\\mathbf{w})\n",
    "P(\\mathbf{z}|\\mathbf{w})\n",
    "$$\n",
    "其中\n",
    "\n",
    "$$\n",
    "P(\\mathbf{z},\\mathbf{w}) = \\prod_{k} \\frac{B(n_k+\\beta)}{B(\\beta)} \\prod_{m} \\frac{B(n_m+\\alpha)}{B(\\alpha)}\n",
    "$$\n",
    "\n",
    "和\n",
    "\n",
    "$$\n",
    "P(\\theta,\\phi|\\mathbf{z},\\mathbf{w})\n",
    "= \\left[\\prod_m \\text{Dir}(\\theta_m|n_m+\\alpha)\\right] \\left[\\prod_k \\text{Dir}(\\phi_k|n_k+\\beta)\\right]\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs抽样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(\\mathbf{z}|\\mathbf{w})$可以通过Gibbs抽样方法得到。\n",
    "注意根据狄利克雷分布，\n",
    "$\\theta_m$ 的期望为 $$(n_m + \\alpha)/\\sum_k (n_{mk}+\\alpha_{mk})$$\n",
    "$\\phi_k$ 的期望为 $$(n_k + \\beta)/\\sum_{i} (n_{ki}+\\beta_{ki})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want 2 topics\n",
      "[[3. 0.]\n",
      " [3. 3.]\n",
      " [0. 3.]\n",
      " [3. 0.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 3.]\n",
      " [3. 0.]\n",
      " [0. 3.]\n",
      " [3. 3.]\n",
      " [4. 4.]\n",
      " [0. 0.]]\n",
      "[3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 0.]\n",
      "[[3. 4. 6. 6. 6. 5. 1.]\n",
      " [5. 3. 2. 5. 6. 6. 1.]]\n",
      "[31. 28.]\n",
      "[array([0, 1, 2]), array([2, 1, 0]), array([0, 1, 0]), array([2, 1, 2]), array([3, 4, 5]), array([5, 4, 3]), array([5, 4, 5]), array([3, 4, 3]), array([2, 1, 3]), array([0, 1, 5]), array([3, 4, 0]), array([5, 4, 2, 6]), array([], dtype=int32)]\n",
      "[array([0, 0, 0]), array([1, 0, 1]), array([1, 1, 1]), array([0, 0, 0]), array([1, 0, 0]), array([0, 0, 1]), array([0, 1, 1]), array([1, 0, 0]), array([0, 0, 0]), array([1, 1, 1]), array([1, 0, 1]), array([0, 0, 1, 1]), array([], dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "ntopics=2\n",
    "print(\"We want %d topics\"%ntopics)\n",
    "lda=LDA()\n",
    "lda.set_documents(documents)\n",
    "lda.initialize_randomly(ntopics=ntopics)\n",
    "print(lda.n_mk)\n",
    "print(lda.n_m)\n",
    "print(lda.n_kv)\n",
    "print(lda.n_k)\n",
    "print(lda.v_mp)\n",
    "print(lda.k_mp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want 2 topics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(0, 5.7E-01)</td>\n",
       "      <td>(1, 4.3E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 6.3E-01)</td>\n",
       "      <td>(0, 3.7E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 6.1E-01)</td>\n",
       "      <td>(0, 3.9E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(1, 6.1E-01)</td>\n",
       "      <td>(0, 3.9E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(0, 6.4E-01)</td>\n",
       "      <td>(1, 3.6E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(0, 6.1E-01)</td>\n",
       "      <td>(1, 3.9E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>(0, 6.0E-01)</td>\n",
       "      <td>(1, 4.0E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>(1, 5.5E-01)</td>\n",
       "      <td>(0, 4.5E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>(0, 5.4E-01)</td>\n",
       "      <td>(1, 4.6E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>(0, 5.5E-01)</td>\n",
       "      <td>(1, 4.5E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>(0, 6.3E-01)</td>\n",
       "      <td>(1, 3.7E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>(0, 5.4E-01)</td>\n",
       "      <td>(1, 4.6E-01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>(0, 5.0E-01)</td>\n",
       "      <td>(1, 5.0E-01)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    document composition 0 composition 1\n",
       "0          0  (0, 5.7E-01)  (1, 4.3E-01)\n",
       "1          1  (1, 6.3E-01)  (0, 3.7E-01)\n",
       "2          2  (1, 6.1E-01)  (0, 3.9E-01)\n",
       "3          3  (1, 6.1E-01)  (0, 3.9E-01)\n",
       "4          4  (0, 6.4E-01)  (1, 3.6E-01)\n",
       "5          5  (0, 6.1E-01)  (1, 3.9E-01)\n",
       "6          6  (0, 6.0E-01)  (1, 4.0E-01)\n",
       "7          7  (1, 5.5E-01)  (0, 4.5E-01)\n",
       "8          8  (0, 5.4E-01)  (1, 4.6E-01)\n",
       "9          9  (0, 5.5E-01)  (1, 4.5E-01)\n",
       "10        10  (0, 6.3E-01)  (1, 3.7E-01)\n",
       "11        11  (0, 5.4E-01)  (1, 4.6E-01)\n",
       "12        12  (0, 5.0E-01)  (1, 5.0E-01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "      <th>composition 2</th>\n",
       "      <th>composition 3</th>\n",
       "      <th>composition 4</th>\n",
       "      <th>composition 5</th>\n",
       "      <th>composition 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(hits, 2.3E-01)</td>\n",
       "      <td>(girl, 1.7E-01)</td>\n",
       "      <td>(meson, 1.6E-01)</td>\n",
       "      <td>(boy, 1.4E-01)</td>\n",
       "      <td>(photon, 1.3E-01)</td>\n",
       "      <td>(loves, 1.1E-01)</td>\n",
       "      <td>(a, 5.7E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(loves, 2.2E-01)</td>\n",
       "      <td>(photon, 1.9E-01)</td>\n",
       "      <td>(boy, 1.8E-01)</td>\n",
       "      <td>(meson, 1.6E-01)</td>\n",
       "      <td>(girl, 1.4E-01)</td>\n",
       "      <td>(hits, 8.2E-02)</td>\n",
       "      <td>(a, 3.3E-02)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic     composition 0      composition 1     composition 2  \\\n",
       "0      0   (hits, 2.3E-01)    (girl, 1.7E-01)  (meson, 1.6E-01)   \n",
       "1      1  (loves, 2.2E-01)  (photon, 1.9E-01)    (boy, 1.8E-01)   \n",
       "\n",
       "      composition 3      composition 4     composition 5 composition 6  \n",
       "0    (boy, 1.4E-01)  (photon, 1.3E-01)  (loves, 1.1E-01)  (a, 5.7E-02)  \n",
       "1  (meson, 1.6E-01)    (girl, 1.4E-01)   (hits, 8.2E-02)  (a, 3.3E-02)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ntopics=2\n",
    "print(\"We want %d topics\"%ntopics)\n",
    "lda=LDA()\n",
    "lda.set_documents(documents)\n",
    "lda.topic_decompose(ntopics = ntopics, alpha = 1, beta = 1)\n",
    "lda.print_mat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20新闻组数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载停止词汇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'would', 'thanks', 'please', 'hi', 'hello']\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    \n",
    "    # downaload stop words\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "else:\n",
    "    # I download and save it for you\n",
    "    stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "stop_words.extend(string.ascii_letters)\n",
    "stop_words.extend([\"would\", \"thanks\", \"please\", \"hi\", \"hello\"])\n",
    "print(stop_words)\n",
    "stop_words.extend([\"_\"*i for i in range(1, 200)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20新闻组语料库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "语料库取自 http://qwone.com/~jason/20Newsgroups/ 。\n",
    "你也可以在sklearn中找到这个数据集。\n",
    "在 https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json 包含json格式的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#wget 'https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json' -O newsgroups.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>From: tchen@magnus.acs.ohio-state.edu (Tsung-K...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>From: a207706@moe.dseg.ti.com (Robert Loper)\\n...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>From: kimman@magnus.acs.ohio-state.edu (Kim Ri...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>From: kwilson@casbah.acns.nwu.edu (Kirtley Wil...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>Subject: Re: Don't more innocents die without ...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n",
       "      <td>0</td>\n",
       "      <td>alt.atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>From: dls@aeg.dsto.gov.au (David Silver)\\nSubj...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>Subject: Re: Mike Francesa's 1993 Predictions\\...</td>\n",
       "      <td>9</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>From: jet@netcom.Netcom.COM (J. Eric Townsend)...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>From: sehari@iastate.edu (Babak Sehari)\\nSubje...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>From: danmg@grok85.ColumbiaSC.NCR.COM (Daniel ...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>From: henry@zoo.toronto.edu (Henry Spencer)\\nS...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>From: tzs@stein2.u.washington.edu (Tim Smith)\\...</td>\n",
       "      <td>18</td>\n",
       "      <td>talk.politics.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>From: U56149@uicvm.uic.edu\\nSubject: LCIII &amp; M...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>From: nsmca@aurora.alaska.edu\\nSubject: Lunar ...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  target  \\\n",
       "0      From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1      From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "10     From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n",
       "100    From: tchen@magnus.acs.ohio-state.edu (Tsung-K...       6   \n",
       "1000   From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...       2   \n",
       "10000  From: a207706@moe.dseg.ti.com (Robert Loper)\\n...       7   \n",
       "10001  From: kimman@magnus.acs.ohio-state.edu (Kim Ri...       6   \n",
       "10002  From: kwilson@casbah.acns.nwu.edu (Kirtley Wil...       2   \n",
       "10003  Subject: Re: Don't more innocents die without ...       0   \n",
       "10004  From: livesey@solntze.wpd.sgi.com (Jon Livesey...       0   \n",
       "10005  From: dls@aeg.dsto.gov.au (David Silver)\\nSubj...       1   \n",
       "10006  Subject: Re: Mike Francesa's 1993 Predictions\\...       9   \n",
       "10007  From: jet@netcom.Netcom.COM (J. Eric Townsend)...       8   \n",
       "10008  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...      10   \n",
       "10009  From: sehari@iastate.edu (Babak Sehari)\\nSubje...      12   \n",
       "1001   From: danmg@grok85.ColumbiaSC.NCR.COM (Daniel ...       7   \n",
       "10010  From: henry@zoo.toronto.edu (Henry Spencer)\\nS...      14   \n",
       "10011  From: tzs@stein2.u.washington.edu (Tim Smith)\\...      18   \n",
       "10012  From: U56149@uicvm.uic.edu\\nSubject: LCIII & M...       4   \n",
       "10013  From: nsmca@aurora.alaska.edu\\nSubject: Lunar ...      14   \n",
       "\n",
       "                  target_names  \n",
       "0                    rec.autos  \n",
       "1        comp.sys.mac.hardware  \n",
       "10             rec.motorcycles  \n",
       "100               misc.forsale  \n",
       "1000   comp.os.ms-windows.misc  \n",
       "10000                rec.autos  \n",
       "10001             misc.forsale  \n",
       "10002  comp.os.ms-windows.misc  \n",
       "10003              alt.atheism  \n",
       "10004              alt.atheism  \n",
       "10005            comp.graphics  \n",
       "10006       rec.sport.baseball  \n",
       "10007          rec.motorcycles  \n",
       "10008         rec.sport.hockey  \n",
       "10009          sci.electronics  \n",
       "1001                 rec.autos  \n",
       "10010                sci.space  \n",
       "10011       talk.politics.misc  \n",
       "10012    comp.sys.mac.hardware  \n",
       "10013                sci.space  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import IPython.display\n",
    "\n",
    "df = pd.read_json('./newsgroups.json')\n",
    "\n",
    "\n",
    "#df = df.head(1000)\n",
    "#display(df)\n",
    "\n",
    "email_documents = df.content.values.tolist()\n",
    "target_names = df.target_names.values.tolist()\n",
    "targets = df.target.values.tolist()\n",
    "\n",
    "n_catogories = len(df.target.unique())\n",
    "catogories = range(n_catogories)\n",
    "cat_names = n_catogories*[None]\n",
    "\n",
    "for i, t in enumerate(targets):\n",
    "    cat_names[t] = target_names[i]\n",
    "print(cat_names) \n",
    "\n",
    "#print(email_documents[10])\n",
    "#print(target_names[10])\n",
    "\n",
    "display.display(df.head(n=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理\n",
    "\n",
    "sklearn提供了这个数据集的预处理选项，但是我们自己做。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'''''From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'''''\n",
      "''''' I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "'''''\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "shown=0\n",
    "print(\"'''''%s'''''\"%email_documents[shown])\n",
    "\n",
    "# remove email header\n",
    "email_documents = [\"\\n\\n\".join(doc.split('\\n\\n')[1:]) for doc in email_documents]\n",
    "\n",
    "# Remove Emails\n",
    "email_documents = [re.sub('\\S*@\\S*\\s?', '', doc) for doc in email_documents]\n",
    "\n",
    "print(\"'''''%s'''''\"%email_documents[shown])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结构化数据 (Structured data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26363 terms found in 11314 documents.\n",
      "terms: ['wondering', 'anyone', 'could', 'enlighten', 'car', 'saw', 'day', '2', 'door', 'sports', 'looked', 'late', '60s', 'early', '70s', 'called', 'doors', 'really', 'small', 'addition']\n",
      "terms_set: ['playing', 'output_entry', 'collider', 'irq5', 'rebound', 'brighton', 'infamous', 'condemnation', 'warned', 'histogram', 'spelled', 'groucho', 'weiss', 'censor', 'tunnel', '30pm', 'wondering', 'complaints', 'otto', 'profiles']\n",
      "term_to_index: [('wondering', 0), ('anyone', 1), ('could', 2), ('enlighten', 3), ('car', 4), ('saw', 5), ('day', 6), ('2', 7), ('door', 8), ('sports', 9)]\n",
      "docs_terms: [['wondering', 'anyone', 'could', 'enlighten', 'car', 'saw', 'day', '2', 'door', 'sports'], ['fair', 'number', 'brave', 'souls', 'upgraded', 'SI', 'clock', 'oscillator', 'shared', 'experiences'], ['line', 'Ducati', '1978', 'model', 'clock', 'Runs', 'well', 'paint', 'bronze', 'brown'], ['1', 'Software', 'publishing', '4', 'windows', '1', '3', '80', '2', 'OCR'], ['Anybody', 'seen', 'mouse', 'cursor', 'distortion', 'running', 'Diamond', '1024x768x256', 'driver', 'Sorry'], ['article', 'James', 'Callison', 'writes', 'article', 'David', 'Hwang', 'writes', 'article', 'wharfie'], ['2', 'New', '2', 'slightly', 'used', 'SyQuest', '44M', 'cartridge', 'forsale', 'Asking'], ['charge', 'purchasing', 'computer', 'software', 'small', 'office', 'question', 'Microsoft', 'Office', 'Pack'], ['article', 'James', 'Tims', 'writes', 'maintaining', 'classes', 'even', 'prison', 'seems', 'place'], ['article', 'Frank', 'Dwyer', 'writes', 'article', 'Jon', 'Livesey', 'writes', 'article', 'Frank']]\n",
      "docs_term_indices: [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [42, 43, 44, 45, 46, 47, 48, 49, 50, 51], [92, 93, 94, 26, 48, 95, 96, 97, 98, 99], [75, 140, 141, 76, 142, 75, 143, 144, 7, 145], [209, 210, 211, 212, 213, 214, 215, 216, 217, 218], [234, 235, 236, 237, 234, 238, 239, 237, 234, 240], [7, 332, 7, 333, 305, 334, 335, 336, 337, 338], [344, 345, 346, 140, 18, 347, 348, 169, 347, 349], [234, 235, 389, 237, 390, 391, 392, 393, 368, 394], [234, 437, 438, 237, 234, 439, 440, 237, 234, 437]]\n"
     ]
    }
   ],
   "source": [
    "email_sdocs=StructuredDocuments()\n",
    "email_sdocs.set_documents(email_documents, stop_words=stop_words, threshold=5)\n",
    "email_sdocs.print_info(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_topics=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD_LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svd=False\n",
    "if svd:\n",
    "    svd_lsa=SVD_LSA()\n",
    "    svd_lsa.set_structured_documents(email_sdocs)\n",
    "    svd_lsa.topic_decompose(ntopics=N_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def print_lsa(lsa):\n",
    "    \n",
    "    topic_weights=np.zeros((n_catogories, lsa.ntopics))\n",
    "    \n",
    "    print(\"top3 topics of each group\")\n",
    "    for cat in range(n_catogories):\n",
    "        #print(nmf_lsa.topic_doc_mat[:,np.equal(targets, cat+1)])\n",
    "        target = catogories[cat]        \n",
    "        topic_weight = lsa.topic_doc_mat[:,np.equal(targets, target)].mean(axis=1)\n",
    "        topic_weights[cat,:] = topic_weight[:]\n",
    "        index = np.argsort(-topic_weight)\n",
    "        print(\"group%2d %30s topic%02d(%.1e) topic%02d(%.1e) topic%02d(%.1e)\"%\\\n",
    "              (target, \"%s\"%(cat_names[target]), index[0], topic_weight[index[0]], index[1],topic_weight[index[1]], index[2], topic_weight[index[2]]   ) )\n",
    "\n",
    "    print(\"top3 groups of each topic\")\n",
    "    for topic in range(lsa.ntopics):\n",
    "        cats_weights = topic_weights[:,topic]\n",
    "        cats_weights = cats_weights\n",
    "        index = np.argsort(-cats_weights)\n",
    "        cat0 = index[0]\n",
    "        cat1 = index[1]\n",
    "        cat2 = index[2]\n",
    "        print(\"topic%d %25s(%.1e) %25s(%.1e) %25s(%.1e)\"%\\\n",
    "              (topic,\n",
    "               cat_names[cat0], cats_weights[cat1], \\\n",
    "               cat_names[cat1], cats_weights[cat1],\\\n",
    "               cat_names[cat2], cats_weights[cat2] ) )\n",
    "\n",
    "    #print(targets[:10])\n",
    "if svd:\n",
    "    svd_lsa.print_mat()\n",
    "    print_lsa(svd_lsa)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF_LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want 50 topics\n",
      "[    0] dH 439666.41143191553\n",
      "[    0] dW 183978.87178917788\n",
      "[   10] dH 0.03651742218847104\n",
      "[   10] dW 3.5428196187610697\n",
      "[   20] dH 0.009653514546825974\n",
      "[   20] dW 0.8572788822827775\n",
      "[   30] dH 0.0024420692095923216\n",
      "[   30] dW 0.13260106866827148\n",
      "[   40] dH 0.0013249679017483084\n",
      "[   40] dW 0.057531165653549765\n",
      "[   50] dH 0.0006033686422098877\n",
      "[   50] dW 0.0546343170001988\n",
      "[   60] dH 0.0004804973029395372\n",
      "[   60] dW 0.06353533592036373\n",
      "[   70] dH 0.0008713924708108141\n",
      "[   70] dW 0.08760684999876715\n",
      "[   80] dH 0.0013094945095094511\n",
      "[   80] dW 0.03726180444575099\n",
      "[   90] dH 0.0019785457571167555\n",
      "[   90] dW 0.026437709313570198\n",
      "[  100] dH 0.0001608842202103164\n",
      "[  100] dW 0.016851844508325435\n",
      "[  110] dH 0.0012107294060322276\n",
      "[  110] dW 0.026030026530278354\n",
      "[  120] dH 5.722670393963191e-05\n",
      "[  120] dW 0.00902644611942426\n",
      "[  130] dH 4.287156221625576e-05\n",
      "[  130] dW 0.006760938517343436\n",
      "[  140] dH 0.0001080465231425697\n",
      "[  140] dW 0.01380795389526195\n",
      "[  150] dH 0.0004245819911266212\n",
      "[  150] dW 0.03045361927397645\n",
      "[  160] dH 8.647959878359222e-05\n",
      "[  160] dW 0.013769045080183302\n",
      "[  170] dH 7.637629219499692e-05\n",
      "[  170] dW 0.01832473449640803\n",
      "[  180] dH 7.554566823009861e-05\n",
      "[  180] dW 0.00959706832029674\n",
      "[  190] dH 0.00011066730408819335\n",
      "[  190] dW 0.013409421588744579\n",
      "[  200] dH 5.7416730616067667e-05\n",
      "[  200] dW 0.007123049717063569\n",
      "[  210] dH 3.886415835805593e-05\n",
      "[  210] dW 0.00551637278550214\n",
      "[  220] dH 2.219179886725487e-05\n",
      "[  220] dW 0.004341753176304045\n",
      "[  230] dH 2.113456791553031e-05\n",
      "[  230] dW 0.004452294967177001\n",
      "[  240] dH 1.720644599694981e-05\n",
      "[  240] dW 0.002632553641847667\n",
      "[  250] dH 1.5259982206723758e-05\n",
      "[  250] dW 0.0023885007526137955\n",
      "[  260] dH 3.448673773975313e-05\n",
      "[  260] dW 0.003544948776428282\n",
      "[  270] dH 4.678078782971146e-05\n",
      "[  270] dW 0.003953497501273006\n",
      "[  280] dH 2.9231536167405347e-05\n",
      "[  280] dW 0.003693519490570076\n",
      "[  290] dH 2.4120909133626985e-05\n",
      "[  290] dW 0.003938116281569571\n",
      "[  300] dH 4.070829104891191e-05\n",
      "[  300] dW 0.004528933028294772\n",
      "[  310] dH 3.125339730957731e-05\n",
      "[  310] dW 0.00472478505722565\n",
      "[  320] dH 3.159962613770362e-05\n",
      "[  320] dW 0.005083590832641883\n",
      "[  330] dH 4.25632315570258e-05\n",
      "[  330] dW 0.00805598340632254\n",
      "[  340] dH 2.8772979530620547e-05\n",
      "[  340] dW 0.012135377865782507\n",
      "[  350] dH 1.2994774125772414e-05\n",
      "[  350] dW 0.0032059920185718974\n",
      "[  360] dH 9.326560574859669e-06\n",
      "[  360] dW 0.00388060534735108\n",
      "[  370] dH 1.1874430243944389e-05\n",
      "[  370] dW 0.003363890656961205\n",
      "[  380] dH 1.652208807922506e-05\n",
      "[  380] dW 0.004310985476441771\n",
      "[  390] dH 3.15009316070445e-05\n",
      "[  390] dW 0.008123097180564318\n",
      "5min ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(\"We want %d topics\"%N_topics)\n",
    "\n",
    "nmf_lsa = NMF_LSA()\n",
    "nmf_lsa.set_structured_documents(email_sdocs)\n",
    "def on_update(i, W, H, Wold, Hold):\n",
    "    if i % 10 == 0:\n",
    "        dH = H - Hold\n",
    "        dW = W - Wold\n",
    "        print(\"[%5d] dH\"%i, np.einsum(\"ij,ij\", dH, dH))\n",
    "        print(\"[%5d] dW\"%i, np.einsum(\"ij,ij\", dW, dW))\n",
    "    \n",
    "%timeit -r1 -n1 nmf_lsa.topic_decompose(ntopics=N_topics, max_iters=400, on_update=on_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "      <th>composition 2</th>\n",
       "      <th>composition 3</th>\n",
       "      <th>composition 4</th>\n",
       "      <th>composition 5</th>\n",
       "      <th>composition 6</th>\n",
       "      <th>composition 7</th>\n",
       "      <th>composition 8</th>\n",
       "      <th>...</th>\n",
       "      <th>composition 40</th>\n",
       "      <th>composition 41</th>\n",
       "      <th>composition 42</th>\n",
       "      <th>composition 43</th>\n",
       "      <th>composition 44</th>\n",
       "      <th>composition 45</th>\n",
       "      <th>composition 46</th>\n",
       "      <th>composition 47</th>\n",
       "      <th>composition 48</th>\n",
       "      <th>composition 49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(22, 3.2E-02)</td>\n",
       "      <td>(48, 2.1E-02)</td>\n",
       "      <td>(3, 1.9E-02)</td>\n",
       "      <td>(32, 1.6E-02)</td>\n",
       "      <td>(38, 1.5E-02)</td>\n",
       "      <td>(37, 4.7E-03)</td>\n",
       "      <td>(9, 3.3E-03)</td>\n",
       "      <td>(21, 2.0E-03)</td>\n",
       "      <td>(13, 1.5E-03)</td>\n",
       "      <td>...</td>\n",
       "      <td>(43, 3.0E-117)</td>\n",
       "      <td>(0, 4.3E-131)</td>\n",
       "      <td>(8, 7.8E-142)</td>\n",
       "      <td>(15, 5.1E-145)</td>\n",
       "      <td>(17, 3.5E-193)</td>\n",
       "      <td>(7, 1.5E-209)</td>\n",
       "      <td>(23, 1.4E-235)</td>\n",
       "      <td>(45, 2.2E-251)</td>\n",
       "      <td>(39, 2.5E-260)</td>\n",
       "      <td>(12, 0.0E+00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(13, 1.9E-02)</td>\n",
       "      <td>(43, 1.2E-02)</td>\n",
       "      <td>(14, 1.1E-02)</td>\n",
       "      <td>(12, 2.2E-03)</td>\n",
       "      <td>(44, 1.3E-03)</td>\n",
       "      <td>(1, 1.3E-03)</td>\n",
       "      <td>(35, 7.0E-04)</td>\n",
       "      <td>(38, 5.2E-04)</td>\n",
       "      <td>(36, 4.0E-04)</td>\n",
       "      <td>...</td>\n",
       "      <td>(33, 1.9E-87)</td>\n",
       "      <td>(0, 2.8E-111)</td>\n",
       "      <td>(21, 3.8E-113)</td>\n",
       "      <td>(15, 2.0E-148)</td>\n",
       "      <td>(17, 2.8E-180)</td>\n",
       "      <td>(29, 3.9E-211)</td>\n",
       "      <td>(20, 1.9E-254)</td>\n",
       "      <td>(46, 5.3E-259)</td>\n",
       "      <td>(5, 1.2E-315)</td>\n",
       "      <td>(7, 0.0E+00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(2, 2.0E-02)</td>\n",
       "      <td>(27, 1.8E-02)</td>\n",
       "      <td>(26, 1.7E-02)</td>\n",
       "      <td>(10, 1.6E-02)</td>\n",
       "      <td>(43, 1.2E-02)</td>\n",
       "      <td>(44, 1.2E-02)</td>\n",
       "      <td>(14, 2.0E-03)</td>\n",
       "      <td>(1, 5.2E-04)</td>\n",
       "      <td>(41, 5.0E-04)</td>\n",
       "      <td>...</td>\n",
       "      <td>(8, 8.1E-117)</td>\n",
       "      <td>(38, 1.8E-121)</td>\n",
       "      <td>(7, 2.9E-139)</td>\n",
       "      <td>(37, 3.2E-147)</td>\n",
       "      <td>(20, 7.5E-156)</td>\n",
       "      <td>(16, 4.5E-194)</td>\n",
       "      <td>(3, 5.6E-210)</td>\n",
       "      <td>(5, 3.3E-250)</td>\n",
       "      <td>(12, 6.7E-259)</td>\n",
       "      <td>(46, 8.8E-318)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(32, 4.4E-02)</td>\n",
       "      <td>(0, 3.9E-02)</td>\n",
       "      <td>(43, 3.0E-02)</td>\n",
       "      <td>(14, 2.6E-02)</td>\n",
       "      <td>(29, 1.2E-02)</td>\n",
       "      <td>(23, 1.1E-02)</td>\n",
       "      <td>(39, 1.1E-03)</td>\n",
       "      <td>(25, 6.8E-04)</td>\n",
       "      <td>(22, 3.3E-04)</td>\n",
       "      <td>...</td>\n",
       "      <td>(35, 2.4E-221)</td>\n",
       "      <td>(40, 9.6E-222)</td>\n",
       "      <td>(21, 2.0E-227)</td>\n",
       "      <td>(1, 1.5E-323)</td>\n",
       "      <td>(41, 0.0E+00)</td>\n",
       "      <td>(8, 0.0E+00)</td>\n",
       "      <td>(7, 0.0E+00)</td>\n",
       "      <td>(5, 0.0E+00)</td>\n",
       "      <td>(20, 0.0E+00)</td>\n",
       "      <td>(11, 0.0E+00)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(48, 3.0E-02)</td>\n",
       "      <td>(22, 2.3E-02)</td>\n",
       "      <td>(23, 2.1E-02)</td>\n",
       "      <td>(44, 1.9E-02)</td>\n",
       "      <td>(12, 1.8E-02)</td>\n",
       "      <td>(1, 2.6E-03)</td>\n",
       "      <td>(21, 2.0E-03)</td>\n",
       "      <td>(35, 2.0E-03)</td>\n",
       "      <td>(0, 1.1E-03)</td>\n",
       "      <td>...</td>\n",
       "      <td>(11, 3.8E-110)</td>\n",
       "      <td>(10, 1.0E-129)</td>\n",
       "      <td>(36, 7.9E-158)</td>\n",
       "      <td>(41, 9.8E-159)</td>\n",
       "      <td>(33, 1.2E-186)</td>\n",
       "      <td>(34, 2.0E-242)</td>\n",
       "      <td>(37, 0.0E+00)</td>\n",
       "      <td>(17, 0.0E+00)</td>\n",
       "      <td>(7, 0.0E+00)</td>\n",
       "      <td>(28, 0.0E+00)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  composition 0  composition 1  composition 2  composition 3  \\\n",
       "0         0  (22, 3.2E-02)  (48, 2.1E-02)   (3, 1.9E-02)  (32, 1.6E-02)   \n",
       "1         1  (13, 1.9E-02)  (43, 1.2E-02)  (14, 1.1E-02)  (12, 2.2E-03)   \n",
       "2         2   (2, 2.0E-02)  (27, 1.8E-02)  (26, 1.7E-02)  (10, 1.6E-02)   \n",
       "3         3  (32, 4.4E-02)   (0, 3.9E-02)  (43, 3.0E-02)  (14, 2.6E-02)   \n",
       "4         4  (48, 3.0E-02)  (22, 2.3E-02)  (23, 2.1E-02)  (44, 1.9E-02)   \n",
       "\n",
       "   composition 4  composition 5  composition 6  composition 7  composition 8  \\\n",
       "0  (38, 1.5E-02)  (37, 4.7E-03)   (9, 3.3E-03)  (21, 2.0E-03)  (13, 1.5E-03)   \n",
       "1  (44, 1.3E-03)   (1, 1.3E-03)  (35, 7.0E-04)  (38, 5.2E-04)  (36, 4.0E-04)   \n",
       "2  (43, 1.2E-02)  (44, 1.2E-02)  (14, 2.0E-03)   (1, 5.2E-04)  (41, 5.0E-04)   \n",
       "3  (29, 1.2E-02)  (23, 1.1E-02)  (39, 1.1E-03)  (25, 6.8E-04)  (22, 3.3E-04)   \n",
       "4  (12, 1.8E-02)   (1, 2.6E-03)  (21, 2.0E-03)  (35, 2.0E-03)   (0, 1.1E-03)   \n",
       "\n",
       "        ...        composition 40  composition 41  composition 42  \\\n",
       "0       ...        (43, 3.0E-117)   (0, 4.3E-131)   (8, 7.8E-142)   \n",
       "1       ...         (33, 1.9E-87)   (0, 2.8E-111)  (21, 3.8E-113)   \n",
       "2       ...         (8, 8.1E-117)  (38, 1.8E-121)   (7, 2.9E-139)   \n",
       "3       ...        (35, 2.4E-221)  (40, 9.6E-222)  (21, 2.0E-227)   \n",
       "4       ...        (11, 3.8E-110)  (10, 1.0E-129)  (36, 7.9E-158)   \n",
       "\n",
       "   composition 43  composition 44  composition 45  composition 46  \\\n",
       "0  (15, 5.1E-145)  (17, 3.5E-193)   (7, 1.5E-209)  (23, 1.4E-235)   \n",
       "1  (15, 2.0E-148)  (17, 2.8E-180)  (29, 3.9E-211)  (20, 1.9E-254)   \n",
       "2  (37, 3.2E-147)  (20, 7.5E-156)  (16, 4.5E-194)   (3, 5.6E-210)   \n",
       "3   (1, 1.5E-323)   (41, 0.0E+00)    (8, 0.0E+00)    (7, 0.0E+00)   \n",
       "4  (41, 9.8E-159)  (33, 1.2E-186)  (34, 2.0E-242)   (37, 0.0E+00)   \n",
       "\n",
       "   composition 47  composition 48  composition 49  \n",
       "0  (45, 2.2E-251)  (39, 2.5E-260)   (12, 0.0E+00)  \n",
       "1  (46, 5.3E-259)   (5, 1.2E-315)    (7, 0.0E+00)  \n",
       "2   (5, 3.3E-250)  (12, 6.7E-259)  (46, 8.8E-318)  \n",
       "3    (5, 0.0E+00)   (20, 0.0E+00)   (11, 0.0E+00)  \n",
       "4   (17, 0.0E+00)    (7, 0.0E+00)   (28, 0.0E+00)  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "      <th>composition 2</th>\n",
       "      <th>composition 3</th>\n",
       "      <th>composition 4</th>\n",
       "      <th>composition 5</th>\n",
       "      <th>composition 6</th>\n",
       "      <th>composition 7</th>\n",
       "      <th>composition 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(3, 7.3E-01)</td>\n",
       "      <td>(windows, 1.5E-01)</td>\n",
       "      <td>(ax, 6.2E-02)</td>\n",
       "      <td>(files, 3.0E-02)</td>\n",
       "      <td>(dos, 2.5E-02)</td>\n",
       "      <td>(version, 2.4E-02)</td>\n",
       "      <td>(driver, 2.3E-02)</td>\n",
       "      <td>(card, 2.3E-02)</td>\n",
       "      <td>(file, 2.2E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(work, 3.3E-01)</td>\n",
       "      <td>(problem, 2.0E-01)</td>\n",
       "      <td>(back, 1.0E-01)</td>\n",
       "      <td>(drive, 4.6E-02)</td>\n",
       "      <td>(using, 3.4E-02)</td>\n",
       "      <td>(try, 3.1E-02)</td>\n",
       "      <td>(got, 3.0E-02)</td>\n",
       "      <td>(might, 2.1E-02)</td>\n",
       "      <td>(works, 2.0E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(like, 7.9E-01)</td>\n",
       "      <td>(things, 1.6E-02)</td>\n",
       "      <td>(look, 1.3E-02)</td>\n",
       "      <td>(etc, 1.2E-02)</td>\n",
       "      <td>(sounds, 9.4E-03)</td>\n",
       "      <td>(looks, 8.4E-03)</td>\n",
       "      <td>(got, 7.8E-03)</td>\n",
       "      <td>(around, 7.7E-03)</td>\n",
       "      <td>(someone, 7.6E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(could, 6.9E-01)</td>\n",
       "      <td>(someone, 8.5E-02)</td>\n",
       "      <td>(tell, 5.6E-02)</td>\n",
       "      <td>(find, 4.1E-02)</td>\n",
       "      <td>(advance, 3.1E-02)</td>\n",
       "      <td>(information, 2.0E-02)</td>\n",
       "      <td>(kind, 1.9E-02)</td>\n",
       "      <td>(point, 1.8E-02)</td>\n",
       "      <td>(wondering, 1.6E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(good, 8.4E-01)</td>\n",
       "      <td>(luck, 1.1E-01)</td>\n",
       "      <td>(bad, 3.9E-02)</td>\n",
       "      <td>(trying, 3.1E-02)</td>\n",
       "      <td>(jim, 2.5E-02)</td>\n",
       "      <td>(comments, 1.8E-02)</td>\n",
       "      <td>(better, 1.4E-02)</td>\n",
       "      <td>(might, 1.3E-02)</td>\n",
       "      <td>(give, 1.3E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(article, 6.8E-01)</td>\n",
       "      <td>(writes, 1.7E-02)</td>\n",
       "      <td>(wrote, 1.2E-02)</td>\n",
       "      <td>(read, 9.2E-03)</td>\n",
       "      <td>(long, 5.8E-03)</td>\n",
       "      <td>(mean, 5.1E-03)</td>\n",
       "      <td>(university, 5.1E-03)</td>\n",
       "      <td>(file, 4.9E-03)</td>\n",
       "      <td>(steve, 4.9E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>(also, 6.6E-01)</td>\n",
       "      <td>(information, 1.6E-02)</td>\n",
       "      <td>(might, 1.6E-02)</td>\n",
       "      <td>(point, 1.6E-02)</td>\n",
       "      <td>(car, 1.3E-02)</td>\n",
       "      <td>(called, 1.3E-02)</td>\n",
       "      <td>(three, 1.2E-02)</td>\n",
       "      <td>(looking, 1.2E-02)</td>\n",
       "      <td>(heard, 1.1E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>(right, 7.1E-01)</td>\n",
       "      <td>(left, 6.2E-02)</td>\n",
       "      <td>(writes, 3.5E-02)</td>\n",
       "      <td>(bill, 2.8E-02)</td>\n",
       "      <td>(article, 2.7E-02)</td>\n",
       "      <td>(wrong, 2.5E-02)</td>\n",
       "      <td>(might, 2.5E-02)</td>\n",
       "      <td>(side, 2.4E-02)</td>\n",
       "      <td>(keep, 2.2E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>(writes, 4.3E-01)</td>\n",
       "      <td>(article, 2.2E-01)</td>\n",
       "      <td>(someone, 1.2E-02)</td>\n",
       "      <td>(day, 4.8E-03)</td>\n",
       "      <td>(john, 4.5E-03)</td>\n",
       "      <td>(back, 4.0E-03)</td>\n",
       "      <td>(ever, 4.0E-03)</td>\n",
       "      <td>(dod, 3.7E-03)</td>\n",
       "      <td>(jim, 3.7E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>(something, 6.0E-01)</td>\n",
       "      <td>(name, 1.9E-01)</td>\n",
       "      <td>(group, 1.9E-01)</td>\n",
       "      <td>(anything, 3.4E-02)</td>\n",
       "      <td>(yet, 2.6E-02)</td>\n",
       "      <td>(wrong, 2.4E-02)</td>\n",
       "      <td>(read, 2.2E-02)</td>\n",
       "      <td>(using, 1.9E-02)</td>\n",
       "      <td>(else, 1.8E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>(want, 3.4E-01)</td>\n",
       "      <td>(one, 2.1E-01)</td>\n",
       "      <td>(god, 1.6E-01)</td>\n",
       "      <td>(believe, 4.1E-02)</td>\n",
       "      <td>(things, 4.0E-02)</td>\n",
       "      <td>(thing, 3.6E-02)</td>\n",
       "      <td>(jesus, 2.4E-02)</td>\n",
       "      <td>(must, 2.1E-02)</td>\n",
       "      <td>(point, 2.0E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>(writes, 5.6E-01)</td>\n",
       "      <td>(question, 7.3E-03)</td>\n",
       "      <td>(state, 6.8E-03)</td>\n",
       "      <td>(since, 6.8E-03)</td>\n",
       "      <td>(yes, 5.5E-03)</td>\n",
       "      <td>(keith, 5.2E-03)</td>\n",
       "      <td>(nothing, 5.1E-03)</td>\n",
       "      <td>(case, 5.1E-03)</td>\n",
       "      <td>(university, 4.9E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>(post, 4.5E-01)</td>\n",
       "      <td>(real, 3.0E-01)</td>\n",
       "      <td>(message, 1.2E-01)</td>\n",
       "      <td>(life, 9.2E-02)</td>\n",
       "      <td>(question, 8.8E-02)</td>\n",
       "      <td>(posting, 6.1E-02)</td>\n",
       "      <td>(tests, 4.0E-02)</td>\n",
       "      <td>(suck, 3.2E-02)</td>\n",
       "      <td>(closed, 2.8E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>(two, 5.0E-01)</td>\n",
       "      <td>(game, 3.0E-02)</td>\n",
       "      <td>(wrote, 2.6E-02)</td>\n",
       "      <td>(years, 2.3E-02)</td>\n",
       "      <td>(three, 2.3E-02)</td>\n",
       "      <td>(last, 2.2E-02)</td>\n",
       "      <td>(power, 1.9E-02)</td>\n",
       "      <td>(take, 1.7E-02)</td>\n",
       "      <td>(team, 1.7E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>(5, 3.5E-01)</td>\n",
       "      <td>(4, 3.5E-01)</td>\n",
       "      <td>(8, 9.3E-02)</td>\n",
       "      <td>(6, 8.2E-02)</td>\n",
       "      <td>(drive, 7.8E-02)</td>\n",
       "      <td>(7, 7.1E-02)</td>\n",
       "      <td>(10, 3.7E-02)</td>\n",
       "      <td>(9, 3.0E-02)</td>\n",
       "      <td>(25, 2.0E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>(may, 6.5E-01)</td>\n",
       "      <td>(going, 1.9E-02)</td>\n",
       "      <td>(soon, 1.5E-02)</td>\n",
       "      <td>(issue, 1.5E-02)</td>\n",
       "      <td>(anything, 1.5E-02)</td>\n",
       "      <td>(try, 1.4E-02)</td>\n",
       "      <td>(window, 1.3E-02)</td>\n",
       "      <td>(power, 1.3E-02)</td>\n",
       "      <td>(orbit, 1.3E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>(lot, 1.4E+00)</td>\n",
       "      <td>(address, 3.1E-02)</td>\n",
       "      <td>(help, 2.6E-02)</td>\n",
       "      <td>(send, 2.5E-02)</td>\n",
       "      <td>(year, 2.2E-02)</td>\n",
       "      <td>(clinton, 1.8E-02)</td>\n",
       "      <td>(white, 1.6E-02)</td>\n",
       "      <td>(high, 1.6E-02)</td>\n",
       "      <td>(house, 1.6E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>(many, 6.3E-01)</td>\n",
       "      <td>(take, 4.0E-02)</td>\n",
       "      <td>(jews, 3.5E-02)</td>\n",
       "      <td>(years, 3.3E-02)</td>\n",
       "      <td>(believe, 2.7E-02)</td>\n",
       "      <td>(still, 2.7E-02)</td>\n",
       "      <td>(answer, 1.7E-02)</td>\n",
       "      <td>(countries, 1.6E-02)</td>\n",
       "      <td>(fact, 1.6E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>(even, 5.3E-01)</td>\n",
       "      <td>(find, 4.3E-02)</td>\n",
       "      <td>(though, 2.3E-02)</td>\n",
       "      <td>(really, 2.1E-02)</td>\n",
       "      <td>(believe, 1.9E-02)</td>\n",
       "      <td>(available, 1.8E-02)</td>\n",
       "      <td>(done, 1.6E-02)</td>\n",
       "      <td>(might, 1.6E-02)</td>\n",
       "      <td>(thought, 1.5E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>(time, 6.6E-01)</td>\n",
       "      <td>(long, 3.4E-02)</td>\n",
       "      <td>(since, 2.8E-02)</td>\n",
       "      <td>(read, 1.5E-02)</td>\n",
       "      <td>(take, 1.5E-02)</td>\n",
       "      <td>(every, 1.4E-02)</td>\n",
       "      <td>(years, 1.1E-02)</td>\n",
       "      <td>(around, 1.0E-02)</td>\n",
       "      <td>(love, 9.6E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>(said, 3.2E-01)</td>\n",
       "      <td>(never, 2.5E-01)</td>\n",
       "      <td>(really, 1.0E-01)</td>\n",
       "      <td>(believe, 4.4E-02)</td>\n",
       "      <td>(god, 4.3E-02)</td>\n",
       "      <td>(going, 3.6E-02)</td>\n",
       "      <td>(writes, 3.4E-02)</td>\n",
       "      <td>(made, 1.9E-02)</td>\n",
       "      <td>(keep, 1.7E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>(see, 5.0E-01)</td>\n",
       "      <td>(believe, 2.9E-02)</td>\n",
       "      <td>(going, 2.9E-02)</td>\n",
       "      <td>(really, 2.7E-02)</td>\n",
       "      <td>(look, 2.7E-02)</td>\n",
       "      <td>(love, 2.5E-02)</td>\n",
       "      <td>(long, 2.3E-02)</td>\n",
       "      <td>(since, 1.9E-02)</td>\n",
       "      <td>(rather, 1.6E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>(anyone, 8.0E-01)</td>\n",
       "      <td>(heard, 3.5E-02)</td>\n",
       "      <td>(advance, 3.2E-02)</td>\n",
       "      <td>(find, 3.2E-02)</td>\n",
       "      <td>(anything, 3.0E-02)</td>\n",
       "      <td>(information, 2.6E-02)</td>\n",
       "      <td>(help, 2.0E-02)</td>\n",
       "      <td>(info, 2.0E-02)</td>\n",
       "      <td>(going, 1.8E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>(system, 6.4E-01)</td>\n",
       "      <td>(frank, 1.2E-01)</td>\n",
       "      <td>(computer, 4.2E-02)</td>\n",
       "      <td>(key, 3.6E-02)</td>\n",
       "      <td>(windows, 3.4E-02)</td>\n",
       "      <td>(using, 3.2E-02)</td>\n",
       "      <td>(phone, 2.8E-02)</td>\n",
       "      <td>(problem, 2.2E-02)</td>\n",
       "      <td>(systems, 2.0E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>(new, 7.1E-01)</td>\n",
       "      <td>(sale, 3.1E-02)</td>\n",
       "      <td>(brand, 2.6E-02)</td>\n",
       "      <td>(price, 2.3E-02)</td>\n",
       "      <td>(york, 2.2E-02)</td>\n",
       "      <td>(university, 1.9E-02)</td>\n",
       "      <td>(00, 1.8E-02)</td>\n",
       "      <td>(50, 1.7E-02)</td>\n",
       "      <td>(try, 1.5E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>(need, 7.8E-01)</td>\n",
       "      <td>(help, 7.5E-02)</td>\n",
       "      <td>(program, 3.4E-02)</td>\n",
       "      <td>(card, 2.9E-02)</td>\n",
       "      <td>(windows, 2.9E-02)</td>\n",
       "      <td>(run, 2.1E-02)</td>\n",
       "      <td>(find, 2.0E-02)</td>\n",
       "      <td>(take, 1.9E-02)</td>\n",
       "      <td>(really, 1.7E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>(get, 8.2E-01)</td>\n",
       "      <td>(life, 3.0E-02)</td>\n",
       "      <td>(real, 2.7E-02)</td>\n",
       "      <td>(source, 1.8E-02)</td>\n",
       "      <td>(going, 1.6E-02)</td>\n",
       "      <td>(help, 1.1E-02)</td>\n",
       "      <td>(ftp, 1.0E-02)</td>\n",
       "      <td>(back, 9.8E-03)</td>\n",
       "      <td>(rather, 9.6E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>(well, 6.4E-01)</td>\n",
       "      <td>(must, 3.8E-02)</td>\n",
       "      <td>(better, 2.1E-02)</td>\n",
       "      <td>(still, 1.7E-02)</td>\n",
       "      <td>(really, 1.5E-02)</td>\n",
       "      <td>(bible, 1.5E-02)</td>\n",
       "      <td>(might, 1.5E-02)</td>\n",
       "      <td>(back, 1.4E-02)</td>\n",
       "      <td>(else, 1.3E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>(test, 2.8E+00)</td>\n",
       "      <td>(message, 1.9E-01)</td>\n",
       "      <td>(help, 1.2E-02)</td>\n",
       "      <td>(another, 8.2E-03)</td>\n",
       "      <td>(serial, 5.9E-03)</td>\n",
       "      <td>(port, 5.5E-03)</td>\n",
       "      <td>(might, 5.0E-03)</td>\n",
       "      <td>(connector, 4.9E-03)</td>\n",
       "      <td>(says, 4.7E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>(0, 1.2E+00)</td>\n",
       "      <td>(problem, 4.3E-02)</td>\n",
       "      <td>(6, 4.2E-02)</td>\n",
       "      <td>(7, 3.6E-02)</td>\n",
       "      <td>(file, 3.4E-02)</td>\n",
       "      <td>(try, 3.3E-02)</td>\n",
       "      <td>(tell, 2.7E-02)</td>\n",
       "      <td>(dos, 2.7E-02)</td>\n",
       "      <td>(255, 2.4E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>(go, 8.8E-01)</td>\n",
       "      <td>(home, 8.2E-02)</td>\n",
       "      <td>(let, 5.2E-02)</td>\n",
       "      <td>(heavy, 4.9E-02)</td>\n",
       "      <td>(red, 3.0E-02)</td>\n",
       "      <td>(blue, 2.4E-02)</td>\n",
       "      <td>(wings, 2.3E-02)</td>\n",
       "      <td>(back, 2.2E-02)</td>\n",
       "      <td>(mike, 2.0E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>(way, 7.4E-01)</td>\n",
       "      <td>(monitor, 4.7E-02)</td>\n",
       "      <td>(mike, 4.6E-02)</td>\n",
       "      <td>(best, 3.4E-02)</td>\n",
       "      <td>(window, 2.7E-02)</td>\n",
       "      <td>(tracy, 1.9E-02)</td>\n",
       "      <td>(find, 1.7E-02)</td>\n",
       "      <td>(going, 1.6E-02)</td>\n",
       "      <td>(another, 1.5E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>(2, 9.2E-01)</td>\n",
       "      <td>(8, 1.9E-02)</td>\n",
       "      <td>(os, 1.7E-02)</td>\n",
       "      <td>(version, 1.6E-02)</td>\n",
       "      <td>(key, 1.5E-02)</td>\n",
       "      <td>(16, 1.5E-02)</td>\n",
       "      <td>(bit, 1.4E-02)</td>\n",
       "      <td>(support, 1.3E-02)</td>\n",
       "      <td>(scsi, 1.3E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>(make, 6.2E-01)</td>\n",
       "      <td>(drive, 4.9E-02)</td>\n",
       "      <td>(offer, 4.2E-02)</td>\n",
       "      <td>(local, 2.1E-02)</td>\n",
       "      <td>(long, 1.9E-02)</td>\n",
       "      <td>(necessary, 1.8E-02)</td>\n",
       "      <td>(chip, 1.8E-02)</td>\n",
       "      <td>(room, 1.7E-02)</td>\n",
       "      <td>(enough, 1.6E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>(much, 6.4E-01)</td>\n",
       "      <td>(makes, 5.3E-02)</td>\n",
       "      <td>(exist, 3.6E-02)</td>\n",
       "      <td>(help, 2.2E-02)</td>\n",
       "      <td>(someone, 2.2E-02)</td>\n",
       "      <td>(better, 2.1E-02)</td>\n",
       "      <td>(case, 1.9E-02)</td>\n",
       "      <td>(pretty, 1.7E-02)</td>\n",
       "      <td>(cost, 1.7E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>(first, 4.8E-01)</td>\n",
       "      <td>(year, 6.4E-02)</td>\n",
       "      <td>(going, 4.4E-02)</td>\n",
       "      <td>(last, 3.6E-02)</td>\n",
       "      <td>(second, 3.5E-02)</td>\n",
       "      <td>(give, 2.7E-02)</td>\n",
       "      <td>(got, 2.6E-02)</td>\n",
       "      <td>(remember, 2.2E-02)</td>\n",
       "      <td>(thing, 1.6E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>(used, 6.0E-01)</td>\n",
       "      <td>(looking, 5.7E-02)</td>\n",
       "      <td>(actually, 3.8E-02)</td>\n",
       "      <td>(video, 3.3E-02)</td>\n",
       "      <td>(windows, 2.5E-02)</td>\n",
       "      <td>(sound, 2.4E-02)</td>\n",
       "      <td>(help, 2.4E-02)</td>\n",
       "      <td>(point, 1.8E-02)</td>\n",
       "      <td>(using, 1.7E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>(us, 5.0E-01)</td>\n",
       "      <td>(god, 4.5E-02)</td>\n",
       "      <td>(guess, 3.7E-02)</td>\n",
       "      <td>(car, 3.6E-02)</td>\n",
       "      <td>(1993, 3.3E-02)</td>\n",
       "      <td>(world, 3.1E-02)</td>\n",
       "      <td>(let, 2.8E-02)</td>\n",
       "      <td>(makes, 2.8E-02)</td>\n",
       "      <td>(government, 2.7E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>(mail, 6.2E-01)</td>\n",
       "      <td>(address, 7.7E-02)</td>\n",
       "      <td>(looking, 5.7E-02)</td>\n",
       "      <td>(monitor, 5.3E-02)</td>\n",
       "      <td>(send, 5.0E-02)</td>\n",
       "      <td>(help, 4.8E-02)</td>\n",
       "      <td>(advance, 3.9E-02)</td>\n",
       "      <td>(list, 3.6E-02)</td>\n",
       "      <td>(vga, 3.5E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>(use, 6.7E-01)</td>\n",
       "      <td>(want, 3.7E-02)</td>\n",
       "      <td>(using, 3.6E-02)</td>\n",
       "      <td>(windows, 3.3E-02)</td>\n",
       "      <td>(help, 2.2E-02)</td>\n",
       "      <td>(window, 1.8E-02)</td>\n",
       "      <td>(program, 1.7E-02)</td>\n",
       "      <td>(hardware, 1.7E-02)</td>\n",
       "      <td>(software, 1.5E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>(sure, 5.7E-01)</td>\n",
       "      <td>(mark, 1.8E-01)</td>\n",
       "      <td>(advantage, 9.9E-02)</td>\n",
       "      <td>(take, 3.0E-02)</td>\n",
       "      <td>(game, 3.0E-02)</td>\n",
       "      <td>(great, 2.2E-02)</td>\n",
       "      <td>(someone, 2.2E-02)</td>\n",
       "      <td>(since, 2.1E-02)</td>\n",
       "      <td>(heard, 2.1E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>(article, 4.3E-01)</td>\n",
       "      <td>(probably, 1.3E-01)</td>\n",
       "      <td>(says, 9.4E-02)</td>\n",
       "      <td>(news, 6.1E-02)</td>\n",
       "      <td>(better, 4.7E-02)</td>\n",
       "      <td>(generated, 3.2E-02)</td>\n",
       "      <td>(want, 3.0E-02)</td>\n",
       "      <td>(reader, 2.9E-02)</td>\n",
       "      <td>(still, 2.8E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>(david, 1.3E+00)</td>\n",
       "      <td>(information, 3.3E-02)</td>\n",
       "      <td>(heard, 2.5E-02)</td>\n",
       "      <td>(true, 1.9E-02)</td>\n",
       "      <td>(going, 1.9E-02)</td>\n",
       "      <td>(university, 1.9E-02)</td>\n",
       "      <td>(read, 1.6E-02)</td>\n",
       "      <td>(taken, 1.5E-02)</td>\n",
       "      <td>(yet, 1.5E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>(1, 1.1E+00)</td>\n",
       "      <td>(00, 1.8E-02)</td>\n",
       "      <td>(800, 1.2E-02)</td>\n",
       "      <td>(12, 1.2E-02)</td>\n",
       "      <td>(000, 9.5E-03)</td>\n",
       "      <td>(internet, 8.7E-03)</td>\n",
       "      <td>(power, 8.5E-03)</td>\n",
       "      <td>(play, 7.9E-03)</td>\n",
       "      <td>(10, 7.6E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>(email, 4.5E-01)</td>\n",
       "      <td>(says, 9.8E-02)</td>\n",
       "      <td>(looking, 9.1E-02)</td>\n",
       "      <td>(replies, 8.0E-02)</td>\n",
       "      <td>(information, 7.9E-02)</td>\n",
       "      <td>(subject, 6.7E-02)</td>\n",
       "      <td>(send, 6.3E-02)</td>\n",
       "      <td>(address, 6.1E-02)</td>\n",
       "      <td>(someone, 5.2E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>(say, 8.2E-01)</td>\n",
       "      <td>(nothing, 3.2E-02)</td>\n",
       "      <td>(god, 3.1E-02)</td>\n",
       "      <td>(means, 2.9E-02)</td>\n",
       "      <td>(anything, 2.8E-02)</td>\n",
       "      <td>(computer, 2.7E-02)</td>\n",
       "      <td>(phone, 2.5E-02)</td>\n",
       "      <td>(sorry, 2.4E-02)</td>\n",
       "      <td>(believe, 2.0E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>(one, 8.3E-01)</td>\n",
       "      <td>(another, 1.9E-02)</td>\n",
       "      <td>(prevented, 7.8E-03)</td>\n",
       "      <td>(diving, 5.4E-03)</td>\n",
       "      <td>(10, 4.2E-03)</td>\n",
       "      <td>(bad, 3.9E-03)</td>\n",
       "      <td>(idea, 3.2E-03)</td>\n",
       "      <td>(man, 3.2E-03)</td>\n",
       "      <td>(info, 3.1E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>(people, 6.6E-01)</td>\n",
       "      <td>(government, 2.0E-02)</td>\n",
       "      <td>(things, 1.5E-02)</td>\n",
       "      <td>(person, 1.1E-02)</td>\n",
       "      <td>(world, 1.1E-02)</td>\n",
       "      <td>(put, 1.1E-02)</td>\n",
       "      <td>(let, 1.0E-02)</td>\n",
       "      <td>(state, 1.0E-02)</td>\n",
       "      <td>(believe, 9.9E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>(know, 8.5E-01)</td>\n",
       "      <td>(let, 3.2E-02)</td>\n",
       "      <td>(anybody, 2.6E-02)</td>\n",
       "      <td>(really, 2.4E-02)</td>\n",
       "      <td>(appreciated, 2.2E-02)</td>\n",
       "      <td>(anything, 2.1E-02)</td>\n",
       "      <td>(program, 1.3E-02)</td>\n",
       "      <td>(help, 1.1E-02)</td>\n",
       "      <td>(windows, 1.1E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>(think, 8.2E-01)</td>\n",
       "      <td>(really, 3.8E-02)</td>\n",
       "      <td>(doug, 1.2E-02)</td>\n",
       "      <td>(ever, 1.1E-02)</td>\n",
       "      <td>(thought, 1.0E-02)</td>\n",
       "      <td>(team, 1.0E-02)</td>\n",
       "      <td>(familiar, 9.8E-03)</td>\n",
       "      <td>(take, 9.0E-03)</td>\n",
       "      <td>(called, 9.0E-03)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic         composition 0           composition 1         composition 2  \\\n",
       "0       0          (3, 7.3E-01)      (windows, 1.5E-01)         (ax, 6.2E-02)   \n",
       "1       1       (work, 3.3E-01)      (problem, 2.0E-01)       (back, 1.0E-01)   \n",
       "2       2       (like, 7.9E-01)       (things, 1.6E-02)       (look, 1.3E-02)   \n",
       "3       3      (could, 6.9E-01)      (someone, 8.5E-02)       (tell, 5.6E-02)   \n",
       "4       4       (good, 8.4E-01)         (luck, 1.1E-01)        (bad, 3.9E-02)   \n",
       "5       5    (article, 6.8E-01)       (writes, 1.7E-02)      (wrote, 1.2E-02)   \n",
       "6       6       (also, 6.6E-01)  (information, 1.6E-02)      (might, 1.6E-02)   \n",
       "7       7      (right, 7.1E-01)         (left, 6.2E-02)     (writes, 3.5E-02)   \n",
       "8       8     (writes, 4.3E-01)      (article, 2.2E-01)    (someone, 1.2E-02)   \n",
       "9       9  (something, 6.0E-01)         (name, 1.9E-01)      (group, 1.9E-01)   \n",
       "10     10       (want, 3.4E-01)          (one, 2.1E-01)        (god, 1.6E-01)   \n",
       "11     11     (writes, 5.6E-01)     (question, 7.3E-03)      (state, 6.8E-03)   \n",
       "12     12       (post, 4.5E-01)         (real, 3.0E-01)    (message, 1.2E-01)   \n",
       "13     13        (two, 5.0E-01)         (game, 3.0E-02)      (wrote, 2.6E-02)   \n",
       "14     14          (5, 3.5E-01)            (4, 3.5E-01)          (8, 9.3E-02)   \n",
       "15     15        (may, 6.5E-01)        (going, 1.9E-02)       (soon, 1.5E-02)   \n",
       "16     16        (lot, 1.4E+00)      (address, 3.1E-02)       (help, 2.6E-02)   \n",
       "17     17       (many, 6.3E-01)         (take, 4.0E-02)       (jews, 3.5E-02)   \n",
       "18     18       (even, 5.3E-01)         (find, 4.3E-02)     (though, 2.3E-02)   \n",
       "19     19       (time, 6.6E-01)         (long, 3.4E-02)      (since, 2.8E-02)   \n",
       "20     20       (said, 3.2E-01)        (never, 2.5E-01)     (really, 1.0E-01)   \n",
       "21     21        (see, 5.0E-01)      (believe, 2.9E-02)      (going, 2.9E-02)   \n",
       "22     22     (anyone, 8.0E-01)        (heard, 3.5E-02)    (advance, 3.2E-02)   \n",
       "23     23     (system, 6.4E-01)        (frank, 1.2E-01)   (computer, 4.2E-02)   \n",
       "24     24        (new, 7.1E-01)         (sale, 3.1E-02)      (brand, 2.6E-02)   \n",
       "25     25       (need, 7.8E-01)         (help, 7.5E-02)    (program, 3.4E-02)   \n",
       "26     26        (get, 8.2E-01)         (life, 3.0E-02)       (real, 2.7E-02)   \n",
       "27     27       (well, 6.4E-01)         (must, 3.8E-02)     (better, 2.1E-02)   \n",
       "28     28       (test, 2.8E+00)      (message, 1.9E-01)       (help, 1.2E-02)   \n",
       "29     29          (0, 1.2E+00)      (problem, 4.3E-02)          (6, 4.2E-02)   \n",
       "30     30         (go, 8.8E-01)         (home, 8.2E-02)        (let, 5.2E-02)   \n",
       "31     31        (way, 7.4E-01)      (monitor, 4.7E-02)       (mike, 4.6E-02)   \n",
       "32     32          (2, 9.2E-01)            (8, 1.9E-02)         (os, 1.7E-02)   \n",
       "33     33       (make, 6.2E-01)        (drive, 4.9E-02)      (offer, 4.2E-02)   \n",
       "34     34       (much, 6.4E-01)        (makes, 5.3E-02)      (exist, 3.6E-02)   \n",
       "35     35      (first, 4.8E-01)         (year, 6.4E-02)      (going, 4.4E-02)   \n",
       "36     36       (used, 6.0E-01)      (looking, 5.7E-02)   (actually, 3.8E-02)   \n",
       "37     37         (us, 5.0E-01)          (god, 4.5E-02)      (guess, 3.7E-02)   \n",
       "38     38       (mail, 6.2E-01)      (address, 7.7E-02)    (looking, 5.7E-02)   \n",
       "39     39        (use, 6.7E-01)         (want, 3.7E-02)      (using, 3.6E-02)   \n",
       "40     40       (sure, 5.7E-01)         (mark, 1.8E-01)  (advantage, 9.9E-02)   \n",
       "41     41    (article, 4.3E-01)     (probably, 1.3E-01)       (says, 9.4E-02)   \n",
       "42     42      (david, 1.3E+00)  (information, 3.3E-02)      (heard, 2.5E-02)   \n",
       "43     43          (1, 1.1E+00)           (00, 1.8E-02)        (800, 1.2E-02)   \n",
       "44     44      (email, 4.5E-01)         (says, 9.8E-02)    (looking, 9.1E-02)   \n",
       "45     45        (say, 8.2E-01)      (nothing, 3.2E-02)        (god, 3.1E-02)   \n",
       "46     46        (one, 8.3E-01)      (another, 1.9E-02)  (prevented, 7.8E-03)   \n",
       "47     47     (people, 6.6E-01)   (government, 2.0E-02)     (things, 1.5E-02)   \n",
       "48     48       (know, 8.5E-01)          (let, 3.2E-02)    (anybody, 2.6E-02)   \n",
       "49     49      (think, 8.2E-01)       (really, 3.8E-02)       (doug, 1.2E-02)   \n",
       "\n",
       "          composition 3           composition 4           composition 5  \\\n",
       "0      (files, 3.0E-02)          (dos, 2.5E-02)      (version, 2.4E-02)   \n",
       "1      (drive, 4.6E-02)        (using, 3.4E-02)          (try, 3.1E-02)   \n",
       "2        (etc, 1.2E-02)       (sounds, 9.4E-03)        (looks, 8.4E-03)   \n",
       "3       (find, 4.1E-02)      (advance, 3.1E-02)  (information, 2.0E-02)   \n",
       "4     (trying, 3.1E-02)          (jim, 2.5E-02)     (comments, 1.8E-02)   \n",
       "5       (read, 9.2E-03)         (long, 5.8E-03)         (mean, 5.1E-03)   \n",
       "6      (point, 1.6E-02)          (car, 1.3E-02)       (called, 1.3E-02)   \n",
       "7       (bill, 2.8E-02)      (article, 2.7E-02)        (wrong, 2.5E-02)   \n",
       "8        (day, 4.8E-03)         (john, 4.5E-03)         (back, 4.0E-03)   \n",
       "9   (anything, 3.4E-02)          (yet, 2.6E-02)        (wrong, 2.4E-02)   \n",
       "10   (believe, 4.1E-02)       (things, 4.0E-02)        (thing, 3.6E-02)   \n",
       "11     (since, 6.8E-03)          (yes, 5.5E-03)        (keith, 5.2E-03)   \n",
       "12      (life, 9.2E-02)     (question, 8.8E-02)      (posting, 6.1E-02)   \n",
       "13     (years, 2.3E-02)        (three, 2.3E-02)         (last, 2.2E-02)   \n",
       "14         (6, 8.2E-02)        (drive, 7.8E-02)            (7, 7.1E-02)   \n",
       "15     (issue, 1.5E-02)     (anything, 1.5E-02)          (try, 1.4E-02)   \n",
       "16      (send, 2.5E-02)         (year, 2.2E-02)      (clinton, 1.8E-02)   \n",
       "17     (years, 3.3E-02)      (believe, 2.7E-02)        (still, 2.7E-02)   \n",
       "18    (really, 2.1E-02)      (believe, 1.9E-02)    (available, 1.8E-02)   \n",
       "19      (read, 1.5E-02)         (take, 1.5E-02)        (every, 1.4E-02)   \n",
       "20   (believe, 4.4E-02)          (god, 4.3E-02)        (going, 3.6E-02)   \n",
       "21    (really, 2.7E-02)         (look, 2.7E-02)         (love, 2.5E-02)   \n",
       "22      (find, 3.2E-02)     (anything, 3.0E-02)  (information, 2.6E-02)   \n",
       "23       (key, 3.6E-02)      (windows, 3.4E-02)        (using, 3.2E-02)   \n",
       "24     (price, 2.3E-02)         (york, 2.2E-02)   (university, 1.9E-02)   \n",
       "25      (card, 2.9E-02)      (windows, 2.9E-02)          (run, 2.1E-02)   \n",
       "26    (source, 1.8E-02)        (going, 1.6E-02)         (help, 1.1E-02)   \n",
       "27     (still, 1.7E-02)       (really, 1.5E-02)        (bible, 1.5E-02)   \n",
       "28   (another, 8.2E-03)       (serial, 5.9E-03)         (port, 5.5E-03)   \n",
       "29         (7, 3.6E-02)         (file, 3.4E-02)          (try, 3.3E-02)   \n",
       "30     (heavy, 4.9E-02)          (red, 3.0E-02)         (blue, 2.4E-02)   \n",
       "31      (best, 3.4E-02)       (window, 2.7E-02)        (tracy, 1.9E-02)   \n",
       "32   (version, 1.6E-02)          (key, 1.5E-02)           (16, 1.5E-02)   \n",
       "33     (local, 2.1E-02)         (long, 1.9E-02)    (necessary, 1.8E-02)   \n",
       "34      (help, 2.2E-02)      (someone, 2.2E-02)       (better, 2.1E-02)   \n",
       "35      (last, 3.6E-02)       (second, 3.5E-02)         (give, 2.7E-02)   \n",
       "36     (video, 3.3E-02)      (windows, 2.5E-02)        (sound, 2.4E-02)   \n",
       "37       (car, 3.6E-02)         (1993, 3.3E-02)        (world, 3.1E-02)   \n",
       "38   (monitor, 5.3E-02)         (send, 5.0E-02)         (help, 4.8E-02)   \n",
       "39   (windows, 3.3E-02)         (help, 2.2E-02)       (window, 1.8E-02)   \n",
       "40      (take, 3.0E-02)         (game, 3.0E-02)        (great, 2.2E-02)   \n",
       "41      (news, 6.1E-02)       (better, 4.7E-02)    (generated, 3.2E-02)   \n",
       "42      (true, 1.9E-02)        (going, 1.9E-02)   (university, 1.9E-02)   \n",
       "43        (12, 1.2E-02)          (000, 9.5E-03)     (internet, 8.7E-03)   \n",
       "44   (replies, 8.0E-02)  (information, 7.9E-02)      (subject, 6.7E-02)   \n",
       "45     (means, 2.9E-02)     (anything, 2.8E-02)     (computer, 2.7E-02)   \n",
       "46    (diving, 5.4E-03)           (10, 4.2E-03)          (bad, 3.9E-03)   \n",
       "47    (person, 1.1E-02)        (world, 1.1E-02)          (put, 1.1E-02)   \n",
       "48    (really, 2.4E-02)  (appreciated, 2.2E-02)     (anything, 2.1E-02)   \n",
       "49      (ever, 1.1E-02)      (thought, 1.0E-02)         (team, 1.0E-02)   \n",
       "\n",
       "            composition 6         composition 7          composition 8  \n",
       "0       (driver, 2.3E-02)       (card, 2.3E-02)        (file, 2.2E-02)  \n",
       "1          (got, 3.0E-02)      (might, 2.1E-02)       (works, 2.0E-02)  \n",
       "2          (got, 7.8E-03)     (around, 7.7E-03)     (someone, 7.6E-03)  \n",
       "3         (kind, 1.9E-02)      (point, 1.8E-02)   (wondering, 1.6E-02)  \n",
       "4       (better, 1.4E-02)      (might, 1.3E-02)        (give, 1.3E-02)  \n",
       "5   (university, 5.1E-03)       (file, 4.9E-03)       (steve, 4.9E-03)  \n",
       "6        (three, 1.2E-02)    (looking, 1.2E-02)       (heard, 1.1E-02)  \n",
       "7        (might, 2.5E-02)       (side, 2.4E-02)        (keep, 2.2E-02)  \n",
       "8         (ever, 4.0E-03)        (dod, 3.7E-03)         (jim, 3.7E-03)  \n",
       "9         (read, 2.2E-02)      (using, 1.9E-02)        (else, 1.8E-02)  \n",
       "10       (jesus, 2.4E-02)       (must, 2.1E-02)       (point, 2.0E-02)  \n",
       "11     (nothing, 5.1E-03)       (case, 5.1E-03)  (university, 4.9E-03)  \n",
       "12       (tests, 4.0E-02)       (suck, 3.2E-02)      (closed, 2.8E-02)  \n",
       "13       (power, 1.9E-02)       (take, 1.7E-02)        (team, 1.7E-02)  \n",
       "14          (10, 3.7E-02)          (9, 3.0E-02)          (25, 2.0E-02)  \n",
       "15      (window, 1.3E-02)      (power, 1.3E-02)       (orbit, 1.3E-02)  \n",
       "16       (white, 1.6E-02)       (high, 1.6E-02)       (house, 1.6E-02)  \n",
       "17      (answer, 1.7E-02)  (countries, 1.6E-02)        (fact, 1.6E-02)  \n",
       "18        (done, 1.6E-02)      (might, 1.6E-02)     (thought, 1.5E-02)  \n",
       "19       (years, 1.1E-02)     (around, 1.0E-02)        (love, 9.6E-03)  \n",
       "20      (writes, 3.4E-02)       (made, 1.9E-02)        (keep, 1.7E-02)  \n",
       "21        (long, 2.3E-02)      (since, 1.9E-02)      (rather, 1.6E-02)  \n",
       "22        (help, 2.0E-02)       (info, 2.0E-02)       (going, 1.8E-02)  \n",
       "23       (phone, 2.8E-02)    (problem, 2.2E-02)     (systems, 2.0E-02)  \n",
       "24          (00, 1.8E-02)         (50, 1.7E-02)         (try, 1.5E-02)  \n",
       "25        (find, 2.0E-02)       (take, 1.9E-02)      (really, 1.7E-02)  \n",
       "26         (ftp, 1.0E-02)       (back, 9.8E-03)      (rather, 9.6E-03)  \n",
       "27       (might, 1.5E-02)       (back, 1.4E-02)        (else, 1.3E-02)  \n",
       "28       (might, 5.0E-03)  (connector, 4.9E-03)        (says, 4.7E-03)  \n",
       "29        (tell, 2.7E-02)        (dos, 2.7E-02)         (255, 2.4E-02)  \n",
       "30       (wings, 2.3E-02)       (back, 2.2E-02)        (mike, 2.0E-02)  \n",
       "31        (find, 1.7E-02)      (going, 1.6E-02)     (another, 1.5E-02)  \n",
       "32         (bit, 1.4E-02)    (support, 1.3E-02)        (scsi, 1.3E-02)  \n",
       "33        (chip, 1.8E-02)       (room, 1.7E-02)      (enough, 1.6E-02)  \n",
       "34        (case, 1.9E-02)     (pretty, 1.7E-02)        (cost, 1.7E-02)  \n",
       "35         (got, 2.6E-02)   (remember, 2.2E-02)       (thing, 1.6E-02)  \n",
       "36        (help, 2.4E-02)      (point, 1.8E-02)       (using, 1.7E-02)  \n",
       "37         (let, 2.8E-02)      (makes, 2.8E-02)  (government, 2.7E-02)  \n",
       "38     (advance, 3.9E-02)       (list, 3.6E-02)         (vga, 3.5E-02)  \n",
       "39     (program, 1.7E-02)   (hardware, 1.7E-02)    (software, 1.5E-02)  \n",
       "40     (someone, 2.2E-02)      (since, 2.1E-02)       (heard, 2.1E-02)  \n",
       "41        (want, 3.0E-02)     (reader, 2.9E-02)       (still, 2.8E-02)  \n",
       "42        (read, 1.6E-02)      (taken, 1.5E-02)         (yet, 1.5E-02)  \n",
       "43       (power, 8.5E-03)       (play, 7.9E-03)          (10, 7.6E-03)  \n",
       "44        (send, 6.3E-02)    (address, 6.1E-02)     (someone, 5.2E-02)  \n",
       "45       (phone, 2.5E-02)      (sorry, 2.4E-02)     (believe, 2.0E-02)  \n",
       "46        (idea, 3.2E-03)        (man, 3.2E-03)        (info, 3.1E-03)  \n",
       "47         (let, 1.0E-02)      (state, 1.0E-02)     (believe, 9.9E-03)  \n",
       "48     (program, 1.3E-02)       (help, 1.1E-02)     (windows, 1.1E-02)  \n",
       "49    (familiar, 9.8E-03)       (take, 9.0E-03)      (called, 9.0E-03)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top3 topics of each group\n",
      "group 0                    alt.atheism topic11(2.5e-02) topic08(1.8e-02) topic05(1.1e-02)\n",
      "group 1                  comp.graphics topic11(1.0e-02) topic48(6.8e-03) topic08(6.4e-03)\n",
      "group 2        comp.os.ms-windows.misc topic11(1.0e-02) topic00(8.8e-03) topic08(7.0e-03)\n",
      "group 3       comp.sys.ibm.pc.hardware topic46(7.9e-03) topic11(7.1e-03) topic01(6.5e-03)\n",
      "group 4          comp.sys.mac.hardware topic11(1.1e-02) topic46(8.8e-03) topic01(7.4e-03)\n",
      "group 5                 comp.windows.x topic11(7.1e-03) topic02(5.9e-03) topic08(5.8e-03)\n",
      "group 6                   misc.forsale topic14(7.9e-03) topic32(7.2e-03) topic43(6.9e-03)\n",
      "group 7                      rec.autos topic11(1.6e-02) topic08(1.2e-02) topic05(9.9e-03)\n",
      "group 8                rec.motorcycles topic08(2.0e-02) topic11(1.6e-02) topic05(1.1e-02)\n",
      "group 9             rec.sport.baseball topic08(1.7e-02) topic11(1.7e-02) topic05(9.1e-03)\n",
      "group10               rec.sport.hockey topic11(1.4e-02) topic08(1.0e-02) topic46(6.3e-03)\n",
      "group11                      sci.crypt topic11(1.7e-02) topic08(8.5e-03) topic46(6.9e-03)\n",
      "group12                sci.electronics topic11(1.2e-02) topic46(8.8e-03) topic08(7.1e-03)\n",
      "group13                        sci.med topic11(1.6e-02) topic05(1.1e-02) topic08(1.0e-02)\n",
      "group14                      sci.space topic11(1.7e-02) topic08(1.2e-02) topic05(9.1e-03)\n",
      "group15         soc.religion.christian topic11(1.2e-02) topic10(1.0e-02) topic46(7.4e-03)\n",
      "group16             talk.politics.guns topic11(1.5e-02) topic08(1.3e-02) topic05(8.1e-03)\n",
      "group17          talk.politics.mideast topic11(1.5e-02) topic08(1.2e-02) topic05(8.7e-03)\n",
      "group18             talk.politics.misc topic11(2.1e-02) topic08(1.6e-02) topic05(1.1e-02)\n",
      "group19             talk.religion.misc topic11(1.8e-02) topic08(1.5e-02) topic05(1.1e-02)\n",
      "top3 groups of each topic\n",
      "topic0   comp.os.ms-windows.misc(3.8e-03)              misc.forsale(3.8e-03)            comp.windows.x(3.4e-03)\n",
      "topic1     comp.sys.mac.hardware(6.5e-03)  comp.sys.ibm.pc.hardware(6.5e-03)   comp.os.ms-windows.misc(5.8e-03)\n",
      "topic2           rec.motorcycles(6.7e-03)                 rec.autos(6.7e-03)           sci.electronics(6.3e-03)\n",
      "topic3               alt.atheism(3.7e-03)                 sci.crypt(3.7e-03)     comp.sys.mac.hardware(3.7e-03)\n",
      "topic4                 rec.autos(3.0e-03)           sci.electronics(3.0e-03)        rec.sport.baseball(2.9e-03)\n",
      "topic5                   sci.med(1.1e-02)        talk.religion.misc(1.1e-02)        talk.politics.misc(1.1e-02)\n",
      "topic6  comp.sys.ibm.pc.hardware(3.9e-03)                   sci.med(3.9e-03)    soc.religion.christian(3.8e-03)\n",
      "topic7        talk.politics.guns(2.3e-03)           rec.motorcycles(2.3e-03)                 rec.autos(1.9e-03)\n",
      "topic8           rec.motorcycles(1.8e-02)               alt.atheism(1.8e-02)        rec.sport.baseball(1.7e-02)\n",
      "topic9               alt.atheism(2.4e-03)            comp.windows.x(2.4e-03)   comp.os.ms-windows.misc(2.3e-03)\n",
      "topic10    soc.religion.christian(7.9e-03)               alt.atheism(7.9e-03)        talk.religion.misc(7.0e-03)\n",
      "topic11               alt.atheism(2.1e-02)        talk.politics.misc(2.1e-02)        talk.religion.misc(1.8e-02)\n",
      "topic12    soc.religion.christian(1.7e-03)             comp.graphics(1.7e-03)               alt.atheism(1.7e-03)\n",
      "topic13          rec.sport.hockey(3.9e-03)        rec.sport.baseball(3.9e-03)                 sci.crypt(2.9e-03)\n",
      "topic14              misc.forsale(5.8e-03)          rec.sport.hockey(5.8e-03)  comp.sys.ibm.pc.hardware(5.4e-03)\n",
      "topic15    soc.religion.christian(2.5e-03)                 sci.space(2.5e-03)        talk.religion.misc(2.4e-03)\n",
      "topic16           sci.electronics(5.8e-04)        rec.sport.baseball(5.8e-04)             comp.graphics(5.1e-04)\n",
      "topic17     talk.politics.mideast(2.5e-03)               alt.atheism(2.5e-03)        talk.religion.misc(2.3e-03)\n",
      "topic18                 sci.crypt(3.6e-03)               alt.atheism(3.6e-03)        talk.politics.guns(3.6e-03)\n",
      "topic19                   sci.med(3.7e-03)          rec.sport.hockey(3.7e-03)        rec.sport.baseball(3.6e-03)\n",
      "topic20               alt.atheism(4.3e-03)        talk.religion.misc(4.3e-03)     talk.politics.mideast(3.7e-03)\n",
      "topic21        talk.religion.misc(3.9e-03)          rec.sport.hockey(3.9e-03)    soc.religion.christian(3.8e-03)\n",
      "topic22             comp.graphics(5.3e-03)           sci.electronics(5.3e-03)   comp.os.ms-windows.misc(4.8e-03)\n",
      "topic23  comp.sys.ibm.pc.hardware(3.6e-03)   comp.os.ms-windows.misc(3.6e-03)                 sci.crypt(3.5e-03)\n",
      "topic24              misc.forsale(3.8e-03)     comp.sys.mac.hardware(3.8e-03)                 rec.autos(3.6e-03)\n",
      "topic25             comp.graphics(2.6e-03)  comp.sys.ibm.pc.hardware(2.6e-03)     comp.sys.mac.hardware(2.5e-03)\n",
      "topic26            comp.windows.x(5.4e-03)     comp.sys.mac.hardware(5.4e-03)  comp.sys.ibm.pc.hardware(5.3e-03)\n",
      "topic27               alt.atheism(3.5e-03)        talk.politics.guns(3.5e-03)        rec.sport.baseball(3.2e-03)\n",
      "topic28     comp.sys.mac.hardware(1.9e-04)              misc.forsale(1.9e-04)           rec.motorcycles(1.8e-04)\n",
      "topic29   comp.os.ms-windows.misc(1.5e-03)          rec.sport.hockey(1.5e-03)        rec.sport.baseball(1.4e-03)\n",
      "topic30          rec.sport.hockey(2.5e-03)        rec.sport.baseball(2.5e-03)           rec.motorcycles(1.6e-03)\n",
      "topic31            comp.windows.x(2.2e-03)        talk.religion.misc(2.2e-03)    soc.religion.christian(2.2e-03)\n",
      "topic32              misc.forsale(5.5e-03)  comp.sys.ibm.pc.hardware(5.5e-03)   comp.os.ms-windows.misc(4.3e-03)\n",
      "topic33              misc.forsale(2.7e-03)                 sci.crypt(2.7e-03)        talk.politics.misc(2.7e-03)\n",
      "topic34                 rec.autos(2.9e-03)        rec.sport.baseball(2.9e-03)     comp.sys.mac.hardware(2.7e-03)\n",
      "topic35        rec.sport.baseball(4.7e-03)          rec.sport.hockey(4.7e-03)                 sci.space(3.2e-03)\n",
      "topic36              misc.forsale(3.2e-03)           sci.electronics(3.2e-03)  comp.sys.ibm.pc.hardware(2.3e-03)\n",
      "topic37    soc.religion.christian(3.2e-03)        talk.religion.misc(3.2e-03)        talk.politics.misc(3.1e-03)\n",
      "topic38              misc.forsale(3.6e-03)             comp.graphics(3.6e-03)   comp.os.ms-windows.misc(3.4e-03)\n",
      "topic39   comp.os.ms-windows.misc(5.7e-03)           sci.electronics(5.7e-03)            comp.windows.x(5.6e-03)\n",
      "topic40                 rec.autos(1.9e-03)                   sci.med(1.9e-03)          rec.sport.hockey(1.5e-03)\n",
      "topic41        rec.sport.baseball(4.9e-03)        talk.politics.misc(4.9e-03)        talk.religion.misc(4.1e-03)\n",
      "topic42          rec.sport.hockey(6.9e-04)        talk.religion.misc(6.9e-04)        rec.sport.baseball(6.9e-04)\n",
      "topic43              misc.forsale(6.6e-03)   comp.os.ms-windows.misc(6.6e-03)          rec.sport.hockey(5.6e-03)\n",
      "topic44              misc.forsale(4.0e-03)             comp.graphics(4.0e-03)  comp.sys.ibm.pc.hardware(3.2e-03)\n",
      "topic45               alt.atheism(2.6e-03)    soc.religion.christian(2.6e-03)        talk.religion.misc(2.0e-03)\n",
      "topic46               alt.atheism(9.3e-03)           rec.motorcycles(9.3e-03)                   sci.med(8.9e-03)\n",
      "topic47        talk.politics.misc(7.6e-03)               alt.atheism(7.6e-03)        talk.politics.guns(7.3e-03)\n",
      "topic48     comp.sys.mac.hardware(6.8e-03)             comp.graphics(6.8e-03)   comp.os.ms-windows.misc(6.8e-03)\n",
      "topic49               alt.atheism(4.6e-03)        rec.sport.baseball(4.6e-03)    soc.religion.christian(4.1e-03)\n"
     ]
    }
   ],
   "source": [
    "nmf_lsa.print_mat(max_docs=5, max_topics=100, max_terms=9)\n",
    "print_lsa(nmf_lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pLSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want 50 topics\n",
      "[    0] dH 173895.70973173284\n",
      "[    0] dW 0.11816001402210731\n",
      "[   10] dH 41.773584490586764\n",
      "[   10] dW 0.006645139083345059\n",
      "[   20] dH 8.98491863021317\n",
      "[   20] dW 0.00028229378174448835\n",
      "[   30] dH 3.343579219352734\n",
      "[   30] dW 9.034181496091312e-05\n",
      "[   40] dH 1.7624504493399509\n",
      "[   40] dW 3.218441046047253e-05\n",
      "[   50] dH 1.160784158410206\n",
      "[   50] dW 6.567969224494409e-05\n",
      "[   60] dH 0.7892368046862805\n",
      "[   60] dW 3.308397151439138e-05\n",
      "[   70] dH 0.6084475894305674\n",
      "[   70] dW 3.360505659416626e-05\n",
      "[   80] dH 0.45938732979903235\n",
      "[   80] dW 2.2021196922845833e-05\n",
      "[   90] dH 0.5535831056824669\n",
      "[   90] dW 1.4447270712491941e-05\n",
      "[  100] dH 0.3660870787632098\n",
      "[  100] dW 9.720413423398238e-06\n",
      "[  110] dH 0.2842112216101363\n",
      "[  110] dW 1.6193646719364028e-05\n",
      "[  120] dH 0.45585382889968656\n",
      "[  120] dW 4.882473005676725e-06\n",
      "[  130] dH 0.27878276957971215\n",
      "[  130] dW 3.1552029650363004e-06\n",
      "[  140] dH 0.18544396061112492\n",
      "[  140] dW 2.2683733909992503e-06\n",
      "[  150] dH 0.20885763551700245\n",
      "[  150] dW 1.8278532719634226e-06\n",
      "[  160] dH 0.12771181245433536\n",
      "[  160] dW 1.3555684216815978e-06\n",
      "[  170] dH 0.14696132563489617\n",
      "[  170] dW 1.2338813009008188e-06\n",
      "[  180] dH 0.220157043851698\n",
      "[  180] dW 9.484835646945795e-07\n",
      "[  190] dH 0.13385845686548034\n",
      "[  190] dW 9.473206392992686e-07\n",
      "[  200] dH 0.08208785732720172\n",
      "[  200] dW 6.366753027196776e-07\n",
      "[  210] dH 0.07859522291549727\n",
      "[  210] dW 7.066818342626767e-07\n",
      "[  220] dH 0.07508837033592525\n",
      "[  220] dW 5.471124818758946e-07\n",
      "[  230] dH 0.06700696483263545\n",
      "[  230] dW 5.767722917182705e-07\n",
      "[  240] dH 0.05646648364381541\n",
      "[  240] dW 5.199915215266623e-07\n",
      "[  250] dH 0.051275734869384276\n",
      "[  250] dW 4.905911569973614e-07\n",
      "[  260] dH 0.04996851626433327\n",
      "[  260] dW 5.734000695975734e-07\n",
      "[  270] dH 0.06128856535878671\n",
      "[  270] dW 5.454852986984146e-07\n",
      "[  280] dH 0.06149379379585188\n",
      "[  280] dW 4.679048189330236e-07\n",
      "[  290] dH 0.0466178885752125\n",
      "[  290] dW 2.757826006854645e-07\n",
      "[  300] dH 0.03627029552411664\n",
      "[  300] dW 2.76157901920571e-07\n",
      "[  310] dH 0.031967289202574314\n",
      "[  310] dW 2.3425906348008448e-07\n",
      "[  320] dH 0.026281901889749673\n",
      "[  320] dW 2.1258592170285367e-07\n",
      "[  330] dH 0.0342995093444011\n",
      "[  330] dW 3.0743571591160627e-07\n",
      "[  340] dH 0.0247959390320971\n",
      "[  340] dW 2.370871971705406e-07\n",
      "[  350] dH 0.026131077069470578\n",
      "[  350] dW 1.8479960695269804e-07\n",
      "[  360] dH 0.026962048403949265\n",
      "[  360] dW 2.69765993583969e-07\n",
      "[  370] dH 0.020303460186984576\n",
      "[  370] dW 1.48189988506516e-07\n",
      "[  380] dH 0.021032525806461526\n",
      "[  380] dW 1.3381566464098216e-07\n",
      "[  390] dH 0.02214983885215203\n",
      "[  390] dW 1.3916976870841426e-07\n",
      "14min 57s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#N_topics = 3+0*min(3, n_catogories)\n",
    "print(\"We want %d topics\"%N_topics)\n",
    "\n",
    "plsa=pLSA()\n",
    "plsa.set_structured_documents(email_sdocs)\n",
    "def on_update(i, W, H, Wold, Hold):\n",
    "    if i % 10 == 0:\n",
    "        dH = H - Hold\n",
    "        dW = W - Wold\n",
    "        print(\"[%5d] dH\"%i, np.einsum(\"ij,ij\", dH, dH))\n",
    "        print(\"[%5d] dW\"%i, np.einsum(\"ij,ij\", dW, dW))\n",
    "%timeit -r1 -n1 plsa.topic_decompose(ntopics=N_topics, max_iters=400, on_update=on_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "      <th>composition 2</th>\n",
       "      <th>composition 3</th>\n",
       "      <th>composition 4</th>\n",
       "      <th>composition 5</th>\n",
       "      <th>composition 6</th>\n",
       "      <th>composition 7</th>\n",
       "      <th>composition 8</th>\n",
       "      <th>...</th>\n",
       "      <th>composition 40</th>\n",
       "      <th>composition 41</th>\n",
       "      <th>composition 42</th>\n",
       "      <th>composition 43</th>\n",
       "      <th>composition 44</th>\n",
       "      <th>composition 45</th>\n",
       "      <th>composition 46</th>\n",
       "      <th>composition 47</th>\n",
       "      <th>composition 48</th>\n",
       "      <th>composition 49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(9, 6.6E-01)</td>\n",
       "      <td>(29, 2.0E-01)</td>\n",
       "      <td>(23, 7.9E-02)</td>\n",
       "      <td>(24, 3.3E-02)</td>\n",
       "      <td>(30, 2.1E-02)</td>\n",
       "      <td>(47, 1.5E-07)</td>\n",
       "      <td>(3, 9.2E-09)</td>\n",
       "      <td>(17, 5.3E-09)</td>\n",
       "      <td>(43, 3.5E-09)</td>\n",
       "      <td>...</td>\n",
       "      <td>(41, 7.8E-17)</td>\n",
       "      <td>(28, 8.5E-19)</td>\n",
       "      <td>(5, 3.9E-22)</td>\n",
       "      <td>(4, 1.1E-22)</td>\n",
       "      <td>(1, 6.6E-34)</td>\n",
       "      <td>(33, 1.4E-34)</td>\n",
       "      <td>(16, 9.3E-40)</td>\n",
       "      <td>(19, 1.1E-42)</td>\n",
       "      <td>(7, 2.6E-57)</td>\n",
       "      <td>(25, 4.2E-66)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(2, 4.6E-01)</td>\n",
       "      <td>(47, 1.8E-01)</td>\n",
       "      <td>(6, 8.3E-02)</td>\n",
       "      <td>(29, 7.7E-02)</td>\n",
       "      <td>(21, 5.4E-02)</td>\n",
       "      <td>(12, 3.9E-02)</td>\n",
       "      <td>(42, 3.2E-02)</td>\n",
       "      <td>(38, 2.9E-02)</td>\n",
       "      <td>(32, 2.6E-02)</td>\n",
       "      <td>...</td>\n",
       "      <td>(41, 2.8E-12)</td>\n",
       "      <td>(20, 4.1E-14)</td>\n",
       "      <td>(48, 4.5E-15)</td>\n",
       "      <td>(17, 3.3E-26)</td>\n",
       "      <td>(28, 1.4E-33)</td>\n",
       "      <td>(7, 1.0E-36)</td>\n",
       "      <td>(35, 8.4E-49)</td>\n",
       "      <td>(19, 2.3E-59)</td>\n",
       "      <td>(25, 9.7E-77)</td>\n",
       "      <td>(33, 1.1E-90)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(9, 5.0E-01)</td>\n",
       "      <td>(34, 2.2E-01)</td>\n",
       "      <td>(46, 1.1E-01)</td>\n",
       "      <td>(30, 4.7E-02)</td>\n",
       "      <td>(2, 4.1E-02)</td>\n",
       "      <td>(12, 3.5E-02)</td>\n",
       "      <td>(23, 2.6E-02)</td>\n",
       "      <td>(13, 1.4E-02)</td>\n",
       "      <td>(36, 1.4E-03)</td>\n",
       "      <td>...</td>\n",
       "      <td>(14, 2.8E-28)</td>\n",
       "      <td>(48, 9.8E-33)</td>\n",
       "      <td>(44, 4.2E-42)</td>\n",
       "      <td>(26, 5.7E-43)</td>\n",
       "      <td>(19, 8.3E-46)</td>\n",
       "      <td>(35, 6.7E-46)</td>\n",
       "      <td>(29, 1.9E-46)</td>\n",
       "      <td>(27, 5.6E-62)</td>\n",
       "      <td>(25, 7.7E-68)</td>\n",
       "      <td>(7, 6.8E-78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(26, 3.1E-01)</td>\n",
       "      <td>(30, 3.0E-01)</td>\n",
       "      <td>(35, 2.2E-01)</td>\n",
       "      <td>(25, 1.4E-01)</td>\n",
       "      <td>(28, 4.0E-02)</td>\n",
       "      <td>(5, 3.3E-05)</td>\n",
       "      <td>(14, 5.0E-09)</td>\n",
       "      <td>(2, 4.4E-09)</td>\n",
       "      <td>(37, 4.8E-10)</td>\n",
       "      <td>...</td>\n",
       "      <td>(17, 1.7E-29)</td>\n",
       "      <td>(27, 3.7E-33)</td>\n",
       "      <td>(1, 1.6E-34)</td>\n",
       "      <td>(19, 6.0E-41)</td>\n",
       "      <td>(23, 1.4E-52)</td>\n",
       "      <td>(16, 9.4E-55)</td>\n",
       "      <td>(4, 1.3E-73)</td>\n",
       "      <td>(47, 5.3E-76)</td>\n",
       "      <td>(7, 5.1E-171)</td>\n",
       "      <td>(29, 1.4E-226)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(48, 7.6E-01)</td>\n",
       "      <td>(29, 2.1E-01)</td>\n",
       "      <td>(23, 3.7E-02)</td>\n",
       "      <td>(7, 3.0E-06)</td>\n",
       "      <td>(47, 3.3E-09)</td>\n",
       "      <td>(35, 2.6E-09)</td>\n",
       "      <td>(12, 1.5E-09)</td>\n",
       "      <td>(11, 1.3E-09)</td>\n",
       "      <td>(46, 1.1E-09)</td>\n",
       "      <td>...</td>\n",
       "      <td>(22, 1.2E-10)</td>\n",
       "      <td>(3, 1.1E-10)</td>\n",
       "      <td>(6, 9.7E-11)</td>\n",
       "      <td>(18, 7.6E-11)</td>\n",
       "      <td>(16, 4.3E-11)</td>\n",
       "      <td>(1, 1.3E-11)</td>\n",
       "      <td>(31, 4.2E-12)</td>\n",
       "      <td>(19, 5.0E-18)</td>\n",
       "      <td>(26, 3.3E-19)</td>\n",
       "      <td>(30, 1.3E-101)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   document  composition 0  composition 1  composition 2  composition 3  \\\n",
       "0         0   (9, 6.6E-01)  (29, 2.0E-01)  (23, 7.9E-02)  (24, 3.3E-02)   \n",
       "1         1   (2, 4.6E-01)  (47, 1.8E-01)   (6, 8.3E-02)  (29, 7.7E-02)   \n",
       "2         2   (9, 5.0E-01)  (34, 2.2E-01)  (46, 1.1E-01)  (30, 4.7E-02)   \n",
       "3         3  (26, 3.1E-01)  (30, 3.0E-01)  (35, 2.2E-01)  (25, 1.4E-01)   \n",
       "4         4  (48, 7.6E-01)  (29, 2.1E-01)  (23, 3.7E-02)   (7, 3.0E-06)   \n",
       "\n",
       "   composition 4  composition 5  composition 6  composition 7  composition 8  \\\n",
       "0  (30, 2.1E-02)  (47, 1.5E-07)   (3, 9.2E-09)  (17, 5.3E-09)  (43, 3.5E-09)   \n",
       "1  (21, 5.4E-02)  (12, 3.9E-02)  (42, 3.2E-02)  (38, 2.9E-02)  (32, 2.6E-02)   \n",
       "2   (2, 4.1E-02)  (12, 3.5E-02)  (23, 2.6E-02)  (13, 1.4E-02)  (36, 1.4E-03)   \n",
       "3  (28, 4.0E-02)   (5, 3.3E-05)  (14, 5.0E-09)   (2, 4.4E-09)  (37, 4.8E-10)   \n",
       "4  (47, 3.3E-09)  (35, 2.6E-09)  (12, 1.5E-09)  (11, 1.3E-09)  (46, 1.1E-09)   \n",
       "\n",
       "        ...       composition 40 composition 41 composition 42 composition 43  \\\n",
       "0       ...        (41, 7.8E-17)  (28, 8.5E-19)   (5, 3.9E-22)   (4, 1.1E-22)   \n",
       "1       ...        (41, 2.8E-12)  (20, 4.1E-14)  (48, 4.5E-15)  (17, 3.3E-26)   \n",
       "2       ...        (14, 2.8E-28)  (48, 9.8E-33)  (44, 4.2E-42)  (26, 5.7E-43)   \n",
       "3       ...        (17, 1.7E-29)  (27, 3.7E-33)   (1, 1.6E-34)  (19, 6.0E-41)   \n",
       "4       ...        (22, 1.2E-10)   (3, 1.1E-10)   (6, 9.7E-11)  (18, 7.6E-11)   \n",
       "\n",
       "  composition 44 composition 45 composition 46 composition 47 composition 48  \\\n",
       "0   (1, 6.6E-34)  (33, 1.4E-34)  (16, 9.3E-40)  (19, 1.1E-42)   (7, 2.6E-57)   \n",
       "1  (28, 1.4E-33)   (7, 1.0E-36)  (35, 8.4E-49)  (19, 2.3E-59)  (25, 9.7E-77)   \n",
       "2  (19, 8.3E-46)  (35, 6.7E-46)  (29, 1.9E-46)  (27, 5.6E-62)  (25, 7.7E-68)   \n",
       "3  (23, 1.4E-52)  (16, 9.4E-55)   (4, 1.3E-73)  (47, 5.3E-76)  (7, 5.1E-171)   \n",
       "4  (16, 4.3E-11)   (1, 1.3E-11)  (31, 4.2E-12)  (19, 5.0E-18)  (26, 3.3E-19)   \n",
       "\n",
       "   composition 49  \n",
       "0   (25, 4.2E-66)  \n",
       "1   (33, 1.1E-90)  \n",
       "2    (7, 6.8E-78)  \n",
       "3  (29, 1.4E-226)  \n",
       "4  (30, 1.3E-101)  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>composition 0</th>\n",
       "      <th>composition 1</th>\n",
       "      <th>composition 2</th>\n",
       "      <th>composition 3</th>\n",
       "      <th>composition 4</th>\n",
       "      <th>composition 5</th>\n",
       "      <th>composition 6</th>\n",
       "      <th>composition 7</th>\n",
       "      <th>composition 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(israel, 2.3E-02)</td>\n",
       "      <td>(israeli, 1.6E-02)</td>\n",
       "      <td>(jews, 1.2E-02)</td>\n",
       "      <td>(arab, 8.4E-03)</td>\n",
       "      <td>(jewish, 5.8E-03)</td>\n",
       "      <td>(peace, 5.7E-03)</td>\n",
       "      <td>(people, 5.6E-03)</td>\n",
       "      <td>(land, 5.4E-03)</td>\n",
       "      <td>(arabs, 5.4E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(money, 2.0E-02)</td>\n",
       "      <td>(government, 9.3E-03)</td>\n",
       "      <td>(cost, 8.5E-03)</td>\n",
       "      <td>(pay, 8.1E-03)</td>\n",
       "      <td>(tax, 7.6E-03)</td>\n",
       "      <td>(year, 7.3E-03)</td>\n",
       "      <td>(insurance, 6.4E-03)</td>\n",
       "      <td>(private, 5.9E-03)</td>\n",
       "      <td>(billion, 5.9E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(mac, 2.0E-02)</td>\n",
       "      <td>(apple, 1.5E-02)</td>\n",
       "      <td>(bit, 1.2E-02)</td>\n",
       "      <td>(memory, 9.6E-03)</td>\n",
       "      <td>(ram, 8.8E-03)</td>\n",
       "      <td>(speed, 8.6E-03)</td>\n",
       "      <td>(32, 7.4E-03)</td>\n",
       "      <td>(simms, 7.1E-03)</td>\n",
       "      <td>(cpu, 7.1E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(said, 1.3E-02)</td>\n",
       "      <td>(people, 1.2E-02)</td>\n",
       "      <td>(one, 1.1E-02)</td>\n",
       "      <td>(us, 9.3E-03)</td>\n",
       "      <td>(armenians, 8.5E-03)</td>\n",
       "      <td>(went, 7.1E-03)</td>\n",
       "      <td>(armenian, 6.4E-03)</td>\n",
       "      <td>(came, 5.7E-03)</td>\n",
       "      <td>(know, 5.4E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(mr, 2.5E-02)</td>\n",
       "      <td>(president, 2.3E-02)</td>\n",
       "      <td>(stephanopoulos, 1.2E-02)</td>\n",
       "      <td>(think, 1.1E-02)</td>\n",
       "      <td>(going, 1.0E-02)</td>\n",
       "      <td>(people, 1.0E-02)</td>\n",
       "      <td>(said, 9.6E-03)</td>\n",
       "      <td>(know, 9.4E-03)</td>\n",
       "      <td>(jobs, 9.0E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>(image, 2.1E-02)</td>\n",
       "      <td>(software, 1.1E-02)</td>\n",
       "      <td>(jpeg, 1.1E-02)</td>\n",
       "      <td>(gif, 9.1E-03)</td>\n",
       "      <td>(images, 8.9E-03)</td>\n",
       "      <td>(bit, 7.5E-03)</td>\n",
       "      <td>(format, 7.4E-03)</td>\n",
       "      <td>(file, 6.7E-03)</td>\n",
       "      <td>(use, 6.5E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>(drive, 4.8E-02)</td>\n",
       "      <td>(scsi, 2.6E-02)</td>\n",
       "      <td>(disk, 2.1E-02)</td>\n",
       "      <td>(hard, 1.7E-02)</td>\n",
       "      <td>(drives, 1.6E-02)</td>\n",
       "      <td>(controller, 1.5E-02)</td>\n",
       "      <td>(ide, 1.2E-02)</td>\n",
       "      <td>(floppy, 9.5E-03)</td>\n",
       "      <td>(system, 9.4E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>(writes, 5.5E-02)</td>\n",
       "      <td>(article, 4.6E-02)</td>\n",
       "      <td>(think, 2.7E-02)</td>\n",
       "      <td>(like, 2.0E-02)</td>\n",
       "      <td>(know, 1.7E-02)</td>\n",
       "      <td>(one, 1.6E-02)</td>\n",
       "      <td>(people, 1.4E-02)</td>\n",
       "      <td>(get, 1.4E-02)</td>\n",
       "      <td>(say, 1.1E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>(use, 9.8E-03)</td>\n",
       "      <td>(one, 8.8E-03)</td>\n",
       "      <td>(sound, 8.3E-03)</td>\n",
       "      <td>(power, 7.0E-03)</td>\n",
       "      <td>(radio, 6.7E-03)</td>\n",
       "      <td>(audio, 6.6E-03)</td>\n",
       "      <td>(input, 6.4E-03)</td>\n",
       "      <td>(output, 5.7E-03)</td>\n",
       "      <td>(high, 5.4E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>(car, 3.5E-02)</td>\n",
       "      <td>(cars, 1.2E-02)</td>\n",
       "      <td>(engine, 8.3E-03)</td>\n",
       "      <td>(speed, 6.0E-03)</td>\n",
       "      <td>(writes, 5.9E-03)</td>\n",
       "      <td>(article, 5.6E-03)</td>\n",
       "      <td>(miles, 5.5E-03)</td>\n",
       "      <td>(good, 4.9E-03)</td>\n",
       "      <td>(much, 4.4E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>(gun, 2.2E-02)</td>\n",
       "      <td>(file, 1.1E-02)</td>\n",
       "      <td>(law, 9.2E-03)</td>\n",
       "      <td>(firearms, 8.4E-03)</td>\n",
       "      <td>(control, 7.4E-03)</td>\n",
       "      <td>(crime, 6.2E-03)</td>\n",
       "      <td>(000, 6.0E-03)</td>\n",
       "      <td>(bill, 5.5E-03)</td>\n",
       "      <td>(guns, 5.1E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>(game, 1.5E-02)</td>\n",
       "      <td>(team, 1.2E-02)</td>\n",
       "      <td>(hockey, 9.9E-03)</td>\n",
       "      <td>(season, 8.5E-03)</td>\n",
       "      <td>(play, 7.9E-03)</td>\n",
       "      <td>(go, 6.9E-03)</td>\n",
       "      <td>(year, 6.2E-03)</td>\n",
       "      <td>(games, 6.0E-03)</td>\n",
       "      <td>(vs, 4.9E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>(window, 2.5E-02)</td>\n",
       "      <td>(server, 9.4E-03)</td>\n",
       "      <td>(application, 8.1E-03)</td>\n",
       "      <td>(widget, 8.1E-03)</td>\n",
       "      <td>(use, 7.4E-03)</td>\n",
       "      <td>(display, 7.0E-03)</td>\n",
       "      <td>(using, 6.3E-03)</td>\n",
       "      <td>(set, 6.0E-03)</td>\n",
       "      <td>(motif, 5.3E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>(year, 1.6E-02)</td>\n",
       "      <td>(last, 8.4E-03)</td>\n",
       "      <td>(runs, 7.7E-03)</td>\n",
       "      <td>(game, 7.4E-03)</td>\n",
       "      <td>(good, 7.2E-03)</td>\n",
       "      <td>(team, 6.9E-03)</td>\n",
       "      <td>(hit, 6.2E-03)</td>\n",
       "      <td>(season, 5.4E-03)</td>\n",
       "      <td>(players, 5.2E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>(book, 1.5E-02)</td>\n",
       "      <td>(science, 1.1E-02)</td>\n",
       "      <td>(one, 1.1E-02)</td>\n",
       "      <td>(theory, 9.4E-03)</td>\n",
       "      <td>(books, 9.0E-03)</td>\n",
       "      <td>(scientific, 4.9E-03)</td>\n",
       "      <td>(many, 4.5E-03)</td>\n",
       "      <td>(time, 4.4E-03)</td>\n",
       "      <td>(knowledge, 3.6E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>(food, 1.3E-02)</td>\n",
       "      <td>(msg, 1.2E-02)</td>\n",
       "      <td>(one, 6.5E-03)</td>\n",
       "      <td>(pain, 6.4E-03)</td>\n",
       "      <td>(people, 6.1E-03)</td>\n",
       "      <td>(effects, 5.5E-03)</td>\n",
       "      <td>(eat, 5.4E-03)</td>\n",
       "      <td>(writes, 5.2E-03)</td>\n",
       "      <td>(article, 5.2E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>(god, 1.7E-02)</td>\n",
       "      <td>(one, 1.0E-02)</td>\n",
       "      <td>(believe, 7.7E-03)</td>\n",
       "      <td>(people, 6.9E-03)</td>\n",
       "      <td>(truth, 6.6E-03)</td>\n",
       "      <td>(religion, 6.3E-03)</td>\n",
       "      <td>(must, 5.7E-03)</td>\n",
       "      <td>(exist, 5.6E-03)</td>\n",
       "      <td>(say, 5.6E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>(people, 1.7E-02)</td>\n",
       "      <td>(writes, 1.2E-02)</td>\n",
       "      <td>(article, 1.1E-02)</td>\n",
       "      <td>(drugs, 8.9E-03)</td>\n",
       "      <td>(think, 7.0E-03)</td>\n",
       "      <td>(kids, 6.5E-03)</td>\n",
       "      <td>(want, 5.5E-03)</td>\n",
       "      <td>(drug, 4.9E-03)</td>\n",
       "      <td>(see, 4.7E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>(key, 4.3E-02)</td>\n",
       "      <td>(keys, 1.2E-02)</td>\n",
       "      <td>(des, 8.9E-03)</td>\n",
       "      <td>(chip, 8.3E-03)</td>\n",
       "      <td>(bit, 8.0E-03)</td>\n",
       "      <td>(number, 7.3E-03)</td>\n",
       "      <td>(one, 7.1E-03)</td>\n",
       "      <td>(public, 7.1E-03)</td>\n",
       "      <td>(encryption, 5.9E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>(gun, 1.1E-02)</td>\n",
       "      <td>(guns, 1.1E-02)</td>\n",
       "      <td>(weapons, 8.0E-03)</td>\n",
       "      <td>(people, 7.9E-03)</td>\n",
       "      <td>(police, 6.8E-03)</td>\n",
       "      <td>(one, 6.6E-03)</td>\n",
       "      <td>(think, 6.0E-03)</td>\n",
       "      <td>(use, 4.6E-03)</td>\n",
       "      <td>(like, 4.4E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>(turkish, 1.2E-02)</td>\n",
       "      <td>(greek, 1.2E-02)</td>\n",
       "      <td>(san, 1.0E-02)</td>\n",
       "      <td>(turks, 7.2E-03)</td>\n",
       "      <td>(turkey, 6.5E-03)</td>\n",
       "      <td>(people, 6.2E-03)</td>\n",
       "      <td>(greece, 5.7E-03)</td>\n",
       "      <td>(greeks, 5.5E-03)</td>\n",
       "      <td>(said, 5.3E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>(water, 1.7E-02)</td>\n",
       "      <td>(air, 9.8E-03)</td>\n",
       "      <td>(radar, 7.2E-03)</td>\n",
       "      <td>(light, 6.5E-03)</td>\n",
       "      <td>(hot, 6.5E-03)</td>\n",
       "      <td>(one, 6.1E-03)</td>\n",
       "      <td>(get, 5.8E-03)</td>\n",
       "      <td>(like, 5.5E-03)</td>\n",
       "      <td>(used, 5.0E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>(university, 1.2E-02)</td>\n",
       "      <td>(research, 9.6E-03)</td>\n",
       "      <td>(1993, 9.2E-03)</td>\n",
       "      <td>(health, 7.7E-03)</td>\n",
       "      <td>(center, 7.6E-03)</td>\n",
       "      <td>(april, 7.4E-03)</td>\n",
       "      <td>(national, 6.8E-03)</td>\n",
       "      <td>(medical, 6.1E-03)</td>\n",
       "      <td>(information, 5.6E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>(fax, 2.1E-02)</td>\n",
       "      <td>(mail, 2.1E-02)</td>\n",
       "      <td>(university, 1.7E-02)</td>\n",
       "      <td>(anyone, 1.6E-02)</td>\n",
       "      <td>(phone, 1.5E-02)</td>\n",
       "      <td>(email, 1.3E-02)</td>\n",
       "      <td>(computer, 1.2E-02)</td>\n",
       "      <td>(know, 1.2E-02)</td>\n",
       "      <td>(advance, 1.1E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>(turkish, 1.2E-02)</td>\n",
       "      <td>(armenian, 1.1E-02)</td>\n",
       "      <td>(war, 9.3E-03)</td>\n",
       "      <td>(armenians, 6.9E-03)</td>\n",
       "      <td>(jews, 6.6E-03)</td>\n",
       "      <td>(genocide, 5.6E-03)</td>\n",
       "      <td>(turks, 5.5E-03)</td>\n",
       "      <td>(people, 5.5E-03)</td>\n",
       "      <td>(world, 5.4E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>(0, 1.2E-01)</td>\n",
       "      <td>(6, 2.3E-02)</td>\n",
       "      <td>(4, 2.0E-02)</td>\n",
       "      <td>(7, 2.0E-02)</td>\n",
       "      <td>(8, 2.0E-02)</td>\n",
       "      <td>(5, 1.9E-02)</td>\n",
       "      <td>(9, 1.8E-02)</td>\n",
       "      <td>(3, 1.6E-02)</td>\n",
       "      <td>(25, 1.4E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>(available, 1.2E-02)</td>\n",
       "      <td>(edu, 1.1E-02)</td>\n",
       "      <td>(ftp, 1.1E-02)</td>\n",
       "      <td>(graphics, 8.5E-03)</td>\n",
       "      <td>(pub, 8.4E-03)</td>\n",
       "      <td>(version, 7.4E-03)</td>\n",
       "      <td>(1, 6.4E-03)</td>\n",
       "      <td>(also, 6.4E-03)</td>\n",
       "      <td>(software, 5.7E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>(team, 1.3E-02)</td>\n",
       "      <td>(games, 1.1E-02)</td>\n",
       "      <td>(baseball, 9.5E-03)</td>\n",
       "      <td>(teams, 8.0E-03)</td>\n",
       "      <td>(players, 7.9E-03)</td>\n",
       "      <td>(hockey, 7.3E-03)</td>\n",
       "      <td>(game, 7.0E-03)</td>\n",
       "      <td>(nhl, 6.5E-03)</td>\n",
       "      <td>(play, 6.3E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>(00, 2.2E-02)</td>\n",
       "      <td>(sale, 1.3E-02)</td>\n",
       "      <td>(offer, 1.2E-02)</td>\n",
       "      <td>(price, 1.2E-02)</td>\n",
       "      <td>(apr, 1.1E-02)</td>\n",
       "      <td>(shipping, 9.7E-03)</td>\n",
       "      <td>(new, 9.3E-03)</td>\n",
       "      <td>(15, 8.0E-03)</td>\n",
       "      <td>(asking, 7.7E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>(know, 2.0E-02)</td>\n",
       "      <td>(like, 1.9E-02)</td>\n",
       "      <td>(anyone, 1.8E-02)</td>\n",
       "      <td>(time, 1.8E-02)</td>\n",
       "      <td>(one, 1.7E-02)</td>\n",
       "      <td>(get, 1.6E-02)</td>\n",
       "      <td>(could, 1.2E-02)</td>\n",
       "      <td>(back, 1.1E-02)</td>\n",
       "      <td>(good, 9.5E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>(1, 2.0E-01)</td>\n",
       "      <td>(2, 1.4E-01)</td>\n",
       "      <td>(3, 8.1E-02)</td>\n",
       "      <td>(4, 5.6E-02)</td>\n",
       "      <td>(5, 4.3E-02)</td>\n",
       "      <td>(0, 4.2E-02)</td>\n",
       "      <td>(6, 2.1E-02)</td>\n",
       "      <td>(7, 2.0E-02)</td>\n",
       "      <td>(10, 1.7E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>(ax, 6.6E-01)</td>\n",
       "      <td>(max, 4.7E-02)</td>\n",
       "      <td>(3, 3.0E-02)</td>\n",
       "      <td>(7, 1.2E-02)</td>\n",
       "      <td>(g9v, 1.2E-02)</td>\n",
       "      <td>(b8f, 1.1E-02)</td>\n",
       "      <td>(a86, 9.4E-03)</td>\n",
       "      <td>(pl, 6.5E-03)</td>\n",
       "      <td>(1d9, 6.2E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>(gordon, 8.8E-03)</td>\n",
       "      <td>(banks, 7.3E-03)</td>\n",
       "      <td>(doctor, 7.1E-03)</td>\n",
       "      <td>(disease, 6.8E-03)</td>\n",
       "      <td>(patients, 6.1E-03)</td>\n",
       "      <td>(one, 5.6E-03)</td>\n",
       "      <td>(treatment, 5.5E-03)</td>\n",
       "      <td>(medical, 5.5E-03)</td>\n",
       "      <td>(article, 5.5E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>(encryption, 1.7E-02)</td>\n",
       "      <td>(government, 1.4E-02)</td>\n",
       "      <td>(clipper, 1.2E-02)</td>\n",
       "      <td>(chip, 1.1E-02)</td>\n",
       "      <td>(key, 8.7E-03)</td>\n",
       "      <td>(technology, 8.1E-03)</td>\n",
       "      <td>(use, 7.6E-03)</td>\n",
       "      <td>(law, 7.4E-03)</td>\n",
       "      <td>(privacy, 6.6E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>(bike, 1.7E-02)</td>\n",
       "      <td>(dod, 1.7E-02)</td>\n",
       "      <td>(article, 8.7E-03)</td>\n",
       "      <td>(writes, 8.6E-03)</td>\n",
       "      <td>(ride, 7.9E-03)</td>\n",
       "      <td>(one, 6.0E-03)</td>\n",
       "      <td>(motorcycle, 5.3E-03)</td>\n",
       "      <td>(riding, 4.9E-03)</td>\n",
       "      <td>(dog, 4.9E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>(windows, 4.7E-02)</td>\n",
       "      <td>(dos, 1.9E-02)</td>\n",
       "      <td>(file, 1.7E-02)</td>\n",
       "      <td>(files, 1.4E-02)</td>\n",
       "      <td>(use, 1.2E-02)</td>\n",
       "      <td>(program, 1.1E-02)</td>\n",
       "      <td>(ms, 9.4E-03)</td>\n",
       "      <td>(using, 8.8E-03)</td>\n",
       "      <td>(run, 7.7E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>(1, 5.4E-02)</td>\n",
       "      <td>(0, 2.1E-02)</td>\n",
       "      <td>(6, 1.8E-02)</td>\n",
       "      <td>(8, 1.8E-02)</td>\n",
       "      <td>(7, 1.6E-02)</td>\n",
       "      <td>(cx, 1.5E-02)</td>\n",
       "      <td>(2, 1.4E-02)</td>\n",
       "      <td>(9, 1.4E-02)</td>\n",
       "      <td>(w7, 1.3E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>(0, 3.3E-02)</td>\n",
       "      <td>(7, 3.2E-02)</td>\n",
       "      <td>(1, 2.9E-02)</td>\n",
       "      <td>(4, 2.8E-02)</td>\n",
       "      <td>(5, 2.8E-02)</td>\n",
       "      <td>(3, 2.6E-02)</td>\n",
       "      <td>(2, 2.6E-02)</td>\n",
       "      <td>(6, 2.4E-02)</td>\n",
       "      <td>(8, 2.2E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>(db, 5.7E-02)</td>\n",
       "      <td>(gm, 1.9E-02)</td>\n",
       "      <td>(cs, 1.3E-02)</td>\n",
       "      <td>(mov, 1.3E-02)</td>\n",
       "      <td>(si, 1.2E-02)</td>\n",
       "      <td>(bh, 1.1E-02)</td>\n",
       "      <td>(al, 9.9E-03)</td>\n",
       "      <td>(one, 9.2E-03)</td>\n",
       "      <td>(motto, 7.8E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>(space, 3.3E-02)</td>\n",
       "      <td>(nasa, 1.1E-02)</td>\n",
       "      <td>(earth, 8.0E-03)</td>\n",
       "      <td>(launch, 7.9E-03)</td>\n",
       "      <td>(orbit, 6.4E-03)</td>\n",
       "      <td>(satellite, 5.5E-03)</td>\n",
       "      <td>(shuttle, 5.4E-03)</td>\n",
       "      <td>(lunar, 5.1E-03)</td>\n",
       "      <td>(moon, 5.1E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>(men, 1.4E-02)</td>\n",
       "      <td>(writes, 1.0E-02)</td>\n",
       "      <td>(people, 9.3E-03)</td>\n",
       "      <td>(article, 9.1E-03)</td>\n",
       "      <td>(sex, 9.0E-03)</td>\n",
       "      <td>(women, 7.3E-03)</td>\n",
       "      <td>(sexual, 6.9E-03)</td>\n",
       "      <td>(gay, 6.7E-03)</td>\n",
       "      <td>(government, 6.4E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>(right, 1.6E-02)</td>\n",
       "      <td>(people, 1.6E-02)</td>\n",
       "      <td>(jim, 1.3E-02)</td>\n",
       "      <td>(well, 1.1E-02)</td>\n",
       "      <td>(amendment, 1.0E-02)</td>\n",
       "      <td>(militia, 9.9E-03)</td>\n",
       "      <td>(rights, 9.8E-03)</td>\n",
       "      <td>(bear, 8.2E-03)</td>\n",
       "      <td>(state, 7.9E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>(ground, 1.7E-02)</td>\n",
       "      <td>(wire, 1.3E-02)</td>\n",
       "      <td>(cable, 9.2E-03)</td>\n",
       "      <td>(use, 7.7E-03)</td>\n",
       "      <td>(wiring, 7.6E-03)</td>\n",
       "      <td>(one, 7.2E-03)</td>\n",
       "      <td>(connected, 6.7E-03)</td>\n",
       "      <td>(neutral, 6.2E-03)</td>\n",
       "      <td>(plastic, 5.4E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>(file, 2.5E-02)</td>\n",
       "      <td>(entry, 2.4E-02)</td>\n",
       "      <td>(output, 2.0E-02)</td>\n",
       "      <td>(program, 1.6E-02)</td>\n",
       "      <td>(0, 1.6E-02)</td>\n",
       "      <td>(section, 1.2E-02)</td>\n",
       "      <td>(1, 1.1E-02)</td>\n",
       "      <td>(rules, 1.1E-02)</td>\n",
       "      <td>(entries, 9.0E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>(people, 1.0E-02)</td>\n",
       "      <td>(koresh, 7.1E-03)</td>\n",
       "      <td>(fbi, 6.7E-03)</td>\n",
       "      <td>(writes, 6.5E-03)</td>\n",
       "      <td>(article, 6.3E-03)</td>\n",
       "      <td>(batf, 6.0E-03)</td>\n",
       "      <td>(never, 6.0E-03)</td>\n",
       "      <td>(death, 5.9E-03)</td>\n",
       "      <td>(law, 5.8E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>(god, 2.7E-02)</td>\n",
       "      <td>(jesus, 1.8E-02)</td>\n",
       "      <td>(one, 8.6E-03)</td>\n",
       "      <td>(church, 8.6E-03)</td>\n",
       "      <td>(bible, 8.2E-03)</td>\n",
       "      <td>(christ, 8.0E-03)</td>\n",
       "      <td>(christian, 7.9E-03)</td>\n",
       "      <td>(people, 6.6E-03)</td>\n",
       "      <td>(christians, 6.5E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>(writes, 1.2E-02)</td>\n",
       "      <td>(gas, 9.8E-03)</td>\n",
       "      <td>(fire, 9.5E-03)</td>\n",
       "      <td>(article, 7.7E-03)</td>\n",
       "      <td>(one, 6.8E-03)</td>\n",
       "      <td>(texas, 6.7E-03)</td>\n",
       "      <td>(believe, 6.1E-03)</td>\n",
       "      <td>(picture, 5.8E-03)</td>\n",
       "      <td>(speak, 4.7E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>(list, 1.6E-02)</td>\n",
       "      <td>(mail, 1.4E-02)</td>\n",
       "      <td>(internet, 1.0E-02)</td>\n",
       "      <td>(send, 1.0E-02)</td>\n",
       "      <td>(information, 9.9E-03)</td>\n",
       "      <td>(posting, 9.3E-03)</td>\n",
       "      <td>(email, 8.9E-03)</td>\n",
       "      <td>(news, 8.0E-03)</td>\n",
       "      <td>(group, 7.7E-03)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>(card, 3.6E-02)</td>\n",
       "      <td>(monitor, 2.1E-02)</td>\n",
       "      <td>(video, 2.1E-02)</td>\n",
       "      <td>(color, 1.7E-02)</td>\n",
       "      <td>(drivers, 1.3E-02)</td>\n",
       "      <td>(vga, 1.2E-02)</td>\n",
       "      <td>(mode, 1.2E-02)</td>\n",
       "      <td>(driver, 1.1E-02)</td>\n",
       "      <td>(screen, 1.0E-02)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>(keyboard, 1.2E-02)</td>\n",
       "      <td>(new, 1.0E-02)</td>\n",
       "      <td>(oil, 6.6E-03)</td>\n",
       "      <td>(price, 5.0E-03)</td>\n",
       "      <td>(one, 4.9E-03)</td>\n",
       "      <td>(also, 4.8E-03)</td>\n",
       "      <td>(sales, 4.3E-03)</td>\n",
       "      <td>(weaver, 4.2E-03)</td>\n",
       "      <td>(may, 4.1E-03)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic          composition 0          composition 1  \\\n",
       "0       0      (israel, 2.3E-02)     (israeli, 1.6E-02)   \n",
       "1       1       (money, 2.0E-02)  (government, 9.3E-03)   \n",
       "2       2         (mac, 2.0E-02)       (apple, 1.5E-02)   \n",
       "3       3        (said, 1.3E-02)      (people, 1.2E-02)   \n",
       "4       4          (mr, 2.5E-02)   (president, 2.3E-02)   \n",
       "5       5       (image, 2.1E-02)    (software, 1.1E-02)   \n",
       "6       6       (drive, 4.8E-02)        (scsi, 2.6E-02)   \n",
       "7       7      (writes, 5.5E-02)     (article, 4.6E-02)   \n",
       "8       8         (use, 9.8E-03)         (one, 8.8E-03)   \n",
       "9       9         (car, 3.5E-02)        (cars, 1.2E-02)   \n",
       "10     10         (gun, 2.2E-02)        (file, 1.1E-02)   \n",
       "11     11        (game, 1.5E-02)        (team, 1.2E-02)   \n",
       "12     12      (window, 2.5E-02)      (server, 9.4E-03)   \n",
       "13     13        (year, 1.6E-02)        (last, 8.4E-03)   \n",
       "14     14        (book, 1.5E-02)     (science, 1.1E-02)   \n",
       "15     15        (food, 1.3E-02)         (msg, 1.2E-02)   \n",
       "16     16         (god, 1.7E-02)         (one, 1.0E-02)   \n",
       "17     17      (people, 1.7E-02)      (writes, 1.2E-02)   \n",
       "18     18         (key, 4.3E-02)        (keys, 1.2E-02)   \n",
       "19     19         (gun, 1.1E-02)        (guns, 1.1E-02)   \n",
       "20     20     (turkish, 1.2E-02)       (greek, 1.2E-02)   \n",
       "21     21       (water, 1.7E-02)         (air, 9.8E-03)   \n",
       "22     22  (university, 1.2E-02)    (research, 9.6E-03)   \n",
       "23     23         (fax, 2.1E-02)        (mail, 2.1E-02)   \n",
       "24     24     (turkish, 1.2E-02)    (armenian, 1.1E-02)   \n",
       "25     25           (0, 1.2E-01)           (6, 2.3E-02)   \n",
       "26     26   (available, 1.2E-02)         (edu, 1.1E-02)   \n",
       "27     27        (team, 1.3E-02)       (games, 1.1E-02)   \n",
       "28     28          (00, 2.2E-02)        (sale, 1.3E-02)   \n",
       "29     29        (know, 2.0E-02)        (like, 1.9E-02)   \n",
       "30     30           (1, 2.0E-01)           (2, 1.4E-01)   \n",
       "31     31          (ax, 6.6E-01)         (max, 4.7E-02)   \n",
       "32     32      (gordon, 8.8E-03)       (banks, 7.3E-03)   \n",
       "33     33  (encryption, 1.7E-02)  (government, 1.4E-02)   \n",
       "34     34        (bike, 1.7E-02)         (dod, 1.7E-02)   \n",
       "35     35     (windows, 4.7E-02)         (dos, 1.9E-02)   \n",
       "36     36           (1, 5.4E-02)           (0, 2.1E-02)   \n",
       "37     37           (0, 3.3E-02)           (7, 3.2E-02)   \n",
       "38     38          (db, 5.7E-02)          (gm, 1.9E-02)   \n",
       "39     39       (space, 3.3E-02)        (nasa, 1.1E-02)   \n",
       "40     40         (men, 1.4E-02)      (writes, 1.0E-02)   \n",
       "41     41       (right, 1.6E-02)      (people, 1.6E-02)   \n",
       "42     42      (ground, 1.7E-02)        (wire, 1.3E-02)   \n",
       "43     43        (file, 2.5E-02)       (entry, 2.4E-02)   \n",
       "44     44      (people, 1.0E-02)      (koresh, 7.1E-03)   \n",
       "45     45         (god, 2.7E-02)       (jesus, 1.8E-02)   \n",
       "46     46      (writes, 1.2E-02)         (gas, 9.8E-03)   \n",
       "47     47        (list, 1.6E-02)        (mail, 1.4E-02)   \n",
       "48     48        (card, 3.6E-02)     (monitor, 2.1E-02)   \n",
       "49     49    (keyboard, 1.2E-02)         (new, 1.0E-02)   \n",
       "\n",
       "                composition 2         composition 3           composition 4  \\\n",
       "0             (jews, 1.2E-02)       (arab, 8.4E-03)       (jewish, 5.8E-03)   \n",
       "1             (cost, 8.5E-03)        (pay, 8.1E-03)          (tax, 7.6E-03)   \n",
       "2              (bit, 1.2E-02)     (memory, 9.6E-03)          (ram, 8.8E-03)   \n",
       "3              (one, 1.1E-02)         (us, 9.3E-03)    (armenians, 8.5E-03)   \n",
       "4   (stephanopoulos, 1.2E-02)      (think, 1.1E-02)        (going, 1.0E-02)   \n",
       "5             (jpeg, 1.1E-02)        (gif, 9.1E-03)       (images, 8.9E-03)   \n",
       "6             (disk, 2.1E-02)       (hard, 1.7E-02)       (drives, 1.6E-02)   \n",
       "7            (think, 2.7E-02)       (like, 2.0E-02)         (know, 1.7E-02)   \n",
       "8            (sound, 8.3E-03)      (power, 7.0E-03)        (radio, 6.7E-03)   \n",
       "9           (engine, 8.3E-03)      (speed, 6.0E-03)       (writes, 5.9E-03)   \n",
       "10             (law, 9.2E-03)   (firearms, 8.4E-03)      (control, 7.4E-03)   \n",
       "11          (hockey, 9.9E-03)     (season, 8.5E-03)         (play, 7.9E-03)   \n",
       "12     (application, 8.1E-03)     (widget, 8.1E-03)          (use, 7.4E-03)   \n",
       "13            (runs, 7.7E-03)       (game, 7.4E-03)         (good, 7.2E-03)   \n",
       "14             (one, 1.1E-02)     (theory, 9.4E-03)        (books, 9.0E-03)   \n",
       "15             (one, 6.5E-03)       (pain, 6.4E-03)       (people, 6.1E-03)   \n",
       "16         (believe, 7.7E-03)     (people, 6.9E-03)        (truth, 6.6E-03)   \n",
       "17         (article, 1.1E-02)      (drugs, 8.9E-03)        (think, 7.0E-03)   \n",
       "18             (des, 8.9E-03)       (chip, 8.3E-03)          (bit, 8.0E-03)   \n",
       "19         (weapons, 8.0E-03)     (people, 7.9E-03)       (police, 6.8E-03)   \n",
       "20             (san, 1.0E-02)      (turks, 7.2E-03)       (turkey, 6.5E-03)   \n",
       "21           (radar, 7.2E-03)      (light, 6.5E-03)          (hot, 6.5E-03)   \n",
       "22            (1993, 9.2E-03)     (health, 7.7E-03)       (center, 7.6E-03)   \n",
       "23      (university, 1.7E-02)     (anyone, 1.6E-02)        (phone, 1.5E-02)   \n",
       "24             (war, 9.3E-03)  (armenians, 6.9E-03)         (jews, 6.6E-03)   \n",
       "25               (4, 2.0E-02)          (7, 2.0E-02)            (8, 2.0E-02)   \n",
       "26             (ftp, 1.1E-02)   (graphics, 8.5E-03)          (pub, 8.4E-03)   \n",
       "27        (baseball, 9.5E-03)      (teams, 8.0E-03)      (players, 7.9E-03)   \n",
       "28           (offer, 1.2E-02)      (price, 1.2E-02)          (apr, 1.1E-02)   \n",
       "29          (anyone, 1.8E-02)       (time, 1.8E-02)          (one, 1.7E-02)   \n",
       "30               (3, 8.1E-02)          (4, 5.6E-02)            (5, 4.3E-02)   \n",
       "31               (3, 3.0E-02)          (7, 1.2E-02)          (g9v, 1.2E-02)   \n",
       "32          (doctor, 7.1E-03)    (disease, 6.8E-03)     (patients, 6.1E-03)   \n",
       "33         (clipper, 1.2E-02)       (chip, 1.1E-02)          (key, 8.7E-03)   \n",
       "34         (article, 8.7E-03)     (writes, 8.6E-03)         (ride, 7.9E-03)   \n",
       "35            (file, 1.7E-02)      (files, 1.4E-02)          (use, 1.2E-02)   \n",
       "36               (6, 1.8E-02)          (8, 1.8E-02)            (7, 1.6E-02)   \n",
       "37               (1, 2.9E-02)          (4, 2.8E-02)            (5, 2.8E-02)   \n",
       "38              (cs, 1.3E-02)        (mov, 1.3E-02)           (si, 1.2E-02)   \n",
       "39           (earth, 8.0E-03)     (launch, 7.9E-03)        (orbit, 6.4E-03)   \n",
       "40          (people, 9.3E-03)    (article, 9.1E-03)          (sex, 9.0E-03)   \n",
       "41             (jim, 1.3E-02)       (well, 1.1E-02)    (amendment, 1.0E-02)   \n",
       "42           (cable, 9.2E-03)        (use, 7.7E-03)       (wiring, 7.6E-03)   \n",
       "43          (output, 2.0E-02)    (program, 1.6E-02)            (0, 1.6E-02)   \n",
       "44             (fbi, 6.7E-03)     (writes, 6.5E-03)      (article, 6.3E-03)   \n",
       "45             (one, 8.6E-03)     (church, 8.6E-03)        (bible, 8.2E-03)   \n",
       "46            (fire, 9.5E-03)    (article, 7.7E-03)          (one, 6.8E-03)   \n",
       "47        (internet, 1.0E-02)       (send, 1.0E-02)  (information, 9.9E-03)   \n",
       "48           (video, 2.1E-02)      (color, 1.7E-02)      (drivers, 1.3E-02)   \n",
       "49             (oil, 6.6E-03)      (price, 5.0E-03)          (one, 4.9E-03)   \n",
       "\n",
       "            composition 5          composition 6       composition 7  \\\n",
       "0        (peace, 5.7E-03)      (people, 5.6E-03)     (land, 5.4E-03)   \n",
       "1         (year, 7.3E-03)   (insurance, 6.4E-03)  (private, 5.9E-03)   \n",
       "2        (speed, 8.6E-03)          (32, 7.4E-03)    (simms, 7.1E-03)   \n",
       "3         (went, 7.1E-03)    (armenian, 6.4E-03)     (came, 5.7E-03)   \n",
       "4       (people, 1.0E-02)        (said, 9.6E-03)     (know, 9.4E-03)   \n",
       "5          (bit, 7.5E-03)      (format, 7.4E-03)     (file, 6.7E-03)   \n",
       "6   (controller, 1.5E-02)         (ide, 1.2E-02)   (floppy, 9.5E-03)   \n",
       "7          (one, 1.6E-02)      (people, 1.4E-02)      (get, 1.4E-02)   \n",
       "8        (audio, 6.6E-03)       (input, 6.4E-03)   (output, 5.7E-03)   \n",
       "9      (article, 5.6E-03)       (miles, 5.5E-03)     (good, 4.9E-03)   \n",
       "10       (crime, 6.2E-03)         (000, 6.0E-03)     (bill, 5.5E-03)   \n",
       "11          (go, 6.9E-03)        (year, 6.2E-03)    (games, 6.0E-03)   \n",
       "12     (display, 7.0E-03)       (using, 6.3E-03)      (set, 6.0E-03)   \n",
       "13        (team, 6.9E-03)         (hit, 6.2E-03)   (season, 5.4E-03)   \n",
       "14  (scientific, 4.9E-03)        (many, 4.5E-03)     (time, 4.4E-03)   \n",
       "15     (effects, 5.5E-03)         (eat, 5.4E-03)   (writes, 5.2E-03)   \n",
       "16    (religion, 6.3E-03)        (must, 5.7E-03)    (exist, 5.6E-03)   \n",
       "17        (kids, 6.5E-03)        (want, 5.5E-03)     (drug, 4.9E-03)   \n",
       "18      (number, 7.3E-03)         (one, 7.1E-03)   (public, 7.1E-03)   \n",
       "19         (one, 6.6E-03)       (think, 6.0E-03)      (use, 4.6E-03)   \n",
       "20      (people, 6.2E-03)      (greece, 5.7E-03)   (greeks, 5.5E-03)   \n",
       "21         (one, 6.1E-03)         (get, 5.8E-03)     (like, 5.5E-03)   \n",
       "22       (april, 7.4E-03)    (national, 6.8E-03)  (medical, 6.1E-03)   \n",
       "23       (email, 1.3E-02)    (computer, 1.2E-02)     (know, 1.2E-02)   \n",
       "24    (genocide, 5.6E-03)       (turks, 5.5E-03)   (people, 5.5E-03)   \n",
       "25           (5, 1.9E-02)           (9, 1.8E-02)        (3, 1.6E-02)   \n",
       "26     (version, 7.4E-03)           (1, 6.4E-03)     (also, 6.4E-03)   \n",
       "27      (hockey, 7.3E-03)        (game, 7.0E-03)      (nhl, 6.5E-03)   \n",
       "28    (shipping, 9.7E-03)         (new, 9.3E-03)       (15, 8.0E-03)   \n",
       "29         (get, 1.6E-02)       (could, 1.2E-02)     (back, 1.1E-02)   \n",
       "30           (0, 4.2E-02)           (6, 2.1E-02)        (7, 2.0E-02)   \n",
       "31         (b8f, 1.1E-02)         (a86, 9.4E-03)       (pl, 6.5E-03)   \n",
       "32         (one, 5.6E-03)   (treatment, 5.5E-03)  (medical, 5.5E-03)   \n",
       "33  (technology, 8.1E-03)         (use, 7.6E-03)      (law, 7.4E-03)   \n",
       "34         (one, 6.0E-03)  (motorcycle, 5.3E-03)   (riding, 4.9E-03)   \n",
       "35     (program, 1.1E-02)          (ms, 9.4E-03)    (using, 8.8E-03)   \n",
       "36          (cx, 1.5E-02)           (2, 1.4E-02)        (9, 1.4E-02)   \n",
       "37           (3, 2.6E-02)           (2, 2.6E-02)        (6, 2.4E-02)   \n",
       "38          (bh, 1.1E-02)          (al, 9.9E-03)      (one, 9.2E-03)   \n",
       "39   (satellite, 5.5E-03)     (shuttle, 5.4E-03)    (lunar, 5.1E-03)   \n",
       "40       (women, 7.3E-03)      (sexual, 6.9E-03)      (gay, 6.7E-03)   \n",
       "41     (militia, 9.9E-03)      (rights, 9.8E-03)     (bear, 8.2E-03)   \n",
       "42         (one, 7.2E-03)   (connected, 6.7E-03)  (neutral, 6.2E-03)   \n",
       "43     (section, 1.2E-02)           (1, 1.1E-02)    (rules, 1.1E-02)   \n",
       "44        (batf, 6.0E-03)       (never, 6.0E-03)    (death, 5.9E-03)   \n",
       "45      (christ, 8.0E-03)   (christian, 7.9E-03)   (people, 6.6E-03)   \n",
       "46       (texas, 6.7E-03)     (believe, 6.1E-03)  (picture, 5.8E-03)   \n",
       "47     (posting, 9.3E-03)       (email, 8.9E-03)     (news, 8.0E-03)   \n",
       "48         (vga, 1.2E-02)        (mode, 1.2E-02)   (driver, 1.1E-02)   \n",
       "49        (also, 4.8E-03)       (sales, 4.3E-03)   (weaver, 4.2E-03)   \n",
       "\n",
       "             composition 8  \n",
       "0         (arabs, 5.4E-03)  \n",
       "1       (billion, 5.9E-03)  \n",
       "2           (cpu, 7.1E-03)  \n",
       "3          (know, 5.4E-03)  \n",
       "4          (jobs, 9.0E-03)  \n",
       "5           (use, 6.5E-03)  \n",
       "6        (system, 9.4E-03)  \n",
       "7           (say, 1.1E-02)  \n",
       "8          (high, 5.4E-03)  \n",
       "9          (much, 4.4E-03)  \n",
       "10         (guns, 5.1E-03)  \n",
       "11           (vs, 4.9E-03)  \n",
       "12        (motif, 5.3E-03)  \n",
       "13      (players, 5.2E-03)  \n",
       "14    (knowledge, 3.6E-03)  \n",
       "15      (article, 5.2E-03)  \n",
       "16          (say, 5.6E-03)  \n",
       "17          (see, 4.7E-03)  \n",
       "18   (encryption, 5.9E-03)  \n",
       "19         (like, 4.4E-03)  \n",
       "20         (said, 5.3E-03)  \n",
       "21         (used, 5.0E-03)  \n",
       "22  (information, 5.6E-03)  \n",
       "23      (advance, 1.1E-02)  \n",
       "24        (world, 5.4E-03)  \n",
       "25           (25, 1.4E-02)  \n",
       "26     (software, 5.7E-03)  \n",
       "27         (play, 6.3E-03)  \n",
       "28       (asking, 7.7E-03)  \n",
       "29         (good, 9.5E-03)  \n",
       "30           (10, 1.7E-02)  \n",
       "31          (1d9, 6.2E-03)  \n",
       "32      (article, 5.5E-03)  \n",
       "33      (privacy, 6.6E-03)  \n",
       "34          (dog, 4.9E-03)  \n",
       "35          (run, 7.7E-03)  \n",
       "36           (w7, 1.3E-02)  \n",
       "37            (8, 2.2E-02)  \n",
       "38        (motto, 7.8E-03)  \n",
       "39         (moon, 5.1E-03)  \n",
       "40   (government, 6.4E-03)  \n",
       "41        (state, 7.9E-03)  \n",
       "42      (plastic, 5.4E-03)  \n",
       "43      (entries, 9.0E-03)  \n",
       "44          (law, 5.8E-03)  \n",
       "45   (christians, 6.5E-03)  \n",
       "46        (speak, 4.7E-03)  \n",
       "47        (group, 7.7E-03)  \n",
       "48       (screen, 1.0E-02)  \n",
       "49          (may, 4.1E-03)  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top3 topics of each group\n",
      "group 0                    alt.atheism topic16(3.4e-01) topic07(1.2e-01) topic44(1.1e-01)\n",
      "group 1                  comp.graphics topic05(2.1e-01) topic26(1.4e-01) topic48(9.5e-02)\n",
      "group 2        comp.os.ms-windows.misc topic35(3.7e-01) topic48(9.0e-02) topic23(8.0e-02)\n",
      "group 3       comp.sys.ibm.pc.hardware topic06(2.1e-01) topic02(1.1e-01) topic48(1.1e-01)\n",
      "group 4          comp.sys.mac.hardware topic02(2.9e-01) topic29(1.2e-01) topic23(1.0e-01)\n",
      "group 5                 comp.windows.x topic12(4.1e-01) topic23(1.1e-01) topic26(1.0e-01)\n",
      "group 6                   misc.forsale topic28(3.9e-01) topic08(6.7e-02) topic23(6.2e-02)\n",
      "group 7                      rec.autos topic09(4.3e-01) topic29(9.6e-02) topic07(7.7e-02)\n",
      "group 8                rec.motorcycles topic34(5.0e-01) topic29(8.6e-02) topic07(7.6e-02)\n",
      "group 9             rec.sport.baseball topic13(4.2e-01) topic27(1.8e-01) topic07(1.1e-01)\n",
      "group10               rec.sport.hockey topic11(4.5e-01) topic07(1.4e-01) topic27(1.3e-01)\n",
      "group11                      sci.crypt topic33(3.0e-01) topic18(2.1e-01) topic07(1.1e-01)\n",
      "group12                sci.electronics topic08(2.7e-01) topic21(9.6e-02) topic23(9.6e-02)\n",
      "group13                        sci.med topic32(2.5e-01) topic15(2.4e-01) topic29(1.0e-01)\n",
      "group14                      sci.space topic39(3.2e-01) topic01(1.0e-01) topic07(9.9e-02)\n",
      "group15         soc.religion.christian topic45(3.9e-01) topic16(1.5e-01) topic29(6.5e-02)\n",
      "group16             talk.politics.guns topic19(2.0e-01) topic46(1.6e-01) topic10(1.5e-01)\n",
      "group17          talk.politics.mideast topic00(3.8e-01) topic24(1.2e-01) topic20(1.0e-01)\n",
      "group18             talk.politics.misc topic40(2.3e-01) topic01(1.2e-01) topic17(1.1e-01)\n",
      "group19             talk.religion.misc topic45(2.1e-01) topic16(1.2e-01) topic07(9.4e-02)\n",
      "top3 groups of each topic\n",
      "topic0     talk.politics.mideast(7.6e-03)        talk.religion.misc(7.6e-03)               alt.atheism(6.9e-03)\n",
      "topic1        talk.politics.misc(1.0e-01)                 sci.space(1.0e-01)        talk.politics.guns(2.2e-02)\n",
      "topic2     comp.sys.mac.hardware(1.1e-01)  comp.sys.ibm.pc.hardware(1.1e-01)              misc.forsale(2.8e-02)\n",
      "topic3     talk.politics.mideast(1.0e-02)        talk.politics.guns(1.0e-02)        talk.religion.misc(9.2e-03)\n",
      "topic4        talk.politics.misc(2.5e-02)     talk.politics.mideast(2.5e-02)        talk.politics.guns(1.4e-02)\n",
      "topic5             comp.graphics(2.7e-02)   comp.os.ms-windows.misc(2.7e-02)            comp.windows.x(1.9e-02)\n",
      "topic6  comp.sys.ibm.pc.hardware(8.2e-02)     comp.sys.mac.hardware(8.2e-02)              misc.forsale(4.8e-02)\n",
      "topic7          rec.sport.hockey(1.2e-01)               alt.atheism(1.2e-01)        rec.sport.baseball(1.1e-01)\n",
      "topic8           sci.electronics(6.7e-02)              misc.forsale(6.7e-02)     comp.sys.mac.hardware(3.9e-02)\n",
      "topic9                 rec.autos(4.8e-02)           rec.motorcycles(4.8e-02)              misc.forsale(2.8e-02)\n",
      "topic10        talk.politics.guns(1.9e-02)        talk.politics.misc(1.9e-02)           rec.motorcycles(5.5e-03)\n",
      "topic11          rec.sport.hockey(9.4e-03)        rec.sport.baseball(9.4e-03)              misc.forsale(7.3e-03)\n",
      "topic12            comp.windows.x(2.7e-02)   comp.os.ms-windows.misc(2.7e-02)             comp.graphics(2.1e-02)\n",
      "topic13        rec.sport.baseball(1.7e-02)          rec.sport.hockey(1.7e-02)        talk.politics.misc(5.3e-03)\n",
      "topic14                   sci.med(6.2e-02)        talk.religion.misc(6.2e-02)               alt.atheism(6.2e-02)\n",
      "topic15                   sci.med(2.2e-02)        talk.religion.misc(2.2e-02)        talk.politics.misc(7.9e-03)\n",
      "topic16               alt.atheism(1.5e-01)    soc.religion.christian(1.5e-01)        talk.religion.misc(1.2e-01)\n",
      "topic17        talk.politics.misc(6.5e-02)               alt.atheism(6.5e-02)                 rec.autos(3.7e-02)\n",
      "topic18                 sci.crypt(7.7e-03)           sci.electronics(7.7e-03)            comp.windows.x(4.1e-03)\n",
      "topic19        talk.politics.guns(5.3e-02)        talk.politics.misc(5.3e-02)                 sci.crypt(1.4e-02)\n",
      "topic20     talk.politics.mideast(4.1e-02)        talk.religion.misc(4.1e-02)        talk.politics.guns(1.7e-02)\n",
      "topic21           sci.electronics(4.1e-02)                 rec.autos(4.1e-02)           rec.motorcycles(3.2e-02)\n",
      "topic22                   sci.med(2.4e-02)        talk.politics.misc(2.4e-02)    soc.religion.christian(1.4e-02)\n",
      "topic23            comp.windows.x(1.1e-01)  comp.sys.ibm.pc.hardware(1.1e-01)     comp.sys.mac.hardware(1.0e-01)\n",
      "topic24     talk.politics.mideast(1.9e-02)        talk.politics.misc(1.9e-02)               alt.atheism(1.3e-02)\n",
      "topic25          rec.sport.hockey(2.4e-02)        rec.sport.baseball(2.4e-02)  comp.sys.ibm.pc.hardware(1.3e-02)\n",
      "topic26             comp.graphics(1.0e-01)            comp.windows.x(1.0e-01)   comp.os.ms-windows.misc(1.8e-02)\n",
      "topic27        rec.sport.baseball(1.3e-01)          rec.sport.hockey(1.3e-01)              misc.forsale(1.8e-02)\n",
      "topic28              misc.forsale(2.5e-02)           rec.motorcycles(2.5e-02)           sci.electronics(2.5e-02)\n",
      "topic29     comp.sys.mac.hardware(1.1e-01)  comp.sys.ibm.pc.hardware(1.1e-01)                   sci.med(1.0e-01)\n",
      "topic30              misc.forsale(4.4e-02)          rec.sport.hockey(4.4e-02)   comp.os.ms-windows.misc(2.9e-02)\n",
      "topic31   comp.os.ms-windows.misc(8.1e-04)           rec.motorcycles(8.1e-04)     comp.sys.mac.hardware(5.6e-04)\n",
      "topic32                   sci.med(5.4e-03)  comp.sys.ibm.pc.hardware(5.4e-03)    soc.religion.christian(5.4e-03)\n",
      "topic33                 sci.crypt(5.3e-03)        talk.politics.guns(5.3e-03)           sci.electronics(4.3e-03)\n",
      "topic34           rec.motorcycles(2.0e-02)                 rec.autos(2.0e-02)              misc.forsale(6.6e-03)\n",
      "topic35   comp.os.ms-windows.misc(6.3e-02)  comp.sys.ibm.pc.hardware(6.3e-02)             comp.graphics(5.3e-02)\n",
      "topic36   comp.os.ms-windows.misc(1.2e-03)  comp.sys.ibm.pc.hardware(1.2e-03)              misc.forsale(1.1e-03)\n",
      "topic37   comp.os.ms-windows.misc(4.2e-03)             comp.graphics(4.2e-03)        rec.sport.baseball(3.5e-03)\n",
      "topic38        talk.religion.misc(1.0e-02)                 sci.crypt(1.0e-02)                 rec.autos(9.5e-03)\n",
      "topic39                 sci.space(7.3e-03)           sci.electronics(7.3e-03)             comp.graphics(6.5e-03)\n",
      "topic40        talk.politics.misc(4.0e-02)        talk.religion.misc(4.0e-02)               alt.atheism(3.0e-02)\n",
      "topic41        talk.politics.guns(3.5e-02)                 sci.crypt(3.5e-02)        talk.religion.misc(3.1e-02)\n",
      "topic42           sci.electronics(2.0e-02)     comp.sys.mac.hardware(2.0e-02)                 sci.space(2.0e-02)\n",
      "topic43            comp.windows.x(9.2e-03)   comp.os.ms-windows.misc(9.2e-03)             comp.graphics(8.2e-03)\n",
      "topic44        talk.politics.guns(1.1e-01)               alt.atheism(1.1e-01)        talk.religion.misc(7.9e-02)\n",
      "topic45    soc.religion.christian(2.1e-01)        talk.religion.misc(2.1e-01)               alt.atheism(5.0e-02)\n",
      "topic46        talk.politics.guns(4.7e-02)        talk.religion.misc(4.7e-02)                 sci.space(3.0e-02)\n",
      "topic47                 sci.crypt(3.2e-02)            comp.windows.x(3.2e-02)   comp.os.ms-windows.misc(2.9e-02)\n",
      "topic48  comp.sys.ibm.pc.hardware(9.5e-02)             comp.graphics(9.5e-02)   comp.os.ms-windows.misc(9.0e-02)\n",
      "topic49                 rec.autos(2.1e-02)     comp.sys.mac.hardware(2.1e-02)                   sci.med(1.3e-02)\n"
     ]
    }
   ],
   "source": [
    "plsa.print_mat(max_docs=5, max_topics=100, max_terms=9)\n",
    "print_lsa(plsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    N_topics = 3+0*min(3, n_catogories)\n",
    "    print(\"We want %d topics\"%N_topics)\n",
    "    lda=LDA()\n",
    "    lda.set_structured_documents(email_sdocs)\n",
    "    lda.topic_decompose(ntopics=N_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    lda.print_mat(max_docs=10, max_terms=3)\n",
    "    print_lsa(lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bakcups\n",
    "## 随机梯度下降 (Stochastic gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to maximize\n",
    "$$\n",
    "P(\\theta, \\phi|\\mathbf{w}) = \\sum_{z}P(\\theta, \\phi|\\mathbf{z}, \\mathbf{w}) P(\\mathbf{z}|\\mathbf{w})\n",
    "$$\n",
    "\n",
    "then we need\n",
    "$$\n",
    "\\partial_\\theta P(\\theta, \\phi|\\mathbf{w})\n",
    "=\n",
    "\\partial_\\theta \\sum_{z}P(\\theta, \\phi|\\mathbf{z}, \\mathbf{w}) P(\\mathbf{z}|\\mathbf{w})\n",
    "=\n",
    "\\sum_{z} P(\\mathbf{z}|\\mathbf{w}) \\partial_\\theta P(\\theta, \\phi|\\mathbf{z}, \\mathbf{w})\n",
    "=0\n",
    "$$\n",
    "\n",
    "similarly\n",
    "$$\n",
    "\\sum_{z} P(\\mathbf{z}|\\mathbf{w}) \\partial_\\phi P(\\theta, \\phi|\\mathbf{z}, \\mathbf{w})\n",
    "=0\n",
    "$$\n",
    "\n",
    "\n",
    "We can sample $z$ with probability of $P(\\mathbf{z}|\\mathbf{w})$, and move $\\theta$ and $\\phi$ along the direction of \n",
    "$-\\partial_\\theta P(\\theta, \\phi|\\mathbf{z}, \\mathbf{w})$ and $-\\partial_\\phi P(\\theta, \\phi, \\mathbf{z}|\\mathbf{w})$, respectively.\n",
    "(At least) for small engouh the step, we will reach the statination point.\n",
    "But it's often bad to use gradient decent method with probablity (we should use log(probablity)). \n",
    "\n",
    "we write it in the form of \n",
    "$$\n",
    "P(\\theta, \\phi|\\mathbf{w}) \n",
    "=\n",
    "\\sum_{z} P(\\theta, \\phi, \\mathbf{z}, \\mathbf{w})/P(\\mathbf{w})\n",
    "=\n",
    "\\sum_{z} P(\\mathbf{z}, \\mathbf{w} | \\theta, \\phi)P(\\theta,\\phi)/P(\\mathbf{w})\n",
    "$$\n",
    "\n",
    "### the pLSA\n",
    "EM algoirhtm, we define the Q function as\n",
    "$$\n",
    "\\sum_{z} P(\\mathbf{z} | \\mathbf{w}, \\theta^i, \\phi^i) \\log  P(\\mathbf{z}, \\mathbf{w}|\\theta, \\phi)\n",
    "$$\n",
    "We to maximize to Q (with constraint of $\\sum_k \\theta_{mk}=1$, or normalize in time)\n",
    "$$\n",
    "\\partial_\\theta \\sum_{z}  P(\\mathbf{z} | \\mathbf{w}, \\theta^i, \\phi^i) \\log  P(\\mathbf{z}, \\mathbf{w}|\\theta, \\phi) = 0\n",
    "$$\n",
    "$$\n",
    "\\sum_{z}  P(\\mathbf{z} | \\mathbf{w}, \\theta^i, \\phi^i) \\partial_\\theta \\log  P(\\mathbf{z}, \\mathbf{w}|\\theta, \\phi) = 0\n",
    "$$\n",
    "\n",
    "\n",
    "We can sample $z$ with probability of $ P(\\mathbf{z} | \\mathbf{w}, \\theta^i, \\phi^i)$, and move $\\theta$ and $\\phi$ along the direction of \n",
    "$-\\partial_\\theta \\log  P(\\mathbf{z}, \\mathbf{w}|\\theta, \\phi)$ and $-\\partial_\\phi \\log  P(\\mathbf{z}, \\mathbf{w}|\\theta, \\phi)$, respectively.\n",
    "The update ruler\n",
    "$$\n",
    "\\theta^{i+1} = \\theta + \\eta \\partial_\\theta \\log  P(\\mathbf{z}, \\mathbf{w}|\\theta, \\phi)\n",
    "$$\n",
    "$$\n",
    "\\phi^{i+1} = \\phi + \\eta \\partial_\\phi\\log  P(\\mathbf{z}, \\mathbf{w}|\\theta, \\phi)\n",
    "$$\n",
    "\n",
    "It's simple that\n",
    "$$\n",
    "\\log P(\\mathbf{z},\\mathbf{w}|\\theta,\\phi)\n",
    "=\n",
    "\\prod_{mn} \\text{Cat}(z_{mn}|\\theta_m) \n",
    "\\text{Cat}(w_{mn}|\\phi_{z_{mn}})\n",
    "$$\n",
    "then\n",
    "$$\n",
    "\\partial_{\\theta_m} \\log P(\\mathbf{z},\\mathbf{w}|\\theta,\\phi)\n",
    "=\n",
    "n_m/\\theta_m\n",
    "$$\n",
    "$$\n",
    "\\partial_{\\phi_k} \\log P(\\mathbf{z},\\mathbf{w}|\\theta,\\phi)\n",
    "=\n",
    "n_k/\\phi_k\n",
    "$$\n",
    "\n",
    "Excisie:\n",
    "Note the normalized pdf of $\\mathbf{z}$ and $\\mathbf{w}$ should be\n",
    "$$\n",
    "P(\\mathbf{z}, \\mathbf{w}|\\theta, \\phi)\n",
    " =\n",
    "P(\\mathbf{z}, \\mathbf{w}, \\theta, \\phi)/P(\\theta, \\phi)\n",
    " =\n",
    "P(\\theta, \\phi | \\mathbf{z}, \\mathbf{w}) P(\\mathbf{z}, \\mathbf{w})/P(\\theta, \\phi)\n",
    "$$\n",
    "\n",
    "we just recall\n",
    "$$\n",
    "P(\\theta, \\phi)\n",
    "=\n",
    "\\left[\\prod_k \\text{Dir} (\\phi_k|\\beta)\\right]\n",
    "\\left[\\prod_m \\text{Dir}(\\theta_m|\\alpha)\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\log P(\\mathbf{z},\\mathbf{w}|\\theta,\\phi)\n",
    "= \n",
    "\\log P(\\mathbf{z}, \\mathbf{w})\n",
    "+ \\log \\left[\\prod_m \\text{Dir}(\\theta_m|n_m+\\alpha)\\right]\n",
    "+\\log\\left[\\prod_k \\text{Dir}(\\phi_k|n_k+\\beta)\\right]\n",
    "-\\log \\left[\\prod_m \\text{Dir}(\\theta_m|\\alpha)\\right]\n",
    "-\\log \\left[\\prod_k \\text{Dir} (\\phi_k|\\beta)\\right]\n",
    "$$\n",
    "we can again obtain the $P(\\mathbf{z}, \\mathbf{w}|\\theta, \\phi)$\n",
    "\n",
    "and \n",
    "$$\n",
    "P(\\mathbf{z} |\\mathbf{w}, \\theta, \\phi)\n",
    "=\n",
    "P(\\mathbf{z}, \\mathbf{w} | \\theta, \\phi)/ P(\\mathbf{w}|\\theta, \\phi)\n",
    "\\propto\n",
    "\\theta_{mk} \\phi_{kn}\n",
    "$$\n",
    "for the document $m$ and word $n$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### the LDA\n",
    "Like EM algoirhtm, we define the Q function as\n",
    "$$\n",
    "\\sum_{z} P(\\mathbf{z}, \\mathbf{w}, \\theta^i, \\phi^i) \\log  P(\\mathbf{z}, \\mathbf{w}, \\theta, \\phi)\n",
    "$$\n",
    "We to maximize to Q (with constraint of $\\sum_k \\theta_{mk}=1$, or normalize in time)\n",
    "$$\n",
    "\\partial_\\theta \\sum_{z}  P(\\mathbf{z}, \\mathbf{w}, \\theta^i, \\phi^i) \\log  P(\\mathbf{z}, \\mathbf{w}, \\theta, \\phi) = 0\n",
    "$$\n",
    "$$\n",
    "\\sum_{z}  P(\\mathbf{z}, \\mathbf{w}, \\theta^i, \\phi^i) \\partial_\\theta \\log  P(\\mathbf{z}, \\mathbf{w}, \\theta, \\phi) = 0\n",
    "$$\n",
    "\n",
    "\n",
    "We can sample $z$ with probability of $ P(\\mathbf{z}, \\mathbf{w}, \\theta^i, \\phi^i)$, and move $\\theta$ and $\\phi$ along the direction of \n",
    "$-\\partial_\\theta \\log  P(\\mathbf{z}, \\mathbf{w}, \\theta, \\phi)$ and $-\\partial_\\phi \\log  P(\\mathbf{z}, \\mathbf{w}, \\theta, \\phi)$, respectively.\n",
    "The update ruler\n",
    "$$\n",
    "\\theta^{i+1} = \\theta + \\eta \\partial_\\theta \\log  P(\\mathbf{z}, \\mathbf{w}, \\theta, \\phi)\n",
    "$$\n",
    "$$\n",
    "\\phi^{i+1} = \\phi + \\eta \\partial_\\phi\\log  P(\\mathbf{z}, \\mathbf{w}, \\theta, \\phi)\n",
    "$$\n",
    "\n",
    "It's simple that\n",
    "$$\n",
    "\\partial_{\\theta_m} \\log P(\\mathbf{z},\\mathbf{w}, \\theta,\\phi)\n",
    "=\n",
    "(n_m + \\alpha - 1)/\\theta_m\n",
    "$$\n",
    "$$\n",
    "\\partial_{\\phi_k} \\log P(\\mathbf{z},\\mathbf{w}, \\theta,\\phi)\n",
    "=\n",
    "(n_k + \\beta - 1)/\\phi_k\n",
    "$$\n",
    "\n",
    "and \n",
    "$$\n",
    "P(\\mathbf{z}, \\mathbf{w}, \\theta, \\phi)\n",
    "\\propto\n",
    "\\theta_{mk} \\phi_{kn}\n",
    "$$\n",
    "for the document $m$ and word $n$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha=1.0\n",
    "beta=1.0\n",
    "\n",
    "theta_mk = np.random.rand(len(documents), ntopics)\n",
    "theta_mk = theta_mk / theta_mk.sum(axis=1, keepdims=True)\n",
    "phi_kv = np.random.rand(ntopics, len(terms_vec))\n",
    "phi_kv = phi_kv / phi_kv.sum(axis=1, keepdims=True)\n",
    "\n",
    "def zwtp_Gibbs_topic_prob(m, v):    \n",
    "    return theta_mk[m,:] * phi_kv[:,v]\n",
    "\n",
    "def zwtp_MH_topic_prob(m, v, k):\n",
    "    return theta_mk[m, k] * phi_kv[k, v]\n",
    "\n",
    "intialize_randomly()\n",
    "\n",
    "# warnming\n",
    "for _ in range(1000):\n",
    "    Gibbs_step(zwtp_Gibbs_topic_prob)\n",
    "\n",
    "def normalize(mat):\n",
    "    return mat/mat.sum(axis=1, keepdims=True)\n",
    "    \n",
    "eta = 0.01\n",
    "for _ in range(1000):\n",
    "    MH_step(zwtp_MH_topic_prob)\n",
    "    \n",
    "    #print(n_mk[:,:] + alpha - 1)\n",
    "    #print(theta_mk)\n",
    "    d = (n_mk[:,:] + alpha - 1)/theta_mk[:,:]\n",
    "    theta_mk = theta_mk + eta*d\n",
    "    theta_mk = normalize(theta_mk)\n",
    "    \n",
    "    d = (n_kv[:,:] + beta - 1)/phi_kv[:,:]\n",
    "    phi_kv = phi_kv + eta*d\n",
    "    phi_kv = normalize(phi_kv)\n",
    "    \n",
    "    #print(theta_mk)\n",
    "    #print(phi_kv)\n",
    "    #print_mat(n_kv.transpose(), n_mk.transpose())\n",
    "    #print(theta_mk.sum(axis=1))\n",
    "    #print(phi_kv.sum(axis=1))\n",
    "    #print(k_mn)\n",
    "    #print(n_kv)\n",
    "    #print(n_mk)\n",
    "    \n",
    "print_mat(phi_kv.transpose(), theta_mk.transpose())"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "24",
    "lenType": "16",
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
