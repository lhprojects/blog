{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#读取数据\" data-toc-modified-id=\"读取数据-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>读取数据</a></span></li><li><span><a href=\"#反查表\" data-toc-modified-id=\"反查表-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>反查表</a></span></li><li><span><a href=\"#协同过滤\" data-toc-modified-id=\"协同过滤-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>协同过滤</a></span><ul class=\"toc-item\"><li><span><a href=\"#链接本页的页也链接了\" data-toc-modified-id=\"链接本页的页也链接了-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>链接本页的页也链接了</a></span></li><li><span><a href=\"#这些页也链接了本页的链接的页\" data-toc-modified-id=\"这些页也链接了本页的链接的页-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>这些页也链接了本页的链接的页</a></span></li><li><span><a href=\"#清除内存\" data-toc-modified-id=\"清除内存-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>清除内存</a></span></li></ul></li><li><span><a href=\"#保存所有结果\" data-toc-modified-id=\"保存所有结果-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>保存所有结果</a></span></li><li><span><a href=\"#读取\" data-toc-modified-id=\"读取-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>读取</a></span><ul class=\"toc-item\"><li><span><a href=\"#链接到本页的页也链接了\" data-toc-modified-id=\"链接到本页的页也链接了-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>链接到本页的页也链接了</a></span></li><li><span><a href=\"#这些页也链接了本页的链接的页\" data-toc-modified-id=\"这些页也链接了本页的链接的页-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>这些页也链接了本页的链接的页</a></span></li></ul></li><li><span><a href=\"#Benchmarks\" data-toc-modified-id=\"Benchmarks-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Benchmarks</a></span><ul class=\"toc-item\"><li><span><a href=\"#hash_unique.unique\" data-toc-modified-id=\"hash_unique.unique-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>hash_unique.unique</a></span></li><li><span><a href=\"#numpy.unique\" data-toc-modified-id=\"numpy.unique-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>numpy.unique</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据\n",
    "\n",
    "读取已经解析好的维基百科数据。参见PageRank笔记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Logarithmic scale', 'Algorithm', 'Google Search', 'Web page', 'Web search engine', 'Larry Page', 'Google Patents', 'Network theory', 'Weighting', 'Hyperlink', 'Set (abstract data type)', 'World Wide Web', 'Link building', 'Webgraph', 'CNN', 'USA.gov', 'Recursion', 'Backlink', 'HITS algorithm', 'Jon Kleinberg', 'Teoma', 'Ask.com', 'CLEVER project', 'TrustRank', 'Google Hummingbird', 'Eigenvalues and eigenvectors', 'Scientometrics', 'Thomas L. Saaty', 'Analytic hierarchy process', 'Cognitive model', 'Baidu', 'Robin Li', 'The New York Times', 'Forbes', 'Sergey Brin', 'Stanford University', 'Rajeev Motwani', 'Terry Winograd', 'Google', 'Software patent', 'Citation analysis', 'Eugene Garfield', 'Hyper Search', 'Massimo Marchiori', 'University of Padua', 'Probability distribution', 'Matt Cutts', 'Markov chain', 'URL', 'Adjacency matrix', 'Stochastic matrix', 'Eigenvector centrality', 'Eigengap', 'Expected value', 'Wikipedia', 'Link farm', 'Trade secret', 'Power iteration', 'Steady state', 'Identity matrix', 'Perron–Frobenius theorem', 'Apache Spark', 'MATLAB', 'GNU Octave', 'Python (programming language)', 'Graph (abstract data type)', 'Bipartite graph', 'Random walk', 'Distributed algorithm', 'Google Toolbar', 'Danny Sullivan (technologist)', 'Search engine results page', 'Moz (marketing software)', 'Search engine optimization', 'Google Maps', 'Google Directory', 'HTTP 302', 'Meta element', 'Website spoofing', 'Nofollow', 'HTML attribute', 'Gaming the system', 'Citation', 'Sociometry', 'Attention economy', 'Institute for Scientific Information', 'Impact factor', 'Eigenfactor', 'SCImago Journal Rank', 'Neuroscience', 'Neuron', 'Twitter', 'Swiftype', 'Web crawler', 'Blogosphere', 'Scale-free network', 'Lexical semantics', 'Word-sense disambiguation', 'Semantic similarity', 'WordNet', 'Synonym ring', 'Link relation', 'Blog', 'Spamdexing', 'Spam in blogs', 'Search engine optimization metrics', 'Google Chrome', 'Domain Authority', 'EigenTrust', 'Google bombing', 'Google matrix', 'Google Panda', 'Google Penguin', 'VisualRank', 'Hilltop algorithm', 'Katz centrality', 'SimRank', 'CheiRank', 'Attention inequality']\n"
     ]
    }
   ],
   "source": [
    "import wiki\n",
    "wiki_titles = wiki.WikiTitles(file = \"pass1.5.data\")\n",
    "wiki_links = wiki.WikiLinks(file = \"pass2.npz\", wiki_titles=wiki_titles)\n",
    "print(wiki_links.get_links_from_title(\"PageRank\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10132.655316718961\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"page_rank.data\", \"rb\") as f:\n",
    "    PR = pickle.load(f)\n",
    "    \n",
    "index = wiki_titles.get_index_from_title(\"USA\")\n",
    "print(PR[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反查表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Carl Linnaeus', 'Google Search', 'History of the Internet', 'List of algorithms', 'Web crawler', 'Spamdexing', 'Hyperlink', 'South East England', 'Advogato', 'Markov chain', 'Larry Page', 'Sergey Brin', \"Bradford's law\", 'Search engine optimization', 'Google Answers', 'Spectrum of a matrix', 'Link farm', 'Google bombing', 'PR', 'MediaWiki', 'Google (verb)', '1996 in science', 'Newsgroup spam', 'Wassily Leontief', 'Timeline of algorithms', 'Relevance', 'Fixed point (mathematics)', 'Global Multimedia Protocols Group', 'Thomas L. Saaty', 'Spam in blogs', 'Backlink', 'MozDex', 'Google Toolbar', 'Automatic summarization', 'Webometrics', 'Affiliate marketing', 'Document retrieval', 'Network theory', 'Web mining', 'List of eponyms (L–Z)', 'Trust metric', 'List of University of California, Berkeley alumni', 'VoIP spam', 'Findability', 'Google', 'Bibliometrics', 'Citation analysis', 'Jon Kleinberg', 'Eugene Garfield', 'Full-text search', 'Referrer spam', 'Centrality', 'Ranking', 'List of Google products', 'Perron–Frobenius theorem', 'Web 2.0', 'Raph Levien', 'Greg Errico', 'Baidu', 'OkCupid', 'Copywriting', 'HITS algorithm', 'IEEE Transactions on Information Theory', 'Tag cloud', 'Tf–idf', 'Eigenvalues and eigenvectors', 'TrustRank', 'Andrew Clausen', 'Power-knowledge', 'Spam blog', 'Sports rating system', 'Lanczos algorithm', 'Sakura HyperMedia Desktop', 'Organic search', 'Greggs', 'Scraper site', 'Attention economy', 'Domains by Proxy', 'Matt Cutts', 'Eigenvector centrality', 'Web ranking', 'Nofollow', 'Jeremy Zawodny', 'Reputation system', 'Web search engine', 'Spam mass', \"Shepard's Citations\", 'History of the World Wide Web', 'History of Google', 'Journal of Biological Chemistry', 'Wikipedia', 'Robin Li', 'Google Personalized Search', 'Consensus (computer science)', 'Power iteration', 'Massimo Marchiori', 'Mark Burgess (computer scientist)', 'Search engine technology', 'Hilltop algorithm', 'Social search', 'Sepandar Kamvar', 'Linkback', 'Saipan Sucks', 'PR2', 'PR5', 'S-rank', 'Article marketing', 'Criticism of Google', 'Journal ranking', 'Domain name drop list', 'Focused crawler', 'Hyper Search', 'Noviforum', 'Enterprise search', 'Proxy voting', 'WikiPilipinas', 'SocialRank', 'Eigendecomposition of a matrix', 'Reputation capital', 'Link building', 'Kaltix', 'Network science', 'Rajeev Motwani', 'VisualRank', 'Swoogle', 'Rebelion.org', 'Teachstreet', 'Operation Clambake', 'DMOZ', 'SimRank', 'Ranking (information retrieval)', 'Google matrix', 'Matrix (mathematics)', 'Richard J. Sullivan', 'Seznam.cz', 'DeepPeep', 'Eigenfactor', 'Stanford Digital Library Project', 'NDepend', 'Googlization', 'SCImago Journal Rank', 'Legal information retrieval', 'Learning to rank', 'Outline of Google', 'Quora', 'MediaWiki extension', 'Convergent Functional Genomics', 'Learning analytics', 'Leo Katz (statistician)', 'Lee–Carter model', 'Vitaly Borker', 'CheiRank', \"Rexer's Annual Data Miner Survey\", 'Google juice', 'Katz centrality', 'Yandex Search', 'Webgraph', 'Academic visibility', 'GraphLab', 'Marketing and artificial intelligence', 'Google Penguin', 'Moz (marketing software)', 'SALSA algorithm', 'Google penalty', 'EdgeRank', 'Entity linking', 'PageRank algorithm in biochemistry', 'Google Hummingbird', \"Who's Bigger?\", 'Timeline of Google Search', 'Timeline of web search engines', 'Apache Spark', 'Kraliçe', 'Mükemmel', 'Rasim Alguliyev', 'Yooreeka', 'Google Pigeon', 'Soumen Chakrabarti', 'Multidimensional network', 'Technology transfer in computer science', 'Bianconi–Barabási model', '9 Algorithms That Changed the Future', \"List of Google April Fools' Day jokes\", 'Search engine optimization metrics', 'RankBrain', 'Domain Authority', 'European Union vs. Google', 'Internet manipulation', 'Local search engine optimisation', 'Outline of machine learning', 'Google Fred', 'WordLift', 'Alessandro Strumia', 'Search engine privacy', 'Truth discovery', 'Amy Langville', 'Random surfing model']\n"
     ]
    }
   ],
   "source": [
    "import CF\n",
    "inverse_links = CF.InverseLinks(links = wiki_links, titles = wiki_titles)\n",
    "print(inverse_links.get_links_from_title_inverse(\"PageRank\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 协同过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CF\n",
    "itemCF = CF.ItemCF(links = wiki_links, inverse_links = inverse_links, titles = wiki_titles, weights = np.power(PR, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 链接本页的页也链接了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008 Summer Olympics                               0.28\n",
      "China                                              0.24\n",
      "2015 World Championships in Athletics              0.23\n",
      "NBC Olympic broadcasts                             0.21\n",
      "Athletics at the 2008 Summer Olympics              0.21\n",
      "Shanghai                                           0.20\n",
      "Tianjin                                            0.17\n",
      "Guangzhou                                          0.15\n",
      "Athletics at the 2016 Summer Olympics              0.14\n",
      "Beijing Subway                                     0.14\n",
      "====\n",
      "New York City                                      0.16\n",
      "California                                         0.16\n",
      "Canada                                             0.14\n",
      "United Kingdom                                     0.13\n",
      "New York (state)                                   0.13\n",
      "Washington, D.C.                                   0.12\n",
      "Texas                                              0.12\n",
      "Los Angeles                                        0.11\n",
      "The New York Times                                 0.11\n",
      "Florida                                            0.10\n",
      "====\n",
      "HITS algorithm                                     0.25\n",
      "Spamdexing                                         0.22\n",
      "Backlink                                           0.18\n",
      "Google Panda                                       0.18\n",
      "Google Penguin                                     0.18\n",
      "TrustRank                                          0.17\n",
      "Katz centrality                                    0.16\n",
      "Search engine optimization                         0.16\n",
      "History of Google                                  0.16\n",
      "Larry Page                                         0.16\n",
      "====\n",
      "Ge (surname)                                       0.16\n",
      "Mou (surname)                                      0.16\n",
      "Wat (surname)                                      0.15\n",
      "Fei (surname)                                      0.14\n",
      "Lian (surname)                                     0.14\n",
      "Ji (surname 嵇)                                     0.12\n",
      "Liang Siyong                                       0.12\n",
      "Shuai                                              0.12\n",
      "Di (surname)                                       0.12\n",
      "Long (surname)                                     0.11\n"
     ]
    }
   ],
   "source": [
    "def print___pages_link_to_this_page_also_link_to(this_page):\n",
    "    i = wiki_titles.get_index_from_title(this_page)\n",
    "    #uns, ws = itemCF.pages_link_to_this_page_also_link_to(i, use_weights_inter=True, use_weights_final=True)\n",
    "    uns, ws = itemCF.pages_link_to_this_page_also_link_to(i, use_weights_inter=True)\n",
    "    #uns, ws = itemCF.pages_link_to_this_page_also_link_to(i, use_weights_final=True)\n",
    "    titles = [wiki_titles.get_title_from_index(pid) for pid in uns]\n",
    "    for page, w in zip(titles, ws):\n",
    "        print(\"%-50s %.2f\"%(page, w))\n",
    "        \n",
    "print___pages_link_to_this_page_also_link_to(this_page=\"Beijing\")\n",
    "print(\"====\")\n",
    "print___pages_link_to_this_page_also_link_to(this_page=\"United States\")\n",
    "print(\"====\")\n",
    "print___pages_link_to_this_page_also_link_to(this_page=\"PageRank\")\n",
    "print(\"====\")\n",
    "print___pages_link_to_this_page_also_link_to(this_page=\"Liang (surname)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这些页也链接了本页的链接的页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History of Beijing                                 0.31\n",
      "Geography of Beijing                               0.26\n",
      "List of Beijing landmarks                          0.26\n",
      "Hebei                                              0.22\n",
      "Transport in Beijing                               0.21\n",
      "Dongcheng District, Beijing                        0.21\n",
      "China                                              0.20\n",
      "Beijing city fortifications                        0.19\n",
      "List of Major National Historical and Cultural Sites in Beijing 0.19\n",
      "Beijing Subway                                     0.18\n",
      "====\n",
      "History of the United States                       0.23\n",
      "Index of United States-related articles            0.22\n",
      "Culture of the United States                       0.21\n",
      "Americans                                          0.19\n",
      "Economy of the United States                       0.18\n",
      "Demographics of the United States                  0.18\n",
      "Outline of the United States                       0.16\n",
      "Political divisions of the United States           0.15\n",
      "California                                         0.15\n",
      "Democratic Party (United States)                   0.15\n",
      "====\n",
      "TrustRank                                          0.26\n",
      "Search engine optimization                         0.25\n",
      "Backlink                                           0.24\n",
      "Nofollow                                           0.24\n",
      "Hilltop algorithm                                  0.21\n",
      "Spamdexing                                         0.21\n",
      "Google matrix                                      0.21\n",
      "Anchor text                                        0.21\n",
      "HITS algorithm                                     0.21\n",
      "Eigenvector centrality                             0.20\n",
      "====\n",
      "Mediacorp Subaru Impreza WRX Challenge             0.23\n",
      "Borders of Vietnam                                 0.23\n",
      "Macrotermes carbonarius                            0.23\n",
      "Gymnanthera oblonga                                0.22\n",
      "Alstonia spatulata                                 0.22\n",
      "Miele Guide                                        0.22\n",
      "Box of Hope                                        0.22\n",
      "Culex rubithoracis                                 0.21\n",
      "Asian-Oceanian Computing Industry Organization     0.21\n",
      "Asia Submarine Cable Express                       0.21\n"
     ]
    }
   ],
   "source": [
    "def print__pages_this_page_link_to_also_linked_by(this_page):\n",
    "    i = wiki_titles.get_index_from_title(this_page)\n",
    "    uns, ws = itemCF.pages_this_page_link_to_also_linked_by(i, use_weights_inter=True)\n",
    "    titles = [wiki_titles.get_title_from_index(pid) for pid in uns]\n",
    "    for page, w in zip(titles, ws):\n",
    "        print(\"%-50s %.2f\"%(page, w))\n",
    "\n",
    "\n",
    "print__pages_this_page_link_to_also_linked_by(this_page=\"Beijing\")\n",
    "print(\"====\")\n",
    "print__pages_this_page_link_to_also_linked_by(this_page=\"United States\")\n",
    "print(\"====\")\n",
    "print__pages_this_page_link_to_also_linked_by(this_page=\"PageRank\")\n",
    "print(\"====\")\n",
    "print__pages_this_page_link_to_also_linked_by(this_page=\"Liang (surname)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清除内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del itemCF\n",
    "del wiki_links\n",
    "del wiki_titles\n",
    "del inverse_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存所有结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对所有article，计算协同过滤top10，并且储存。\n",
    "\n",
    "我们采用多进程方案，并且多进程采用`spawn`方式。进程采用`spawn`方式，尽管可能需要更多的时间进行任务的初始化，但是兼容windows。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%file wiki_save.py\n",
    "import multiprocessing\n",
    "import wiki\n",
    "import CF\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def map1(tid, start, end):\n",
    "    print(\"thread %02d: [%d - %d]\"%(tid, start, end))\n",
    "    # initialization need lots of memory, we avoid running them at the same time\n",
    "    if tid < 8:\n",
    "        for i in range(tid):\n",
    "            print(\"thread %02d: sleeping\"%tid)        \n",
    "            time.sleep(20)        \n",
    "    print(\"thread %02d: initializing\"%tid)\n",
    "    itemCF = CF.ItemCF(wiki_titles=None)\n",
    "    n_pages = end - start\n",
    "    pages_link_to_this_page_also_link_to_ = np.zeros((n_pages,10), np.int)-1\n",
    "    for i in range(n_pages):\n",
    "        ids, ws = itemCF.pages_link_to_this_page_also_link_to(start + i)\n",
    "        pages_link_to_this_page_also_link_to_[i, 0:len(ids)] = ids\n",
    "        if i % 1000 == 0:\n",
    "            print(\"thread %02d: %d\"%(tid, i))\n",
    "        \n",
    "    return pages_link_to_this_page_also_link_to_\n",
    "\n",
    "def map2(tid, start, end):\n",
    "    print(\"thread %02d: [%d - %d]\"%(tid, start, end))\n",
    "    # initialization need lots of memory, we avoid running them at the same time\n",
    "    if tid < 8:\n",
    "        for i in range(tid):\n",
    "            print(\"thread %02d: sleeping\"%tid)        \n",
    "            time.sleep(20)        \n",
    "    print(\"thread %02d: initializing\"%tid)\n",
    "    \n",
    "    itemCF = wiki_item_CF.ItemCF(wiki_titles=None)\n",
    "    n_pages = end - start\n",
    "    pages_this_page_link_to_also_linked_by_ = np.zeros((n_pages,10), np.int)-1\n",
    "    for i in range(n_pages):\n",
    "        ids, ws = itemCF.pages_this_page_link_to_also_linked_by(start + i)\n",
    "        pages_this_page_link_to_also_linked_by_[i, 0:len(ids)] = ids\n",
    "        if i % 1000 == 0:\n",
    "            print(\"thread %02d: %d\"%(tid, i))\n",
    "        \n",
    "    return pages_this_page_link_to_also_linked_by_\n",
    "    \n",
    "\n",
    "def save(n_pages):\n",
    "        \n",
    "    n_proc = 8\n",
    "    n_splits = 32\n",
    "    pool = multiprocessing.Pool(processes = n_proc)\n",
    "\n",
    "    results = pool.starmap(map1, [(i, i*n_pages//n_splits, (i+1)*n_pages//n_splits) for i in range(n_splits)])    \n",
    "    pages_link_to_this_page_also_link_to_ = np.concatenate(results)\n",
    "    np.savez_compressed(\"pages_link_to_this_page_also_link_to.npz\", pages_link_to_this_page_also_link_to_)\n",
    "    \n",
    "    results = pool.starmap(map2, [(i, i*n_pages//n_splits, (i+1)*n_pages//n_splits) for i in  range(n_splits)])\n",
    "    pages_this_page_link_to_also_linked_by_ = np.concatenate(results)\n",
    "    np.savez_compressed(\"pages_this_page_link_to_also_linked_by.npz\", pages_this_page_link_to_also_linked_by_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import wiki\n",
    "import wiki_save\n",
    "import imp\n",
    "imp.reload(wiki_save)\n",
    "imp.reload(wiki)\n",
    "n_pages = len(wiki.WikiLinks().page_n_links)\n",
    "%timeit -r1 -n1 wiki_save.save(n_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CF\n",
    "import wiki\n",
    "wiki_titles = wiki.WikiTitles()\n",
    "itemCFCached=CF.ItemCFCached(pages_link_to_this_page_also_link_to=\"pages_link_to_this_page_also_link_to.npz\",\n",
    "                            pages_this_page_link_to_also_linked_by=\"pages_this_page_link_to_also_linked_by.npz\",\n",
    "                            titles = wiki_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 链接到本页的页也链接了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008 Summer Olympics                              \n",
      "China                                             \n",
      "2015 World Championships in Athletics             \n",
      "Athletics at the 2008 Summer Olympics             \n",
      "NBC Olympic broadcasts                            \n",
      "Shanghai                                          \n",
      "Tianjin                                           \n",
      "Guangzhou                                         \n",
      "Athletics at the 2016 Summer Olympics             \n",
      "Beijing Subway                                    \n",
      "====\n",
      "HITS algorithm                                    \n",
      "Spamdexing                                        \n",
      "Backlink                                          \n",
      "Google Panda                                      \n",
      "Google Penguin                                    \n",
      "TrustRank                                         \n",
      "Katz centrality                                   \n",
      "History of Google                                 \n",
      "Search engine optimization                        \n",
      "Larry Page                                        \n",
      "====\n",
      "Ge (surname)                                      \n",
      "Mou (surname)                                     \n",
      "Wat (surname)                                     \n",
      "Fei (surname)                                     \n",
      "Lian (surname)                                    \n",
      "Shuai                                             \n",
      "Liang Siyong                                      \n",
      "Ji (surname 嵇)                                    \n",
      "Di (surname)                                      \n",
      "Long (surname)                                    \n",
      "6.25 µs ± 60.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def print___pages_link_to_this_page_also_link_to(this_page):\n",
    "    titles = itemCFCached.pages_link_to_this_page_also_link_to_title(this_page)\n",
    "    for page in titles:\n",
    "        print(\"%-50s\"%(page))\n",
    "        \n",
    "print___pages_link_to_this_page_also_link_to(this_page=\"Beijing\")\n",
    "print(\"====\")\n",
    "print___pages_link_to_this_page_also_link_to(this_page=\"PageRank\")\n",
    "print(\"====\")\n",
    "print___pages_link_to_this_page_also_link_to(this_page=\"Liang (surname)\")\n",
    "\n",
    "%timeit itemCFCached.pages_link_to_this_page_also_link_to_title(\"Beijing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这些页也链接了本页的链接的页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History of Beijing                                \n",
      "Geography of Beijing                              \n",
      "List of Beijing landmarks                         \n",
      "Transport in Beijing                              \n",
      "Hebei                                             \n",
      "Dongcheng District, Beijing                       \n",
      "List of Major National Historical and Cultural Sites in Beijing\n",
      "Beijing city fortifications                       \n",
      "China                                             \n",
      "Beijing Subway                                    \n",
      "====\n",
      "History of the United States                      \n",
      "Index of United States-related articles           \n",
      "Culture of the United States                      \n",
      "Americans                                         \n",
      "Economy of the United States                      \n",
      "Demographics of the United States                 \n",
      "Outline of the United States                      \n",
      "Political divisions of the United States          \n",
      "Outline of United States history                  \n",
      "Race and ethnicity in the United States           \n",
      "====\n",
      "TrustRank                                         \n",
      "Search engine optimization                        \n",
      "Nofollow                                          \n",
      "Backlink                                          \n",
      "Hilltop algorithm                                 \n",
      "Google matrix                                     \n",
      "Spamdexing                                        \n",
      "Anchor text                                       \n",
      "HITS algorithm                                    \n",
      "Eigenvector centrality                            \n",
      "====\n",
      "Mediacorp Subaru Impreza WRX Challenge            \n",
      "Borders of Vietnam                                \n",
      "Macrotermes carbonarius                           \n",
      "Alstonia spatulata                                \n",
      "Box of Hope                                       \n",
      "Gymnanthera oblonga                               \n",
      "Culex rubithoracis                                \n",
      "Miele Guide                                       \n",
      "Asia Submarine Cable Express                      \n",
      "Asian-Oceanian Computing Industry Organization    \n"
     ]
    }
   ],
   "source": [
    "def print__pages_this_page_link_to_also_linked_by(this_page):\n",
    "    titles = itemCFCached.pages_this_page_link_to_also_linked_by_title(this_page)\n",
    "    for page in titles:\n",
    "        print(\"%-50s\"%(page))\n",
    "\n",
    "print__pages_this_page_link_to_also_linked_by(this_page=\"Beijing\")\n",
    "print(\"====\")\n",
    "print__pages_this_page_link_to_also_linked_by(this_page=\"United States\")\n",
    "print(\"====\")\n",
    "print__pages_this_page_link_to_also_linked_by(this_page=\"PageRank\")\n",
    "print(\"====\")\n",
    "print__pages_this_page_link_to_also_linked_by(this_page=\"Liang (surname)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hash_unique.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.6 ms ± 784 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "553 ms ± 9.93 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "         26 function calls in 0.069 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.004    0.004 <__array_function__ internals>:2(argpartition)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(argsort)\n",
      "        1    0.000    0.000    0.069    0.069 <string>:1(<module>)\n",
      "        2    0.000    0.000    0.004    0.002 fromnumeric.py:52(_wrapfunc)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:752(_argpartition_dispatcher)\n",
      "        1    0.000    0.000    0.004    0.004 fromnumeric.py:756(argpartition)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:995(_argsort_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:999(argsort)\n",
      "        1    0.000    0.000    0.045    0.045 hash_unique.py:35(unique)\n",
      "        1    0.045    0.045    0.045    0.045 hash_unique.py:42(unique_impl)\n",
      "        1    0.000    0.000    0.000    0.000 wiki_data.py:26(get_index_from_title)\n",
      "        1    0.007    0.007    0.007    0.007 wiki_item_CF.py:12(collect_links)\n",
      "        1    0.012    0.012    0.069    0.069 wiki_item_CF.py:38(itemitem)\n",
      "        1    0.000    0.000    0.069    0.069 wiki_item_CF.py:87(pages_link_to_this_page_also_link_to)\n",
      "        1    0.000    0.000    0.069    0.069 {built-in method builtins.exec}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.004    0.002 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "        1    0.004    0.004    0.004    0.004 {method 'argpartition' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print___pages_link_to_this_page_also_link_to(this_page):\n",
    "    i = wiki_titles.get_index_from_title(this_page)\n",
    "    uns, ws = itemCF.pages_link_to_this_page_also_link_to(i)\n",
    "    titles = [wiki_titles.get_title_from_index(pid) for pid in uns]\n",
    "    for page, w in zip(titles, ws):\n",
    "        print(\"%-50s %.2f\"%(page, w))\n",
    "        \n",
    "%timeit itemCF.pages_link_to_this_page_also_link_to(wiki_titles.get_index_from_title(\"Beijing\"))\n",
    "%timeit itemCF.pages_link_to_this_page_also_link_to(wiki_titles.get_index_from_title(\"USA\"))\n",
    "import cProfile\n",
    "cProfile.run('itemCF.pages_link_to_this_page_also_link_to(wiki_titles.get_index_from_title(\"Beijing\"))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 ms ± 368 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "1.02 s ± 5.36 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "         57 function calls (54 primitive calls) in 0.125 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.003    0.003 <__array_function__ internals>:2(argpartition)\n",
      "        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(argsort)\n",
      "        1    0.000    0.000    0.001    0.001 <__array_function__ internals>:2(concatenate)\n",
      "        1    0.000    0.000    0.001    0.001 <__array_function__ internals>:2(diff)\n",
      "        1    0.000    0.000    0.004    0.004 <__array_function__ internals>:2(nonzero)\n",
      "        1    0.000    0.000    0.109    0.109 <__array_function__ internals>:2(unique)\n",
      "        1    0.000    0.000    0.125    0.125 <string>:1(<module>)\n",
      "        3    0.000    0.000    0.000    0.000 _asarray.py:86(asanyarray)\n",
      "        1    0.000    0.000    0.000    0.000 arraysetops.py:136(_unpack_tuple)\n",
      "        1    0.000    0.000    0.000    0.000 arraysetops.py:144(_unique_dispatcher)\n",
      "        1    0.000    0.000    0.109    0.109 arraysetops.py:149(unique)\n",
      "        1    0.006    0.006    0.109    0.109 arraysetops.py:309(_unique1d)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:1812(_nonzero_dispatcher)\n",
      "        1    0.000    0.000    0.004    0.004 fromnumeric.py:1816(nonzero)\n",
      "        3    0.000    0.000    0.007    0.002 fromnumeric.py:52(_wrapfunc)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:752(_argpartition_dispatcher)\n",
      "        1    0.000    0.000    0.003    0.003 fromnumeric.py:756(argpartition)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:995(_argsort_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:999(argsort)\n",
      "        1    0.000    0.000    0.000    0.000 function_base.py:1148(_diff_dispatcher)\n",
      "        1    0.001    0.001    0.001    0.001 function_base.py:1152(diff)\n",
      "        1    0.000    0.000    0.000    0.000 multiarray.py:143(concatenate)\n",
      "        1    0.000    0.000    0.000    0.000 wiki_data.py:26(get_index_from_title)\n",
      "        1    0.008    0.008    0.008    0.008 wiki_item_CF.py:12(collect_links)\n",
      "        1    0.006    0.006    0.125    0.125 wiki_item_CF.py:38(itemitem)\n",
      "        1    0.000    0.000    0.125    0.125 wiki_item_CF.py:87(pages_link_to_this_page_also_link_to)\n",
      "        1    0.000    0.000    0.125    0.125 {built-in method builtins.exec}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        3    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "      6/3    0.001    0.000    0.112    0.037 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.core._multiarray_umath.normalize_axis_index}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.003    0.003    0.003    0.003 {method 'argpartition' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.001    0.001    0.001    0.001 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "        1    0.004    0.004    0.004    0.004 {method 'nonzero' of 'numpy.ndarray' objects}\n",
      "        1    0.096    0.096    0.096    0.096 {method 'sort' of 'numpy.ndarray' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print___pages_link_to_this_page_also_link_to(this_page):\n",
    "    i = wiki_titles.get_index_from_title(this_page)\n",
    "    uns, ws = itemCF.pages_link_to_this_page_also_link_to(i)\n",
    "    titles = [wiki_titles.get_title_from_index(pid) for pid in uns]\n",
    "    for page, w in zip(titles, ws):\n",
    "        print(\"%-50s %.2f\"%(page, w))\n",
    "        \n",
    "%timeit itemCF.pages_link_to_this_page_also_link_to(wiki_titles.get_index_from_title(\"Beijing\"))\n",
    "%timeit itemCF.pages_link_to_this_page_also_link_to(wiki_titles.get_index_from_title(\"USA\"))\n",
    "import cProfile\n",
    "cProfile.run('itemCF.pages_link_to_this_page_also_link_to(wiki_titles.get_index_from_title(\"Beijing\"))')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285.099px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "262px",
    "left": "1574px",
    "right": "20px",
    "top": "119px",
    "width": "327px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
